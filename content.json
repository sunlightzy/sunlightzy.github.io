{"meta":{"title":"Jerry Simple","subtitle":null,"description":null,"author":"John Doe","url":"https://blog.milk4j.com"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-10-21T15:06:58.893Z","updated":"2018-10-21T15:06:58.892Z","comments":false,"path":"/404.html","permalink":"https://blog.milk4j.com//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-10-21T15:07:09.476Z","updated":"2018-10-21T15:07:09.475Z","comments":false,"path":"about/index.html","permalink":"https://blog.milk4j.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2018-10-21T15:06:46.286Z","updated":"2018-10-21T15:06:46.286Z","comments":false,"path":"books/index.html","permalink":"https://blog.milk4j.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-10-21T15:07:19.450Z","updated":"2018-10-21T15:07:19.450Z","comments":false,"path":"categories/index.html","permalink":"https://blog.milk4j.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-21T15:07:32.536Z","updated":"2018-10-21T15:07:32.536Z","comments":true,"path":"links/index.html","permalink":"https://blog.milk4j.com/links/index.html","excerpt":"","text":""},{"title":"Github仓库","date":"2018-10-21T16:49:07.578Z","updated":"2018-10-21T16:49:07.578Z","comments":false,"path":"repository/index.html","permalink":"https://blog.milk4j.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-22T16:07:59.439Z","updated":"2018-10-22T16:07:59.436Z","comments":false,"path":"tags/index.html","permalink":"https://blog.milk4j.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring Boot 自动配置(autoconfigure)原理","slug":"Spring Boot 自动配置(autoconfigure)原理","date":"2018-11-11T15:59:59.000Z","updated":"2018-12-22T06:25:24.081Z","comments":true,"path":"2018/11/11/Spring Boot 自动配置(autoconfigure)原理/","link":"","permalink":"https://blog.milk4j.com/2018/11/11/Spring Boot 自动配置(autoconfigure)原理/","excerpt":"","text":"0. 说明环境配置清单 java version “1.8.0_161”Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)Spring Boot 2.1.0.RELEASE 项目 GitHub 1. 前提知识一、SPI扩展机制1. 解释SPI: Service Provider Interface , 即 服务提供接口 2. 如何写一个Java SPI呢? 定义一组接口， 接口是 com.glmapper.spi.FilterProvider； 接口的一个或多个实现(com.glmapper.spi.provider.FileFilterProvider [从文件系统加载filter], com.glmapper.spi.provider.DataSourceFilterProvider [从数据源中加载filter])； 在 src/main/resources/ 下建立 /META-INF/services 目录， 新增一个以接口命名的文件 com.glmapper.spi.FilterProvider, 内容是要对应的实现类(com.glmapper.spi.provider.FileFilterProvider 或 com.glmapper.spi.provider.DataSourceFilterProvider 或两者)； 使用 ServiceLoader 来加载配置文件中指定的实现。 3. SPI应用案例 Dubbo 中有大量的SPI应用,不过Dubbo不是原生的java spi机制,他是原生的一个变种 . Dubbo SPI 约定: 扩展点约定 : 扩展点必须是 Interface 类型 ， 必须被 @SPI 注解 ， 满足这两点才是一个扩展点。 扩展定义约定 ： 在 META-INF/services/、META-INF/dubbo/、META-INF/dubbo/internal/目录下新建扩展点文件,这些路径下定义的文件名称为扩展点接口的全类名 , 文件中以键值对的方式配置扩展点的扩展实现。例如文件 META-INF/dubbo/internal/com.alibaba.dubbo.common.extension.ExtensionFactory 中定义的扩展 ： 123adaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactoryspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactoryspring=com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory 关于Dubbo SPI扩展机制在此不再继续展开描述 JDBC 数据库驱动包: java mysql 驱动采用原生的spi机制mysql-connector-java-xxx.jar 就有一个 /META-INF/services/java.sql.Driver 里面内容是 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当然还有今天的主角 spring boot ,他也是原生spi的变种,它的约定是在src/main/resorces/下建立META-INF/spring.factories, 当springboot服务启动时，对象实例化过程会加载META-INF/spring.factories文件，将该配置文件中的配置的类载入到Spring容器中.下面是spring-boot-autoconfigure jar包中spring.factories 的内容: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnClassCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\# 这里省略了一堆# Failure analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer# Template availability providersorg.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.web.JspTemplateAvailabilityProvider 2. Spring Boot 自动配置机制0. 总体流程概述1. 几个重要的事件回调机制ApplicationContextInitializer配置在META-INF/spring.factories 1234# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer ApplicationContextInitializer 是上下文初始化入口 SpringApplicationRunListener配置在META-INF/spring.factories 123# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener SpringApplicationRunListener 的功能是监听容器的整个启动过程也就是SpringApplication.run()方法的整个生命周期 ApplicationRunner &amp; CommandLineRunnerCommandLineRunner &amp; ApplicationRunner 接口是在容器启动成功后的最后一步回调（类似开机自启动）, 两者功能差不多, 只需要将其实现类放在IOC容器中,应用启动后会自动回调接口方法 2. 自动配置注解@EnableAutoConfiguration@EnableAutoConfiguration是自动配置的开关, 下面看看他的结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Enable auto-configuration of the Spring Application Context, attempting to guess and * configure beans that you are likely to need. Auto-configuration classes are usually * applied based on your classpath and what beans you have defined. For example, if you * have &#123;@code tomcat-embedded.jar&#125; on your classpath you are likely to want a * &#123;@link TomcatServletWebServerFactory&#125; (unless you have defined your own * &#123;@link ServletWebServerFactory&#125; bean). * &lt;p&gt; * When using &#123;@link SpringBootApplication&#125;, the auto-configuration of the context is * automatically enabled and adding this annotation has therefore no additional effect. * &lt;p&gt; * Auto-configuration tries to be as intelligent as possible and will back-away as you * define more of your own configuration. You can always manually &#123;@link #exclude()&#125; any * configuration that you never want to apply (use &#123;@link #excludeName()&#125; if you don't * have access to them). You can also exclude them via the * &#123;@code spring.autoconfigure.exclude&#125; property. Auto-configuration is always applied * after user-defined beans have been registered. * &lt;p&gt; * The package of the class that is annotated with &#123;@code @EnableAutoConfiguration&#125;, * usually via &#123;@code @SpringBootApplication&#125;, has specific significance and is often used * as a 'default'. For example, it will be used when scanning for &#123;@code @Entity&#125; classes. * It is generally recommended that you place &#123;@code @EnableAutoConfiguration&#125; (if you're * not using &#123;@code @SpringBootApplication&#125;) in a root package so that all sub-packages * and classes can be searched. * &lt;p&gt; * Auto-configuration classes are regular Spring &#123;@link Configuration&#125; beans. They are * located using the &#123;@link SpringFactoriesLoader&#125; mechanism (keyed against this class). * Generally auto-configuration beans are &#123;@link Conditional @Conditional&#125; beans (most * often using &#123;@link ConditionalOnClass @ConditionalOnClass&#125; and * &#123;@link ConditionalOnMissingBean @ConditionalOnMissingBean&#125; annotations). * * @author Phillip Webb * @author Stephane Nicoll * @see ConditionalOnBean * @see ConditionalOnMissingBean * @see ConditionalOnClass * @see AutoConfigureAfter * @see SpringBootApplication */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited// 自动配置包,注册扫描包@AutoConfigurationPackage// 导入的这个AutoConfigurationImportSelector是自动配置的关键@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; 进入AutoConfigurationImportSelector找到selectImports()方法，他调用了getCandidateConfigurations()方法，在这里，这个方法又调用了Spring Core包中的loadFactoryNames()方法。这个方法的作用是，会查询META-INF/spring.factories文件中包含的JAR文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //1. 得到注解信息 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry( autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125;/** * Return the &#123;@link AutoConfigurationEntry&#125; based on the &#123;@link AnnotationMetadata&#125; * of the importing &#123;@link Configuration @Configuration&#125; class. * @param autoConfigurationMetadata the auto-configuration metadata * @param annotationMetadata the annotation metadata of the configuration class * @return the auto-configurations that should be imported */protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; // 2. 得到注解中的所有属性信息 AnnotationAttributes attributes = getAttributes(annotationMetadata); // 3. 得到spring.factories中配置在EnableAutoConfiguration下的字符串列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 4. 去重 configurations = removeDuplicates(configurations); // 5. 根据注解中的exclude信息去除不需要的 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); // 7. 派发事件 fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125;/** * 获取所有的自动配置类,也就是配置在spring.factories中 EnableAutoConfiguration 下的所有字符串列表 * Return the auto-configuration class names that should be considered. By default * this method will load candidates using &#123;@link SpringFactoriesLoader&#125; with * &#123;@link #getSpringFactoriesLoaderFactoryClass()&#125;. * @param metadata the source metadata * @param attributes the &#123;@link #getAttributes(AnnotationMetadata) annotation * attributes&#125; * @return a list of candidate configurations */protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; // getSpringFactoriesLoaderFactoryClass()直接返回EnableAutoConfiguration.class // 所以这一步加载了所有的自动配置类 List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations;&#125;/** * Return the class used by &#123;@link SpringFactoriesLoader&#125; to load configuration * candidates. * @return the factory class */protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class;&#125; 下面进入org.springframework.core.io.support.SpringFactoriesLoader#loadFactoryNames 12345678910111213141516/** * Load the fully qualified class names of factory implementations of the * given type from &#123;@value #FACTORIES_RESOURCE_LOCATION&#125;, using the given * class loader. * @param factoryClass the interface or abstract class representing the factory * @param classLoader the ClassLoader to use for loading resources; can be * &#123;@code null&#125; to use the default * @throws IllegalArgumentException if an error occurs while loading factory names * @see #loadFactories */public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; // 获取全类名 String factoryClassName = factoryClass.getName(); // 加载所有的spring.factories中的配置,然后筛选出factoryClassName下的配置的值 return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());&#125; 在上面的spring-boot-autoconfigure.jar里的spring.factories文件下我们可以看到有这么一段关于EnableAutoConfiguration的配置(放一小段) 1234567891011121314# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 在SpringBoot启动配置类上面打上@EnableAutoConfiguration注解之后springboot就会实例化配置文件中这些XxxAutoConfiguration类启用这些类的功能, ==需要注意的是: 加了@EableAutoConfiguration注解的配置类只会为这个类所在的包以及子包下面的类自动配置== @EnableAutoConfiguration是自动配置的开关 ,如果要自己写自动配置类,还有一些Conditional的注解类需要掌握 @ConditionalOnXxx系列注解SpringBoot的自动配置全都依赖于这个系列的注解,下面列举了一些: ConditionalOnBean 当指定bean存在时, 配置生效ConditionalOnClass 当指定类存在时, 配置生效ConditionalOnCloudPlatform 当项目环境为指定云平台环境时, 配置生效ConditionalOnEnableResourceChain 当ResourceChain是启用状态时, 配置生效ConditionalOnExpression 当表达式为true时, 配置生效ConditionalOnJava 当环境的java为指定版本时,配置生效ConditionalOnJndi 当指定的JNDI存在时, 配置生效ConditionalOnMissingBean 当指定的bean不存在时, 配置生效ConditionalOnMissingClass 当指定的类不存在时, 配置生效ConditionalOnNotWebApplication 当项目为非web项目时, 配置生效ConditionalOnProperty 当指定的配置存在时, 配置生效ConditionalOnResource 当指定的资源存在时, 配置生效ConditionalOnSingleCandidate 当指定的类是单例时, 配置生效ConditionalOnWebApplication 当项目是web项目时, 配置生效 举个栗子下面以HttpEncodingAutoConfiguration为例来看一下自动配置 @ConditionalOnProperty注解的玩法很多, 详细使用案例参考本文文末附件@ConditionalOnProperty注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * &#123;@link EnableAutoConfiguration Auto-configuration&#125; for configuring the encoding to use * in web applications. * * @author Stephane Nicoll * @author Brian Clozel * @since 1.2.0 */@Configuration// 启用HttpProperties配置并加入到IOC容器@EnableConfigurationProperties(HttpProperties.class)// 当项目是servlet容器下的web项目时,这个配置类才生效@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET)// 当CharacterEncodingFilter类存在时,这个配置类才生效@ConditionalOnClass(CharacterEncodingFilter.class)// 当spring.http.encoding.enabled这个环境变量存在且值不为false时,这个配置类才生效// @ConditionalOnProperty这个注解的玩法很多@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true)public class HttpEncodingAutoConfiguration &#123; private final HttpProperties.Encoding properties; public HttpEncodingAutoConfiguration(HttpProperties properties) &#123; this.properties = properties.getEncoding(); &#125; @Bean // 当容器中没有CharacterEncodingFilter类型的实例时,这个方法生效 @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; @Bean public LocaleCharsetMappingsCustomizer localeCharsetMappingsCustomizer() &#123; return new LocaleCharsetMappingsCustomizer(this.properties); &#125; private static class LocaleCharsetMappingsCustomizer implements WebServerFactoryCustomizer&lt;ConfigurableServletWebServerFactory&gt;, Ordered &#123; private final HttpProperties.Encoding properties; LocaleCharsetMappingsCustomizer(HttpProperties.Encoding properties) &#123; this.properties = properties; &#125; @Override public void customize(ConfigurableServletWebServerFactory factory) &#123; if (this.properties.getMapping() != null) &#123; factory.setLocaleCharsetMappings(this.properties.getMapping()); &#125; &#125; @Override public int getOrder() &#123; return 0; &#125; &#125;&#125; 3. SpringBoot启动过程0. 总体流程概述1. 创建启动类1.1. 创建启动类 1234567@SpringBootApplicationpublic class Bootstrap &#123; public static void main(String[] args) &#123; // 调用SpringApplication静态方法run为入口 SpringApplication.run(Bootstrap.class, args); &#125;&#125; 1.2. 跟踪进入org.springframework.boot.SpringApplication#run(java.lang.String...) 123456789101112131415161718192021222324252627282930313233343536373839 /** * Static helper that can be used to run a &#123;@link SpringApplication&#125; from the * specified sources using default settings and user supplied arguments. * @param sources the sources to load * @param args the application arguments (usually passed from a Java main method) * @return the running &#123;@link ApplicationContext&#125; */ public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 进入构造器,会有初始化过程 return new SpringApplication(sources).run(args); &#125;/** * Create a new &#123;@link SpringApplication&#125; instance. The application context will load * beans from the specified sources (see &#123;@link SpringApplication class-level&#125; * documentation for details. The instance can be customized before calling * &#123;@link #run(String...)&#125;. * @param sources the bean sources * @see #run(Object, String[]) * @see #SpringApplication(ResourceLoader, Object...) */public SpringApplication(Object... sources) &#123; // 初始化 initialize(sources);&#125;@SuppressWarnings(&#123; \"unchecked\", \"rawtypes\" &#125;)private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; // 推断是否为web环境 this.webEnvironment = deduceWebEnvironment(); // 获取所有的配置在spring.factores中的ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 获取所有的配置在spring.factores中的 ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 推断启动类,我们这里就是Bootstrap.class this.mainApplicationClass = deduceMainApplicationClass();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 运行spring应用,创建一个新的spring上ApplicationContext下文环境 * Run the Spring application, creating and refreshing a new * &#123;@link ApplicationContext&#125;. * @param args the application arguments (usually passed from a Java main method) * @return a running &#123;@link ApplicationContext&#125; */public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 加载java的AWT图形化相关的系统配置变量, 可以忽略 configureHeadlessProperty(); // 实例化spring.factories中配置的所有SpringApplicationRunListener并返回到 listeners 中 // SpringApplicationRunListeners内部是一个List&lt;SpringApplicationRunListener&gt; SpringApplicationRunListeners listeners = getRunListeners(args); // 启动应用监听器,回调starting方法, // spring应用进行到某一阶段时会广播通知所有的监听器, 监听器的方法就会被回调执行 listeners.starting(); try &#123; // 包装命令行启动参数 也就是 Bootstrap.main(String[] args)中的args // 我们可以通过命令号启动应用 java -jar demo.jar --server.port=8989 这个server.port=8989就是启动参数 // 他可以接受多个启动参数,包括指定profile [dev/test/pre/prod] ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 准备应用环境, 包括读取系统环境变量,yml,properties等配置文件, // 同时回调listeners的environmentPrepared方法 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 打印Banner 也就是我们启动应用时控制台打印出的Spring 的 logo了,这个也可以自定义 // 有兴趣的自行百度自定义springboot banner, 我不喜欢这些花里胡哨的东西(才怪) Banner printedBanner = printBanner(environment); // 创建上下文,决定创建web的ioc还是普通的ioc context = createApplicationContext(); // 实例化配置在spring.factories中的FailureAnalyzer应用启动失败的分析器,并返回 analyzers = new FailureAnalyzers(context); // 上下文准备,会广播通知listeners回调contextPrepared方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新上下文 refreshContext(context); // 上下文刷新后的一些擦屁股工作 afterRefresh(context, applicationArguments); // 容器已经创建和刷新完成,广播通知listeners回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; // 到此如果没有启动报错,那你的应用就已经启动完成了 return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 我们要说的是springboot自动配置, 但是我写这些做什么呢? 因为自动配置就是在上面的一些步骤中完成的,下面继续 总结一下,应用启动过程经历了哪些阶段呢. getRunListeners(...)获取SpringApplicationRunListener监听器 prepareEnvironment(...)应用环境准备 createApplicationContext(...)创建应用上下文 prepareContext(...)上下文准备 refreshContext(...)刷新上下文 afterRefresh(...)上下文刷新完后的一些收尾工作 2. prepareEnvironment容器环境准备阶段 123456789101112131415161718192021private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // 存在就获取环境,不存在就创建环境 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 环境配置: // 1. 收集用户自定义的配置和系统环境变量 // 2. 收集Profiles信息 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 遍历listeners 调用 environmentPrepared listeners.environmentPrepared(environment); // 把环境绑定到SpringApplication, 实际上是增加了一个K-V键值对==&gt; // \"spring.main\" = SpringApplication的Bindable对象 bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; // 推断项目的环境,并把当前环境转换成项目所需要的环境 environment = new EnvironmentConverter(getClassLoader()) .convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 3. createApplicationContext根据是否为web环境来决定创建一个web应用或者非web应用的上下文 1234567891011121314151617181920212223242526272829protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; // 根据环境来创建对应的上下文, 下面的值的包名我省略了 //DEFAULT_CONTEXT_CLASS: \"AnnotationConfigApplicationContext\"; //DEFAULT_SERVLET_WEB_CONTEXT_CLASS: \"AnnotationConfigServletWebServerApplicationContext\"; //DEFAULT_REACTIVE_WEB_CONTEXT_CLASS: \"AnnotationConfigReactiveWebServerApplicationContext\"; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Unable create a default ApplicationContext, \" + \"please specify an ApplicationContextClass\", ex); &#125; &#125; // 创建并返回应用上下文 return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 4. prepareContext上下文的一些成员变量初始化工作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); // 做了三件事: // 1. 注册beanNameGenerator到Context中 // 2. 为Context设置资源加载器resourceLoader // 3. 为Context设置类加载器 // 4. 为Context设置ConversionService, ConversionService是提供值转换服务的 postProcessApplicationContext(context); // 触发ApplicationContextInitializer初始化方法,初始化上下文 applyInitializers(context); // 遍历触发listener的contextPrepared方法 listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans 把命令行参数添加到ioc中 context.getBeanFactory().registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(\"springBootBanner\", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // Load the sources Set&lt;Object&gt; sources = getSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); // 加载上下文: // 1. 实例化 BeanDefinitionLoader // 2. 执行load()方法 // 2.1 加载启动类上的注解、解析注解元信息、 load(context, sources.toArray(new Object[sources.size()])); // 遍历listener调动contextLoaded上下文加载完成方法 listeners.contextLoaded(context);&#125;// load()最终会到AnnotatedBeanDefinitionReader#doRegisterBean方法,看看做了些啥&lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &#123; // 分析启动类的注解的信息 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass); if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; // Supplier无参数有返回值的接口方法 abd.setInstanceSupplier(instanceSupplier); //检查scope，实例中没有指定，默认是singleton ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); ////获取bean的名字，这里是启动类 String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); // 对于是否是@lazy，是否使用了@primary AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); if (qualifiers != null) &#123; for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &#123; customizer.customize(abd); &#125; // 根据注解信息生产BeanDefinition BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); // 根据Bean的作用域，创建相应的代理对象 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); // 将Bean加入到beanDefinitionMap中 BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);&#125; 5. refreshContext最终会定位到org.springframework.context.support.AbstractApplicationContext#refresh方法, 除此之外最后还会注册ShutdownHook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 1. 清除缓存 // 2. 初始化所有在上下文环境中的占位符配置 // 3. 校验所有required的配置是否已经被解析完成 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 通知子类刷新Bean工厂 // 1. 为BeanFactory设置了一个ID, 就是在yaml文件中配置的spring.application.name ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 1. 为BeanFactory设置类加载器 // 2. 设置表达式解析器StandardBeanExpressionResolver // 3. 设置配置文件注册器ResourceEditorRegistrar // 4. 设置Bean的后置处理器 // 不一一列举了,下面看图 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 1. 添加子类自定义的Bean后置处理器 // 2. 扫描basePackage下的类,按照需求加入到容器 // 3. 把带有Spring注解的类加入到容器 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用IOC容器中所有的Bean工厂处理器 BeanDefinitionRegistryPostProcessor、BeanFactoryPostProcessor // 1. 配置类后置处理器 ConfigurationClassPostProcessor 解析 配置类 转换为 BeanDefinition // 1.1 @ComponentScan注解配置的basePackage // 1.2 @Import注解导入的配置类 // 1.3 @ImportResource注解导入的xml文件 // 1.4 @Bean注解的方法 // 1.5 @PropertySource注解导入的.properties配置文件 // 1.6 处理所有的SpringBoot配置类 // 2. 后置处理器太多了, 功能列不过来了 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册所有 用于拦截Bean创建的BeanProcessor registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化MessageSource, 供i18n用的 initMessageSource(); // Initialize event multicaster for this context. // 初始化事件广播器, 在这之前的listener都是遍历直接调用的方法, 从这里开始,listener会通过接受广播的方式回调 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化其他在特殊容器中的Bean,比如父子容器 // 比如在web容器中会初始化TomcatWebServer onRefresh(); // Check for listener beans and register them. // 检查并注册listener到广播器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 初始化所有的非懒加载的单例对象 // 需要注意的是在AbstractAutowireCapableBeanFactory#createBean(String, RootBeanDefinition, Object[]) // 这个方法中有一段如下代码 // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 方法注释的意思是给BeanPostProcessor一个返回目标接口的代理对象的机会, 具体可查阅和 // InstantiationAwareBeanPostProcessor相关的资料 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // 完成刷新: // 1. 清除各种缓存 // 2. 初始化生命周期处理器 // 3. 发布ContextRefreshedEvent事件 // 4. 启动WebServer // 5. 发布ServletWebServerInitializedEvent时间 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; prepareBeanFactory 6. afterRefresh这个阶段SpringBoot没有具体的实现,留给开发者自定义子类去实现 12345678/** * Called after the context has been refreshed. * @param context the application context * @param args the application arguments */protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) &#123;&#125; 4. 附件@ConditionalOnProperty注解一、@ConditionalOnProperty 结构1234567891011121314151617181920212223@Retention(RetentionPolicy.RUNTIME) @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Documented @Conditional(&#123;OnPropertyCondition.class&#125;) public @interface ConditionalOnProperty &#123; //数组，获取对应property名称的值，不可与name同时使用 String[] value() default &#123;&#125;; //property名称的前缀，可有可无 String prefix() default \"\"; //数组，property完整名称或部分名称（可与prefix组合使用，组成完整的property名称），不可与value同时使用 String[] name() default &#123;&#125;; //可与name组合使用，比较获取到的属性值与havingValue给定的值是否相同，相同才加载配置 String havingValue() default \"\"; //缺少该property时是否可以加载。如果为true，没有该property也会正常加载；反之报错 boolean matchIfMissing() default false; //是否可以松散匹配 boolean relaxedNames() default true;&#125; 二、@ConditionalOnProperty 用法1. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(value = \"object.pool.size\") public class ObjectPoolConfig &#123; &#125; yml配置如下：12345678910object.pool: size: true //正常 object.pool: size: //正常，空字符时 object.pool: size: false //失败 object.pool: size: null //正常 object.pool: size: 30 //正常 2. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(value = \"object.pool.size\",havingValue=\"30\") public class ObjectPoolConfig &#123; &#125; yml配置如下：123456object.pool: size: 1234 //失败,与havingValue给定的值不一致 object.pool: size: false //失败,与havingValue给定的值不一致 object.pool: size: 30 //正常 当且仅当配置文件中的Value和havingValue的值一致时才加载成功3. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\") public class ObjectPoolConfig &#123; &#125; yml配置如下：123456object.pool: size: 1234 //失败,与havingValue给定的值不一致object.pool: size: false //失败,与havingValue给定的值不一致object.pool: size: 30 //正常 4. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\",matchIfMissing = true) public class ObjectPoolConfig &#123; &#125; yml不配置相关参数,正常启动，当 matchIfMissing = true 时，即使没有 object.pool.size 属性也会加载正常5. 有如下spring boot代码和yml配置 123456@Configuration //matchIfMissing的缺省值为false@ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\",matchIfMissing = false) public class ObjectPoolConfig &#123; &#125; yml配置如下： yml不配置相关参数,加载失败,当 matchIfMissing = false 时，必须要有对应的属性配置123456object.pool: size: 1234 //失败,与havingValue给定的值不一致object.pool: size: false //失败,与havingValue给定的值不一致object.pool: size: 30 //正常 6. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = &#123;\"size\",\"timeout\"&#125;) //name中的属性需要两个都存在且都不为false才会加载正常 public class ObjectPoolConfig &#123; &#125; yml配置如下：123456789object.pool: timeout: true size: 1234 //正常object.pool: timeout: true size: false //失败,两个值都不能为 falseobject.pool: timeout: true size: true //正常 7. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = &#123;\"size\",\"timeout\"&#125;,havingValue=\"false\") public class ObjectPoolConfig &#123; &#125; .yml配置如下：123object.pool: timeout: false size: false //正常 8. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\", name = &#123;\"size\", \"timeout\"&#125;, havingValue = \"123\", matchIfMissing = true) public class ObjectPoolConfig &#123; &#125; yml配置如下：123456789object.pool: timeout: 123 size: false //失败,和havingValue的值不一致object.pool: timeout: 123 size: 1234 //失败,和havingValue的值不一致object.pool: timeout: 123 size: 123 //正常 matchIfMissing = true , 不配置参数也正常 三、 @ConditionalOnProperty 应用场景 通过 @ConditionalOnProperty 来控制 Configuration 是否生效","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"}]},{"title":"MySQL的一些遗忘点","slug":"MySQL的一些遗忘点","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-19T10:33:48.724Z","comments":true,"path":"2018/10/31/MySQL的一些遗忘点/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/MySQL的一些遗忘点/","excerpt":"","text":"一、Group By 和 Order By 一起使用order by 的列，必须是出现在group by 子句里的列 1234SELECT MAX( `id` ) FROM `order`GROUP BY `order_code` , `created_at`-- order by 的列，必须是出现在 group by 子句里的列 ORDER BY `created_at` DESC; 二、忘记root密码具体步骤如下： 修改MySQL的配置文件（默认为/etc/my.cnf）,在[mysqld]下添加一行skip-grant-tables 保存配置文件后，重启MySQL服务 service mysqld restart 再次进入MySQL命令行 mysql -uroot -p,输入密码时直接回车，就会进入MySQL数据库了，这个时候按照常规流程修改root密码即可。依次输入： use mysql; 更改数据库UPDATE user SET authentication_string=password(“passwd”) WHERE USER= ‘root’; 重设密码,注意我用的是5.7.22的数据库密码存储在authentication_string字段, 之前有的版本存储在password字段,具体看情况吧flush privileges; 刷新MySQL的系统权限相关表，以防止更改后拒绝访问；或或者重启MySQL服务器 密码修改完毕后，再按照步骤1中的流程，删掉配置文件中的那行，并且重启MySQL服务，新密码就生效了。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://blog.milk4j.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.milk4j.com/tags/mysql/"}]},{"title":"SpringBoot Junit单元测试","slug":"SpringBoot Junit单元测试","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-03T08:51:50.530Z","comments":true,"path":"2018/10/31/SpringBoot Junit单元测试/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot Junit单元测试/","excerpt":"","text":"一、JUnit中的注解 @BeforeClass：针对所有测试，只执行一次，且必须为static void @Before：初始化方法，执行当前测试类的每个测试方法前执行。 @Test：测试方法，在这里可以测试期望异常和超时时间 @After：释放资源，执行当前测试类的每个测试方法后执行 @AfterClass：针对所有测试，只执行一次，且必须为static void @Ignore：忽略的测试方法（只在测试类的时候生效，单独执行该测试方法无效） @RunWith:可以更改测试运行器 ，缺省值 org.junit.runner.Runner 一个单元测试类执行顺序为： @BeforeClass –&gt; @Before –&gt; @Test –&gt; @After –&gt; @AfterClass 每一个测试方法的调用顺序为： @Before –&gt; @Test –&gt; @After","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"Junit","slug":"Junit","permalink":"https://blog.milk4j.com/tags/Junit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"}]},{"title":"SpringBoot+H2+Mybatis单元测试整合和坑","slug":"SpringBoot+H2+Mybatis单元测试整合和坑","date":"2018-10-31T05:59:00.000Z","updated":"2018-10-31T08:46:11.871Z","comments":true,"path":"2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","excerpt":"","text":"Maven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 配置文件1234567891011spring: datasource: driver-class-name: org.h2.Driver url: jdbc:h2:mem:testdb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false username: root # 随便填 password: 123456 # 随便填 schema: classpath:db/schema.sql # 建表SQL语句 data: classpath:db/data.sql # 数据导入SQL语句 platform: h2 profiles: active: test 然后在src/test/resources文件夹下面新建一个文件夹db ,然后新建 schema.sql和data.sql schema.sql 文件是建表语句,内容不能为空,否则报错 data.sql文件是数据导入的SQL语句,内容不能为空,否则报错 注意事项一、不支持表级别的Comment 建表SQL如下： 12345678CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除') ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 列名后面的COMMENT是支持的，但是最后面的 ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= &#39;区域路线信息列表&#39; 中的COMMENT不支持。删掉后面的COMMENT即可。 二、只支持最普通的引索结构,不支持BTREE引索结构 123456789CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除', PRIMARY KEY (`Id`) USING BTREE,) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 这种情况去掉 USING BTREE ,使用普通的引索就好了 三、插入语句的单引号中的\\’不支持 有如下SQL，其中一个字段存的里面带有单引号： 12345678910111213141516INSERT INTO `testTable`VALUES ( '1', '部门权限', 'LoginName=\\'&#123;1&#125;\\'', '1', '2', NULL, NULL, '2016-05-27 14:30:49', '1', '1', NULL, '1' ); MySQL支持双引号包含字符串，可以把内容中包含的单引号改为双引号，但其他情况可能会涉及到业务调整。另外，不能将包含字符串的单引号改为双引号，H2会把双引号中的内容当做列名处理。 四、H2 的 UNIQUE KEY是数据库级别的 H2 的 UNIQUE KEY不是表级别的，MySQL是表级别的，转为H2后容易出现UNIQUE KEY重复。删掉UNIQUE KEY或者修改KEY的名称即可。 五、无法使用子查询 目前没有办法解决,尽量避免使用吧","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"},{"name":"h2","slug":"h2","permalink":"https://blog.milk4j.com/tags/h2/"}]},{"title":"我的ElasticSearch命令简记","slug":"我的ElasticSearch命令简记","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-06T11:59:22.121Z","comments":true,"path":"2018/10/31/我的ElasticSearch命令简记/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/我的ElasticSearch命令简记/","excerpt":"","text":"常用简单命令条件删除数据1234567# 条件删除curl -XPOST \"http://localhost:9200/opt-log-index/opt-log-type/_delete_by_query\" -H 'Content-Type: application/json' -d'&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;&#125;' 删除index和数据1curl -XDELETE \"http://localhost:9200/opt-log-index\" 获取 mapping 结构12345# 获取所有的index的mappingcurl -XGET \"http://localhost:9200/_mapping\"# 获取指定的index的mapping结构curl -XGET \"http://localhost:9200/opt-log-index/_mapping\" 创建index和mapping123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 创建index和mappingcurl -XPUT \"http://localhost:9200/opt-log-index\" -H 'Content-Type: application/json' -d'&#123; \"settings\":&#123; \"analysis\":&#123; \"analyzer\":&#123; \"ik\":&#123; \"tokenizer\":\"ik_max_word\" &#125; &#125; &#125; &#125;, \"mappings\":&#123; \"opt-log-type\":&#123; \"properties\":&#123; \"id\":&#123; \"type\":\"keyword\" &#125;, \"operator\":&#123; \"type\":\"keyword\" &#125;, \"role\":&#123; \"type\":\"keyword\" &#125;, \"operatorName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"remark\":&#123; \"type\":\"keyword\" &#125;, \"operateType\":&#123; \"type\":\"keyword\" &#125;, \"txId\":&#123; \"type\":\"long\" &#125;, \"schemaName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"tableName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"afterData\":&#123; \"type\":\"keyword\" &#125;, \"beforeData\":&#123; \"type\":\"keyword\" &#125;, \"changeFields\":&#123; \"type\":\"keyword\" &#125;, \"createdAt\":&#123; \"type\":\"date\", \"format\":\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" &#125;, \"updatedAt\":&#123; \"type\":\"date\", \"format\":\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" &#125; &#125; &#125; &#125;&#125;' 查询数据查询所有数据12345678910111213141516171819curl -XGET \"http://localhost:9200/opt-log-index/opt-log-type/_search\" -H 'Content-Type: application/json' -d'&#123; \"from\": 0, \"size\": 20, \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match_all\": &#123;&#125; &#125; ] &#125; &#125;, \"_source\": &#123; \"excludes\": [ \"beforeData\" ] &#125;&#125;' 精准匹配1234567891011121314151617181920212223242526curl -XGET \"http://localhost:9200/opt-log-index/opt-log-type/_search\" -H 'Content-Type: application/json' -d'&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"term\": &#123; \"tableName\": \"parana_item_detail\" &#125; &#125; ] &#125; &#125;, \"_source\": &#123; \"excludes\": [ \"beforeData\",\"schemaName\" ] &#125;, \"sort\": [ &#123; \"createdAt\": &#123; \"order\": \"desc\" &#125; &#125; ]&#125;'","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/tags/elasticsearch/"}]},{"title":"Kotlin在IntelliJ Idea中无法生成 spring-configuration-metadata.json 文件","slug":"用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件","date":"2018-09-05T11:12:09.000Z","updated":"2018-10-31T01:32:08.944Z","comments":true,"path":"2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","link":"","permalink":"https://blog.milk4j.com/2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","excerpt":"","text":"问题描述在百度搜索关键词,搜索到了 Stack Overflow 有相关问题 spring-configuration-metadata.json file is not generated in IntelliJ Idea for Kotlin @ConfigurationProperties class 原文链接: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko 按照里面的方法试了一下,失败了,然后继续百度,在spring-boot的官方文档中找到了相关线索, 直达链接: https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties 在spring官方文档中找到了kotlin的官方示例,链接地址: https://kotlinlang.org/docs/reference/kapt.html#using-in-maven 下面是我参考上面的文档所得出来的可用方案 解决方案一、添加插件在pom文件中添加插件,没有写版本号是因为项目继承了spring-boot-starter-parent 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;proc&gt;none&lt;/proc&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- Replacing default-compile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;!-- Replacing default-testCompile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-testCompile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;configuration&gt; &lt;args&gt; &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt; &lt;/args&gt; &lt;compilerPlugins&gt; &lt;plugin&gt;spring&lt;/plugin&gt; &lt;/compilerPlugins&gt; &lt;jvmTarget&gt;$&#123;java.version&#125;&lt;/jvmTarget&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;kapt&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;kapt&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sourceDirs&gt; &lt;sourceDir&gt;src/main/kotlin&lt;/sourceDir&gt; &lt;sourceDir&gt;src/main/java&lt;/sourceDir&gt; &lt;/sourceDirs&gt; &lt;annotationProcessorPaths&gt; &lt;!-- Specify your annotation processors here. --&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;test-compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt; &lt;version&gt;1.2.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt;&lt;/plugins&gt; 二、使用插件生成我之前也是使用了同样的插件,但是始终生成不出来文件,直到看了kotlin官方文档我才发现有这么一句话 文字的意思是: “请注意，kapt仍然不支持IntelliJ IDEA自己的构建系统。当你想要重新运行注释处理器时，可以从“Maven Projects”工具栏启动构建。” 很是坑爹啊,你也不标红也不加粗是想怎样啊 好了,那就按照他说的做吧, 双击下面的插件按钮就可以生产spring-configuration-metadata.json文件了 参考文档: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties &lt;https://kotlinlang.org/docs/reference/kapt.html","categories":[{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/categories/kotlin/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"},{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/tags/kotlin/"}]},{"title":"Docker使用","slug":"【02】Docker 使用","date":"2018-08-11T14:59:00.000Z","updated":"2018-12-22T06:26:35.823Z","comments":true,"path":"2018/08/11/【02】Docker 使用/","link":"","permalink":"https://blog.milk4j.com/2018/08/11/【02】Docker 使用/","excerpt":"","text":"Docker使用一. docker使用 1. docker ps 查看运行中的容器 2. docker images 查看docker镜像 3. docker rm id(容器id) 删除容器（容器id可以通过docker ps查看，容器必须停止后才能删除） 3.1 删除全部的容器 docker rm docker ps -a -q 4. docker stop id(容器id) 停止容器运行 5. docker rmi id(镜像id) 删除镜像 6. docker pull ubuntu:16.04(镜像名称:版本号) 下载镜像 7. docker run -it ubuntu:16.04 创建并运行容器容器 -t 表示在新容器内指定一个伪终端或终端 -i 表示允许我们对容器内的 (STDIN) 进行交互 -p 指定映射端口 -d 在后台运行容器并打印容器ID 7.1 docker run -dit ubuntu:16.04 创建并后台运行容器 7.2 docker run -ditp 8080:8080（主机端口:容器端口） ubuntu:16.04 创建并后台运行容器且映射容器的端口 8. docker attach id(容器id) 进入正在运行中的容器环境 9. 退出容器 9.1 exit 直接退出容器并终止容器运行 9.2 [ctrl+p]+[ctrl+q]（快捷键） 退出容器，但是不会终止容器运行 10. docker commit -m’版本标识’ id(容器id) ubuntu:16.04(镜像与版本号) 提交镜像且生成镜像（可以通过该命令把搭建好的容器打包成一个新的镜像或者覆盖原镜像（即是修改原镜像内容，生成的镜像名与版本号相同就可以直接覆盖））","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"docker 安装 nginx","slug":"Docker 安装 nginx","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:29:12.628Z","comments":true,"path":"2018/08/05/Docker 安装 nginx/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/Docker 安装 nginx/","excerpt":"","text":"Docker 安装 nginx方式一：通过 pull 仓库镜像一、下载镜像1docker pull nginx 二、使用镜像创建容器1234567891011121314151617181920212223242526cd ~mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf#www目录将映射为nginx容器配置的虚拟目录#logs目录将映射为nginx容器的日志目录#conf目录里的配置文件将映射为nginx容器的配置文件#找一份默认的 nginx.conf 配置文件放在 conf 目录下,否则下面启动会报错docker run -p 80:80 --name web -v $PWD/www:/www -v $PWD/logs:/wwwlogs -d nginxdocker cp web:/etc/nginx/nginx.conf #删除容器后再运行下面的命令docker run -p 80:80 --name web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/conf/servers:/etc/nginx/conf.d -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~#docker inspect [容器名|id]docker inspect mynginx 命令说明： -p 80:80：将容器的80端口映射到主机的80端口 –name web：将容器命名为web -v $PWD/www:/www：将主机中当前目录下的www挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf：将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs：将主机中当前目录下的logs挂载到容器的/wwwlogs 方式二：通过 Dockerfile构建构建准备工作123mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/confcd ~/nginxvi Dockerfile 在 Dockerfile 中输入如下内容：123456789101112131415161718#指定使用那个基础镜像FROM centosMAINTAINER ginkgoLABEL Discription=\"基于centos的nginx镜像\" version=\"1.0\"WORKDIR /usr/local/srcRUN yum install -y wgetRUN wget http://nginx.org/download/nginx-1.8.0.tar.gzRUN tar -zxvf nginx-1.8.0.tar.gzWORKDIR nginx-1.8.0#安装nginx所依赖的包RUN yum -y install gcc-c++RUN yum -y install pcre pcre-develRUN yum -y install zlib zlib-develRUN yum -y install openssl openssl-devel libssl-devRUN ./configureRUN makeRUN make installEXPOSE 80 通过Dockerfile 构建一个镜像1234# -t 镜像名 , \".\" 是Dockerfile 所在的目录，可以使用绝对路径docker build -t ginkgo/nginx .#查看镜像docker images 构建|运行容器1234567891011121314151617#找一份默认的 nginx.conf 配置文件放在 ~/nginx/conf 目录下,否则下面启动会报错docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~docker inspect [容器名|id]","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.milk4j.com/tags/nginx/"}]},{"title":"docker 安装redis","slug":"Docker 安装 redis","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:29:46.888Z","comments":true,"path":"2018/08/05/Docker 安装 redis/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/Docker 安装 redis/","excerpt":"","text":"Docker 安装 Redis下载镜像|创建运行容器123docker pull redis#创建|运行容器docker run -d --name=myredis -p 6379:6379 redis 其他容器与 redis 容器通讯nginx容器需要与redis容器通信的话首先要知道它的ip地址，但是每次都手工获取容器的ip地址显然是一件繁琐的事情，于是我们需要修改容器的启动方式，加–link参数，建立其他容器与redis容器之间的联系。 删除掉之前的容器，现在重新修改 nginx容器的启动方式： 1234# 使用 pwd 变量cd ~/nginx &amp;&amp; docker run -it -p 80:80 --name=mynginx --link=myredis:db -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginxdocker run -it -p 80:80 --name=web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx 这次加入了两个参数： -v /code:/usr/src/app 表示把宿主机上的/code目录挂载到容器内的/usr/src/app目录，可以通过直接管理宿主机上的挂载目录来管理容器内部的挂载目录。 –link=redis:db 表示把redis容器以db别名与该容器建立关系，在该容器内以db作为主机名表示了redis容器的主机地址。 现在进入到其他容器，通过ping命令确认nginx容器能访问到redis容器： 1234567$ ping dbPING db (192.168.32.12): 56 data bytes64 bytes from 192.168.32.12: icmp_seq=0 ttl=64 time=0.463 ms64 bytes from 192.168.32.12: icmp_seq=1 ttl=64 time=0.086 ms#ping 命令找不到$ apt-get update$ apt-get install inetutils-ping Redis 集群搭建12345#创建 redis master 容器$ docker run -d --name=redis_master -p 6380:6379 redis#两个 redis slave 容器$ docker run -d --name=redis_slave_1 -p 6380:6379 --link=redis_master:master redis redis-server --slaveof master 6379$ docker run -d --name=redis_slave_2 -p 6381:6379 --link=redis_master:master redis redis-server --slaveof master 6379 现在写入到Redis主节点的数据都会在从节点上备份一份数据。 为了防止 master 宕机，再由Sentinel集群根据投票选举出slave节点作为新的master。 下面为Sentinel编写Dockerfile，在redis镜像的基础上作改动： 12345FROM redis:latestCOPY run-sentinel.sh /run-sentinel.shCOPY sentinel.conf /etc/sentinel.confRUN chmod +x /run-sentinel.shENTRYPOINT [\"/run-sentinel.sh\"] Sentinel的配置文件： 123456port 26379dir /tmpsentinel monitor master redis-master 6379 2sentinel down-after-milliseconds master 30000sentinel parallel-syncs master 1sentinel failover-timeout master 180000 run-sentinel.sh： 12#!/bin/bashexec redis-server /etc/sentinel.conf --sentinel 构建出Sentinel的镜像文件，容器运行的方式类似于redis： 123$ docker run -d --name=sentinel_1 --link=redis_master:redis-master [build_sentinel_image]$ docker run -d --name=sentinel_2 --link=redis_master:redis-master [build_sentinel_image]$ docker run -d --name=sentinel_3 --link=redis_master:redis-master [build_sentinel_image] 这下Sentinel的容器也搭建起来了，应用的结构图如下：","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"},{"name":"redis","slug":"redis","permalink":"https://blog.milk4j.com/tags/redis/"}]},{"title":"Docker构建Epics","slug":"Docker构建Epics","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:30:41.897Z","comments":true,"path":"2018/08/05/Docker构建Epics/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/Docker构建Epics/","excerpt":"","text":"Docker构建Epics基于MySQL:5.7.24镜像123456789101112131415docker pull mysql:5.7.24docker run -p 3307:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7.24docker exec -it mysql /bin/bash# mysql 镜像是基于debian发行版Linux系统apt-get update # 更新源apt-get install build-essential # 这个命令最方便，把所有要安装的全部安装好：build-essential是c语言的开发包，包含了gcc make gdb和libc函数库等很多工具。# 保证perl gcc g++ c++ 都已安装which perl which gccwhich g++which c++# 编译中可能出现缺少 readline.hapt-get install libreadline-dev 准备安装12345678910111213141516171819202122232425262728cd ~mkdir epics cd epicsmkdir extensions # 存放扩展程序cd /usr/srcwget https://epics.anl.gov/download/base/base-3.15.5.tar.gztar -vxzf base-3.15.5.tar.gzln -s base-3.15.5.tar.gz base #创建软连接cd base./startup/EpicsHostArch # 获取系统架构, 我的是linux-x86_64pwd # 输出 /home/parallels/epics/basecd ~vi .bashrc# 添加# export EPICS_HOST_ARCH=linux-x86_64# export HOST_ARCH=linux-x86_64# 上面的linux-x86_64根据系统情况设置，具体参考base/configure/CONFIG_SITE# export EPICS_EXTENSIONS=/home/parallels/epics/extensions# export EPICS_BASE=/home/parallels/epics/basesource .bashrc # 使环境变量生效cd ~/epics/base/startup./EpicsHostArch # 获取系统架构, 我的是linux-x86_64cd ~/epics/base/configurevim CONFIG_SITE# 填写下面几项值 , 下面的值来自于获取系统架构的输出CROSS_COMPILER_TARGET_ARCHS=linux-x86_64CROSS_COMPILER_HOST_ARCHS=linux-x86_64CROSS_COMPILER_RUNTEST_ARCHS=linux-x86_64 安装Python3 1apt-get install python3 安装pip3 1apt-get install python3-pip","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"},{"name":"epics","slug":"epics","permalink":"https://blog.milk4j.com/tags/epics/"}]},{"title":"Epics编译安装","slug":"Epics编译安装","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:31:20.105Z","comments":true,"path":"2018/08/05/Epics编译安装/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/Epics编译安装/","excerpt":"","text":"Epics编译安装我的系统环境 macOS Mojave parallels desktop虚拟机系统: centos 7 linux-x86_64 Epics版本: 3.15.5 下载链接 记一笔:parallels desktop下载的centos7 默认用户名是parallels 密码是需要设置的。软件没有自动设置。密码必须大于8位； 并且无法进行su命令，提示 Authentication failure。 这个问题产生的原因是由于系统默认是没有激活root用户的，需要我们手工进行操作，在命令行界面下，或者在终端中输入如下命令： 1234sudo passwdPassword：你当前的密码Enter new UNIX password：这个是root的密码Retype new UNIX password：重复root的密码 然后会提示成功的信息。 在说明一点，使用su和sudo是有区别的，使用su切换用户需要输入所切换到的用户的密码，而使用sudo则是当前用户的密码。 安装准备12345678910111213141516171819202122232425262728cd ~mkdir epics cd epicsmkdir extensions # 存放扩展程序cd .. wget https://epics.anl.gov/download/base/base-3.15.5.tar.gztar -vxzf base-3.15.5.tar.gzln -s base-3.15.5.tar.gz base #创建软连接cd base./startup/EpicsHostArch # 获取系统架构, 我的是linux-x86_64pwd # 输出 /home/parallels/epics/basecd ~vi .bashrc# 添加# export EPICS_HOST_ARCH=linux-x86_64# export HOST_ARCH=linux-x86_64# 上面的linux-x86_64根据系统情况设置，具体参考base/configure/CONFIG_SITE# export EPICS_EXTENSIONS=/home/parallels/epics/extensions# export EPICS_BASE=/home/parallels/epics/basesource .bashrc # 使环境变量生效cd ~/epics/base/startup./EpicsHostArch # 获取系统架构, 我的是linux-x86_64cd ~/epics/base/configurevim CONFIG_SITE# 填写下面几项值 , 下面的值来自于获取系统架构的输出CROSS_COMPILER_TARGET_ARCHS=linux-x86_64CROSS_COMPILER_HOST_ARCHS=linux-x86_64CROSS_COMPILER_RUNTEST_ARCHS=linux-x86_64 为了确保安装过程顺利 123456# 编译中可能出现缺少 readline.hsudo yum install readline-static.x86_64# 确保环境安装了 g++ c++ gcc perlwhich perl # 输出 /usr/bin/perl表示安装了perl,其他三个类似# 由于我的环境没有g++ 和 c++ ,安装一下sudo yum install gcc gcc-c++ Make安装 123456789101112131415cd ~/epics/base # 回到epics base的根目录make # 下面就是漫长的等待...# 如果没有什么问题就成功了,如果编译报缺失什么文件,安装后再依次执行 # make distclean # make# 我的make过程很顺利,花了大概1分钟,但是我在云主机上花了30多分钟ls # bin configure db dbd documentation html include lib LICENSE Makefile README src startup templatesvi ~/.bashrc# 添加PATH=$PATH:/home/parallels/epics/base/bin/linux-x86_64export PATH# 生效环境变量source ~/.bashrc 创建example软件和IOC环境 12345678910111213141516171819202122232425262728293031323334353637383940cd ~/epicsmkdir -p iocs/examplecd iocscd examplemakeBaseApp.pl -t example examplemakeBaseApp.pl -i -t example examplels# configure exampleApp iocBoot Makefilemake # 等待完成ls# bin configure db dbd exampleApp include iocBoot lib Makefilecd iocBoot/iocexample/ls# envPaths Makefile README st.cmdsudo chmod +x ./st.cmd./st.cmdepics&gt; dblparallels:xxxExampleparallels:compressExampleparallels:calcExampleparallels:calcExample1parallels:calc1parallels:calcExample2parallels:calc2parallels:calcExample3parallels:calc3parallels:aSubExampleparallels:subExampleparallels:aiExampleparallels:aiExample1parallels:ai1parallels:aiExample2parallels:ai2parallels:aiExample3parallels:ai3epics&gt; dbpr parallels:ai1ASG: DESC: Analog input No. 1 DISA: 0DISP: 0 DISV: 1 NAME: parallels:aiExample1RVAL: 0 SEVR: MAJOR STAT: LOLO SVAL: 0TPRO: 0 VAL: 0 开启一个新终端,继续输入 1camonitor parallels:aiExample mac os 安装问题 EXTERN.h 文件缺失:是因为perl的原因, 解决方案 brew install perl-build","categories":[{"name":"epics","slug":"epics","permalink":"https://blog.milk4j.com/categories/epics/"}],"tags":[{"name":"epics","slug":"epics","permalink":"https://blog.milk4j.com/tags/epics/"}]},{"title":"线上系统常用命令","slug":"线上系统常用命令","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:28:21.253Z","comments":true,"path":"2018/08/05/线上系统常用命令/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/线上系统常用命令/","excerpt":"","text":"线上系统常用命令一、日志查找1. 日志内容查询1.1 tail命令一、tail命令语法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455tail [ -f ][ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ]参数解释：-f 该参数用于监视File文件增长。-c Number 从 Number 字节位置读取指定文件-n Number 从 Number 行位置读取指定文件。-m Number 从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。-b Number 从 Number 表示的512字节块位置读取指定文件。-k Number 从 Number 表示的1KB块位置读取指定文件。File 指定操作的目标文件名称上述命令中，都涉及到number，假设不指定，默认显示10行。Number前面可使用正负号，表示该偏移从顶部还是从尾部開始计算。tail可运行文件一般在/usr/bin/下。tail [OPTION]... [FILE]...Print the last 10 lines of each FILE to standard output.With more than one FILE, precede each with a header giving the file name.With no FILE, or when FILE is -, read standard input.Mandatory arguments to long options are mandatory for short options too. -c, --bytes=K output the last K bytes; or use -c +K to output bytes starting with the Kth of each file -f, --follow[=&#123;name|descriptor&#125;] output appended data as the file grows; an absent option argument means 'descriptor' -F same as --follow=name --retry -n, --lines=K output the last K lines, instead of the last 10; or use -n +K to output starting with the Kth --max-unchanged-stats=N with --follow=name, reopen a FILE which has not changed size after N (default 5) iterations to see if it has been unlinked or renamed (this is the usual case of rotated log files); with inotify, this option is rarely useful --pid=PID with -f, terminate after process ID, PID dies -q, --quiet, --silent never output headers giving file names --retry keep trying to open a file if it is inaccessible -s, --sleep-interval=N with -f, sleep for approximately N seconds (default 1.0) between iterations; with inotify and --pid=P, check process P at least once every N seconds -v, --verbose always output headers giving file names --help display this help and exit --version output version information and exitIf the first character of K (the number of bytes or lines) is a '+',print beginning with the Kth item from the start of each file, otherwise,print the last K items in the file. K may have a multiplier suffix:b 512, kB 1000, K 1024, MB 1000*1000, M 1024*1024,GB 1000*1000*1000, G 1024*1024*1024, and so on for T, P, E, Z, Y.With --follow (-f), tail defaults to following the file descriptor, whichmeans that even if a tail'ed file is renamed, tail will continue to trackits end. This default behavior is not desirable when you really want totrack the actual name of the file, not the file descriptor (e.g., logrotation). Use --follow=name in that case. That causes tail to track thenamed file in a way that accommodates renaming, removal and creation. 二、tail命令使用方法演示例子 1、tail -f filename说明：监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C。 2、tail -n 20 filename说明：显示filename最后20行。 3、tail -r -n 10 filename说明：逆序显示filename最后10行。 补充：跟tail功能相似的命令还有：cat 从第一行開始显示档案内容。tac 从最后一行開始显示档案内容。more 分页显示档案内容。less 与 more 相似，但支持向前翻页head 仅仅显示前面几行tail 仅仅显示后面几行n 带行号显示档案内容od 以二进制方式显示档案内容 1.2 more 命令一、more命令语法 1234567891011121314more [options] fileOptions: -d display help instead of ring bell -f count logical, rather than screen lines -l suppress pause after form feed -p do not scroll, clean screen and display text -c do not scroll, display text and clean line ends -u suppress underlining -s squeeze multiple blank lines into one -NUM specify the number of lines per screenful +NUM display file beginning from line number NUM +/STRING display file beginning from search string match -V output version information and exit","categories":[{"name":"常用命令","slug":"常用命令","permalink":"https://blog.milk4j.com/categories/常用命令/"}],"tags":[{"name":"常用命令","slug":"常用命令","permalink":"https://blog.milk4j.com/tags/常用命令/"}]},{"title":"Centos 7 环境构建","slug":"【01】Centos 7 环境构建文档","date":"2018-08-05T14:59:00.000Z","updated":"2018-12-22T06:27:30.197Z","comments":true,"path":"2018/08/05/【01】Centos 7 环境构建文档/","link":"","permalink":"https://blog.milk4j.com/2018/08/05/【01】Centos 7 环境构建文档/","excerpt":"","text":"Centos 7 环境构建目录准备123456789在~目录下建立如下目录结构|-apps |-bin 存放可执行文件 |- cellar 存放安装文件 lib |-data 存放应用数据 |- etc 存放配置文件 |- sbin 存放超管执行文件 |- src 存放源码文件 |- var 存放运行时产生文件，log、pid 12345# 构建目录cd ~mkdir appscd appsmkdir src bin sbin data var cellar etc 环境准备必装软件Git、JDK、Maven、Docker、Nginx、Redis、MySQL、Zookeeper、Node GIT安装1234567891011121314151617181920212223242526272829303132333435363738# 更新 yum 包sudo yum update# 安装 git# 检查是否自带的 gityum list installed | grep git# 如果有，卸载自带的 gityum remove git#安装gccyum install gcc#安装其它所需的包yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel yum install gcc-c++ perl-ExtUtils-MakeMakeryum install autoconf automake libtool# 进入源码目录cd ~/apps/src# 下载 git 源码，使用源码安装wget https://github.com/git/git/archive/v2.17.0.tar.gz# 解压tar zxvf v2.17.0.tar.gzcd git-2.17.0# 配置源码安装make configure./configure --help# 比较有用，下面的配置都是来自于 help ，返回响应省略./configure --prefix=/root/apps/cellar/git --sbindir=/root/apps/sbin/git --bindir=/root/apps/bin/git --sysconfdir=/root/apps/etc/git/git.conf --datadir=/root/apps/data/git -docdir=/root/apps/data/git/doc# make 和 installmake &amp;&amp; make install# 清理 make 文件make cleanmake distclean# 设置环境变量vi /etc/profile#git 添加到文件最后export PATH=\"$PATH:/root/apps/bin/git\"# 生效配置的变量source /etc/profile# 查看版本git --version 配置123456# 创建用户git config --global user.name &quot;你的名字&quot;git config --global user.email &quot;你的邮箱&quot;# 创建秘钥ssh-keygen -t rsa -C &quot;你的邮箱&quot;# 获取公钥，将公钥添加到 git 加入 git 服务器 JDK安装12345678910111213141516171819202122232425262728293031323334353637# 检查并卸载OpenJDK# 检查命令：java -versionrpm -qa | grep java# 卸载 OpenJDKrpm -e --nodeps java-1.8.0-openjdk-headless-debug-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-demo-debug-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-debug-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-devel-debug-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-src-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-demo-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-src-debug-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.171-3.b10.el6_9.x86_64rpm -e --nodeps java-1.8.0-openjdk-devel-1.8.0.171-3.b10.el6_9.x86_64# 下面两个可以不用删rpm -e --nodeps java-1.8.0-openjdk-javadoc-debug-1.8.0.171-3.b10.el6_9.noarchrpm -e --nodeps java-1.8.0-openjdk-javadoc-1.8.0.171-3.b10.el6_9.noarch# 验证删除是否完成java -version# 如果还没有删除，则用yum -y remove去删除他们# 安装# 去官网下载指定版本的 jdk 压缩包解压# 命令介绍：# rpm 管理套件 # -e 删除指定的套件# --nodeps 不验证套件档的相互关联性# 配置环境变量# 安装完成后需要配置一下环境变量，编辑/etc/profile文件：vi /etc/profile# 在文件尾部添加如下配置：export JAVA_HOME=/tools/jdk1.8.0_171export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin# 使变量生效source /etc/profile Maven 安装1234567891011121314# 下载压缩包wget http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz# 版本 apache-maven-3.5.3-bin.tar.gztar -xvf apache-maven-3.5.3-bin.tar.gzmv apache-maven-3.5.3 /usr/local/maven# 文件存放好之后，设置环境变量，vi /etc/profile#写入环境变量export M2_HOME=/usr/local/mavenexport PATH=$PATH:$M2_HOME/bin# 再执行source /etc/profile# 验证mvn -v Docker 安装Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 官方安装文档 方式一：通过 yum 安装 1234567891011121314151617# 通过 uname -r 命令查看你当前的内核版本uname -r# 卸载旧版本(如果安装过旧版本的话)sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine# 安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的sudo yum install -y yum-utils device-mapper-persistent-data lvm2# 设置稳定的镜像，使用国内阿里云的sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 查看哪些 docker 版本可用，都是稳定版yum list docker-ce --showduplicates | sort -r# 安装 dockersudo yum install docker-ce# 安装指定版本使用 sudo yum install docker-ce-&lt;VERSION STRING&gt;# 启动 dockersudo systemctl start docker# 开机启动sudo systemctl enable docker 方式二：通过 rpm 安装包安装 去 https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ 下载你要的版本的 .rpm 文件 指定下载的文件路径去安装 docker 1sudo yum install /path/to/package.rpm 启动 docker 123sudo systemctl start docker# 开机启动sudo systemctl enable docker 设置mirror使用清华源 https://lug.ustc.edu.cn/wiki/mirrors/help/docker 新版的 Docker 使用 /etc/docker/daemon.json 来配置 Daemon ，在该配置文件中加入（没有该文件的话，请先创建一个） 1&#123;\"registry-mirrors\":[\"http://13694f87.m.daocloud.io\"]&#125; 如果 docker 不能 pull ，设置其它镜像参考：http://www.datastart.cn/tech/2016/09/28/docker-mirror.html 最后，通过 hello-world 验证是否安装成功 1sudo docker run hello-world Zookeeper1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 下载wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gztar zxvf zookeeper-3.4.12.tar.gz# 新建zookeeper配置文件,Zookeeper需要一个名为zoo.cfg的配置文件，我们解压后，得到的是官方的示例文件，名为zoo_sample.cfg，这个文件在zookeeper根目录的conf子目录下# 进入 config 文件夹cd zookeeper-3.4.10/conf/cp zoo_sample.cfg zoo.cfg# 用 vim 打开 zoo.cfg 文件并修改其内容为如下： # The number of milliseconds of each tick # zookeeper 定义的基准时间间隔，单位：毫秒 tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. # dataDir=/tmp/zookeeper # 数据文件夹 dataDir=/root/apps/data/zookeeper # 日志文件夹 dataLogDir=/root/apps/var/zookeeper/logs # the port at which the clients will connect # 客户端访问 zookeeper 的端口号 clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1# 用 vim 打开 /etc/ 目录下的配置文件 profile：vim /etc/profile# 添加export ZOOKEEPER_HOME=/root/apps/zookeeperexport PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH# 使 /etc/ 目录下的 profile 文件即可生效：source /etc/profile# 启动zkServer.sh start# 重新启动zkServer.sh restart# 执行命令查看zookeeper状态：zkServer.sh status Nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# gcc 安装# 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装：yum install gcc-c++# PCRE pcre-devel 安装# PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令：yum install -y pcre pcre-devel# zlib 安装# zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。yum install -y zlib zlib-devel# OpenSSL 安装# OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。# nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。yum install -y openssl openssl-devel# nginx 下载wget -c https://nginx.org/download/nginx-1.14.0.tar.gz# 解压# 依然是直接命令：tar -zxvf nginx-1.14.0.tar.gzcd nginx-1.14.0# 配置# 其实在 nginx-1.10.1 版本中你就不需要去配置相关东西，默认就可以了。当然，如果你要自己配置目录也是可以的。# 1.使用默认配置./configure#2.自定义配置（不推荐）./configure \\--prefix=/usr/local/nginx \\--conf-path=/usr/local/nginx/conf/nginx.conf \\--pid-path=/usr/local/nginx/conf/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path=/var/temp/nginx/client \\--http-proxy-temp-path=/var/temp/nginx/proxy \\--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\--http-scgi-temp-path=/var/temp/nginx/scgi# 注：将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录# 编译安装makemake install# 查找安装路径：whereis nginx# 启动、停止nginxcd /usr/local/nginx/sbin/./nginx ./nginx -s stop./nginx -s quit./nginx -s reload# ./nginx -s quit:此方式停止步骤是待nginx进程处理任务完毕进行停止。# ./nginx -s stop:此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。# 查询nginx进程：ps aux|grep nginx# 重启 nginx# 1.先停止再启动（推荐）：# 对 nginx 进行重启相当于先停止再启动，即先执行停止命令再执行启动命令。如下：./nginx -s quit./nginx# 2.重新加载配置文件：# 当 ngin x的配置文件 nginx.conf 修改后，要想让配置生效需要重启 nginx，使用-s reload不用先停止 ngin x再启动 nginx 即可将配置信息在 nginx 中生效，如下：./nginx -s reload# 开机自启动# 即在rc.local增加启动代码就可以了。vi /etc/rc.local# 增加一行 /usr/local/nginx/sbin/nginx# 设置执行权限：chmod 755 rc.local Redis12345678910$ wget http://download.redis.io/releases/redis-4.0.9.tar.gz$ tar xzf redis-4.0.9.tar.gz$ cd redis-4.0.9$ make$ src/redis-server$ src/redis-cliredis&gt; set foo barOKredis&gt; get foo\"bar\" MySQL1、配置YUM源在MySQL官网中下载YUM源rpm安装包：http://dev.mysql.com/downloads/repo/yum/ 1234# 下载mysql源安装包shell&gt; wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm# 安装mysql源shell&gt; yum localinstall mysql57-community-release-el7-8.noarch.rpm 检查mysql源是否安装成功 1shell&gt; yum repolist enabled | grep &quot;mysql.*-community.*&quot; 看到上图所示表示安装成功。可以修改vim /etc/yum.repos.d/mysql-community.repo源，改变默认安装的mysql版本。比如要安装5.6版本，将5.7源的enabled=1改成enabled=0。然后再将5.6源的enabled=0改成enabled=1即可。改完之后的效果如下所示： 2、安装MySQL1shell&gt; yum install mysql-community-server 3、启动MySQL服务1shell&gt; systemctl start mysqld 查看MySQL的启动状态 12345678910shell&gt; systemctl status mysqld● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; disabled; vendor preset: disabled) Active: active (running) since 五 2016-06-24 04:37:37 CST; 35min ago Main PID: 2888 (mysqld) CGroup: /system.slice/mysqld.service └─2888 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid6月 24 04:37:36 localhost.localdomain systemd[1]: Starting MySQL Server...6月 24 04:37:37 localhost.localdomain systemd[1]: Started MySQL Server. 4、开机启动12shell&gt; systemctl enable mysqldshell&gt; systemctl daemon-reload 5、修改root本地登录密码mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改： 1shell&gt; grep &apos;temporary password&apos; /var/log/mysqld.log 12shell&gt; mysql -uroot -pmysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;MyNewPass4!&apos;; 或者 1mysql&gt; set password for &apos;root&apos;@&apos;localhost&apos;=password(&apos;MyNewPass4!&apos;); 注意：mysql5.7默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。否则会提示ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误，如下图所示： 通过msyql环境变量可以查看密码策略的相关信息： 1mysql&gt; show variables like &apos;%password%&apos;; validate_password_policy：密码策略，默认为MEDIUM策略validate_password_dictionary_file：密码策略文件，策略为STRONG才需要validate_password_length：密码最少长度validate_password_mixed_case_count：大小写字符长度，至少1个validate_password_number_count ：数字至少1个validate_password_special_char_count：特殊字符至少1个上述参数是默认策略MEDIUM的密码检查规则。 共有以下几种密码策略： 策略 检查规则 0 or LOW Length 1 or MEDIUM Length; numeric, lowercase/uppercase, and special characters 2 or STRONG Length; numeric, lowercase/uppercase, and special characters; dictionary file MySQL官网密码策略详细说明：http://dev.mysql.com/doc/refman/5.7/en/validate-password-options-variables.html#sysvar_validate_password_policy 修改密码策略在/etc/my.cnf文件添加validate_password_policy配置，指定密码策略 12# 选择0（LOW），1（MEDIUM），2（STRONG）其中一种，选择2需要提供密码字典文件validate_password_policy=0 如果不需要密码策略，添加my.cnf文件中添加如下配置禁用即可： 1validate_password = off 重新启动mysql服务使配置生效： 1systemctl restart mysqld 6、添加远程登录用户默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户： 1mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;yangxin&apos;@&apos;%&apos; IDENTIFIED BY &apos;Yangxin0917!&apos; WITH GRANT OPTION; 7、配置默认编码为utf8修改/etc/my.cnf配置文件，在[mysqld]下添加编码配置，如下所示： 123[mysqld]character_set_server=utf8init_connect=&apos;SET NAMES utf8&apos; 重新启动mysql服务，查看数据库默认编码如下所示： 默认配置文件路径：配置文件：/etc/my.cnf日志文件：/var/log//var/log/mysqld.log服务启动脚本：/usr/lib/systemd/system/mysqld.servicesocket文件：/var/run/mysqld/mysqld.pid Node1、下载源码，你需要下载最新的Nodejs版本，本文以node-v8.11.2.tar.gz为例: 1wget https://npm.taobao.org/mirrors/node/v8.11.2/node-v8.11.2.tar.gz 2、解压源码 1tar zxvf node-v8.11.2.tar.gz 3、 编译安装 1234cd node-v8.11.2./configure --prefix=/root/apps/cellar/nodemakemake install 4、 配置NODE_HOME，进入profile编辑环境变量 1vim /etc/profile 设置nodejs环境变量，在 *export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL* 一行的上面添加如下内容: 123#set for nodejsexport NODE_HOME=/root/apps/cellar/nodeexport PATH=$NODE_HOME/bin:$PATH :wq保存并退出，编译/etc/profile 使配置生效 1source /etc/profile 验证是否安装配置成功 1node -v 输出 版本号表示配置成功 npm模块安装路径 1/root/apps/cellar/node/lib/node_modules/ 可选装ElasticSearch5.x、Kibana5.x、RocketMQ、zsh、MongoDB、Kafka、RabbitMQ、MariaDB","categories":[{"name":"centos","slug":"centos","permalink":"https://blog.milk4j.com/categories/centos/"}],"tags":[{"name":"centos","slug":"centos","permalink":"https://blog.milk4j.com/tags/centos/"}]},{"title":"Arthas 使用文档","slug":"Arthas使用文档","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:47:23.887Z","comments":true,"path":"2018/07/05/Arthas使用文档/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/Arthas使用文档/","excerpt":"","text":"Arthas 使用文档Arthas 是基于 Greys 开发的, 所以命令基本通用 https://alibaba.github.io/arthas/","categories":[{"name":"Arthas","slug":"Arthas","permalink":"https://blog.milk4j.com/categories/Arthas/"}],"tags":[{"name":"Arthas","slug":"Arthas","permalink":"https://blog.milk4j.com/tags/Arthas/"}]},{"title":"Greys 使用手册 [安装]","slug":"Greys 使用手册[安装]","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:32:05.272Z","comments":true,"path":"2018/07/05/Greys 使用手册[安装]/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/Greys 使用手册[安装]/","excerpt":"","text":"Greys 使用手册 [安装]Greys支持在线安装和本地安装两种安装方案，安装即可用，推荐使用在线安装。 在线安装（推荐）请复制以下内容，并粘贴到命令行中。 1curl -sLk http://ompc.oss.aliyuncs.com/greys/install.sh|bash 命令将会下载的启动脚本文件greys.sh到当前目录，你可以放在任何地方或加入到$PATH中 本地安装在某些情况下，目标服务器无法访问远程阿里云主机，此时你需要自行下载greys的安装文件。 下载最新版本的Greys http://ompc.oss.aliyuncs.com/greys/release/greys-stable-bin.zip 解压zip文件后，执行以下命令 12cd greyssh ./install-local.sh 即完成本地安装。 版本管理 多版本管理 从1.7.0.1版本开始，greys.sh支持自动更新，在网络允许的情况下会自动监测远程服务器上是否存在可升级的最新版本。 若网络不可达（网络隔离的环境）则需要进行本地安装。本地安装的greys也一样会纳入到多版本管理识别范围。 大版本兼容性问题 大版本之间不做任何兼容性保障，比如1.7.0.0版本的客户端不保证能访问1.6.0.0启动的服务端。 常见安装问题 下载失败 通常这样的原因你需要检查你的网络是否畅通，核对是否能正确访问这个网址http://ompc.oss.aliyuncs.com/greys/greys.sh 12downloading...download failed! 没有权限 安装脚本首先会将greys文件从阿里云服务器上下载到当前执行脚本的目录，所以你必须要拥有当前目录的写权限。 1permission denied, target directory is not writable.","categories":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/categories/greys/"}],"tags":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/tags/greys/"}]},{"title":"Greys 使用手册 [快速入门]","slug":"Greys 使用手册[快速入门]","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:32:51.097Z","comments":true,"path":"2018/07/05/Greys 使用手册[快速入门]/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/Greys 使用手册[快速入门]/","excerpt":"","text":"Greys 使用手册[快速入门]启动Greys参数说明1./greys &lt;PID&gt;[@IP:PORT] PID：目标Java进程ID（请确保执行当前执行命令的用户必须有足够的权限操作对应的Java进程） IP：目标服务器IP地址，当远程服务开启之后，其他人可以通过指定IP的形式加载到对应目标机器的Java进程中，从而实现远程协助。专门用于解决目标主机账号没有权限，但对方兄弟却非常需要你支援的时候。Greys允许多个用户同时访问，并且各自的命令不会相互干扰执行。 PORT：目标服务器端口号，设计端口号的初心则是希望解决同台机器上存在多个Java进程需要被Greys分析的情况，默认的端口号是3658，如果不做区分则会引起端口冲突。 启动范例 如果不指定IP和PORT，默认是127.0.0.1和3658 1./greys.sh 12345 等价于 1./greys.sh 12345@127.0.0.1 等价于 1./greys.sh 12356@127.0.0.1:3658 会话与任务Greys是一个C/S架构的程序，所以当Client访问到Server时，Server会维护一个session（会话），以及session的心跳、超时机制。事务（Tx）机制则是建立在session的基础上，所有的命令交互都会创建一个事务，并且产生对应的队列进行输出缓冲。 事务伴随着命令的生命周期而存在，命令分两种： 立即返回 立即返回的命令定义是：敲下命令后Server端立即返回最终结果，后续无持续反馈信息，释放Client对输入的锁定，重新开放让用户输入信息，比如version、sc、sm等。 等待中止 等待中止的命令则是需要用户主动输入Ctrl+D完成的命令中止操作。命令执行后无法立即返回最终结果，而是不断的将中间产生的输出源源不断的输出到客户端中，这种命令比如stack、monitor等。 当session关闭时，所有挂在session的事务也会立即被关闭。 重要命令 命令 说明 help 查看命令的帮助文档，每个命令和参数都有很详细的说明 sc 查看JVM已加载的类信息 sm 查看已加载的方法信息 monitor 方法执行监控 trace 渲染方法内部调用路径，并输出方法路径上的每个节点上耗时 ptrace 强化版的trace命令。通过指定渲染路径，并可记录下路径中所有方法的入参、返值；与tt命令联动。 watch 方法执行数据观测 tt 详细用法 方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 stack 输出当前方法被调用的调用路径 version 输出当前目标Java进程所加载的Greys版本号 quit 退出greys客户端 shutdown 关闭greys服务端 reset 重置增强类，将被greys增强过的类全部还原 jvm 查看当前JVM的信息 重要类结构用于watch/tt命令，grovvy表达式的重要数据结构 12345678Advice | +--ClassLoader loader (ClassLoader) +--Class&lt;?&gt; clazz (目标类) +--GaMethod method (目标方法，包括普通方法和构造函数) +--Object[] params (调用参数) +--Object returnObj (返回值) `--Throwable throwExp (抛出异常) 在表达式中直接使用变量名，例如 1watch -b *StringUtil* isEmpty params[0].length()","categories":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/categories/greys/"}],"tags":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/tags/greys/"}]},{"title":"JVM 分析工具概述","slug":"JVM 分析工具概述","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:35:43.775Z","comments":true,"path":"2018/07/05/JVM 分析工具概述/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/JVM 分析工具概述/","excerpt":"","text":"JVM 分析工具概述指令简述 JPS : java process status 查看进程 Jstat: 类装载、内存、垃圾收集、jit编译信息 Jinfo: 实时查看和调整虚拟机的各项参数 Jmap: 打印JVM堆内对象情况,查询Java堆和永久代的详细信息, 使用率, 使用大小 Jhat : jvm heap analysis tool jvm堆分析工具, 内存占用较高 Jstack: 打印线程堆栈信息 Jconsole: 内存监控 visualVm: 可视化的java虚拟机界面 JPS(java process status)12345678910111213141516171819202122232425262728293031323334$ jps# PID | 主函数类名29057 CanalLauncher28849 BrokerStartup31315 Jps28870 rocketmq-console-ng-1.0.0.jar488 QuorumPeerMain30297 RemoteMavenServer$ jps -m # 输出主函数传入的参数29057 CanalLauncher28849 BrokerStartup -n localhost:987628870 rocketmq-console-ng-1.0.0.jar488 QuorumPeerMain /usr/local/etc/zookeeper/zoo.cfg30297 RemoteMavenServer$ jps -q # 只显示PID3132829057288492887048830297$ jps -l # 输出应用程序主类全类名或启动jar包的完整路径名29057 com.alibaba.otter.canal.deployer.CanalLauncher28849 org.apache.rocketmq.broker.BrokerStartup28870 /Users/ginkgo/myapp/rocketmq-console/target/rocketmq-console-ng-1.0.0.jar31335 sun.tools.jps.Jps488 org.apache.zookeeper.server.quorum.QuorumPeerMain30297 org.jetbrains.idea.maven.server.RemoteMavenServer$ jps -v # 列出jvm参数345 Elasticsearch -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=/var/folders/3v/pls8r6nj2jz09pbtmqxcxy700000gn/T/elasticsearch.FXTflx5J -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -Xloggc:logs/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=32 -XX:GCLogFileSize=64m -Des.path.home=/usr/local/Cellar/elasticsearch/6.4.2/libexec -Des.path.conf=/usr/local/etc/elasticsearch -Des.distribution.flavor=oss -Des.distribution.type=tar 详情请参考地址 获取远程服务器 jps 信息jps 支持查看远程服务上的 jvm 进程信息。如果需要查看其他机器上的 jvm 进程，需要在待查看机器上启动 jstatd 服务。 开启 jstatd 服务启动 jstatd 服务，需要有足够的权限。 需要使用 Java 的安全策略分配相应的权限。 创建 jstatd.all.policy 策略文件。 123grant codebase \"file:$&#123;java.home&#125;/../lib/tools.jar\" &#123; permission java.security.AllPermission;&#125;; 启动 jstatd 服务器 12345jstatd -J-Djava.security.policy=jstatd.all.policy -J-Djava.rmi.server.hostname=192.168.31.241-J 参数是一个公共的参数，如 jps、 jstat 等命令都可以接收这个参数。 由于 jps、 jstat 命令本身也是 Java 应用程序， -J 参数可以为 jps 等命令本身设置 Java 虚拟机参数。-Djava.security.policy：指定策略文件-Djava.rmi.server.hostname：指定服务器的ip地址（可忽略） 默认情况下， jstatd 开启在 1099 端口上开启 RMI 服务器。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://blog.milk4j.com/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://blog.milk4j.com/tags/jvm/"}]},{"title":"Greys 使用手册 [watch命令]","slug":"Greys使用手册[watch命令]","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:34:50.788Z","comments":true,"path":"2018/07/05/Greys使用手册[watch命令]/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/Greys使用手册[watch命令]/","excerpt":"","text":"Greys使用手册[watch命令]写到这一篇的时候, 发现了Arthas, 他是基于greys开发的, 有很完善的文档, https://alibaba.github.io/arthas/ 后面就直接参考就好 方法执行数据观测 让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 \bOGNL 表达式进行对应变量的查看。 参数说明watch 的参数比较多，主要是因为它能在 4 个不同的场景观察对象 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 express 观察表达式 condition-express 条件表达式 [b] 在方法调用之前观察 [e] 在方法异常之后观察 [s] 在方法返回之后观察 [f] 在方法结束之后(正常返回和异常返回)观察 [E] 开启正则表达式匹配，默认为通配符匹配 [x:] 指定输出结果的属性遍历深度，默认为 1 这里重点要说明的是观察表达式，观察表达式的构成主要由 \bognl 表达式组成，所以你可以这样写&quot;{params,returnObj}&quot;，只要是一个合法的 ognl 表达式，都能被正常支持。 观察的维度也比较多，主要体现在参数 advice 的数据结构上。Advice 参数最主要是封装了通知节点的所有信息。请参考表达式核心变量中关于该节点的描述。 特殊用法请参考：https://github.com/alibaba/arthas/issues/71 OGNL表达式官网：https://commons.apache.org/proper/commons-ognl/language-guide.html 特别说明： watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后 4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出 这里要注意方法入参和方法出参的区别，有可能在中间被修改导致前后不一致，除了 -b 事件点 params 代表方法入参外，其余事件都代表方法出参 当使用 -b 时，由于观察事件点是在方法调用前，此时返回值或异常均不存在 使用参考观察方法出参和返回值1234567891011121314$ watch demo.MathGame primeFactors \"&#123;params,returnObj&#125;\" -x 2Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 44 ms.ts=2018-12-03 19:16:51; [cost=1.280502ms] result=@ArrayList[ @Object[][ @Integer[535629513], ], @ArrayList[ @Integer[3], @Integer[19], @Integer[191], @Integer[49199], ],] 观察方法入参123456789$ watch demo.MathGame primeFactors \"&#123;params,returnObj&#125;\" -x 2 -bPress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 50 ms.ts=2018-12-03 19:23:23; [cost=0.0353ms] result=@ArrayList[ @Object[][ @Integer[-1077465243], ], null,] 对比前一个例子，返回值为空（事件点为方法执行前，因此获取不到返回值） 同时观察方法调用前和方法返回后1234567891011121314151617181920212223242526272829303132$ watch demo.MathGame primeFactors \"&#123;params,target,returnObj&#125;\" -x 2 -b -s -n 2Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 46 ms.ts=2018-12-03 19:29:54; [cost=0.01696ms] result=@ArrayList[ @Object[][ @Integer[1544665400], ], @MathGame[ random=@Random[java.util.Random@522b408a], illegalArgumentCount=@Integer[13038], ], null,]ts=2018-12-03 19:29:54; [cost=4.277392ms] result=@ArrayList[ @Object[][ @Integer[1544665400], ], @MathGame[ random=@Random[java.util.Random@522b408a], illegalArgumentCount=@Integer[13038], ], @ArrayList[ @Integer[2], @Integer[2], @Integer[2], @Integer[5], @Integer[5], @Integer[73], @Integer[241], @Integer[439], ],] 参数里-n 2，表示只执行两次 这里输出结果中，第一次输出的是方法调用前的观察表达式的结果，第二次输出的是方法返回后的表达式的结果 结果的顺序和命令中 -s -b 的顺序没有关系，只与事件本身的先后顺序有关 调整-x的值，观察具体的方法参数值12345678910111213141516171819202122232425262728$ watch demo.MathGame primeFactors \"&#123;params,target&#125;\" -x 3Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 58 ms.ts=2018-12-03 19:34:19; [cost=0.587833ms] result=@ArrayList[ @Object[][ @Integer[47816758], ], @MathGame[ random=@Random[ serialVersionUID=@Long[3905348978240129619], seed=@AtomicLong[3133719055989], multiplier=@Long[25214903917], addend=@Long[11], mask=@Long[281474976710655], DOUBLE_UNIT=@Double[1.1102230246251565E-16], BadBound=@String[bound must be positive], BadRange=@String[bound must be greater than origin], BadSize=@String[size must be non-negative], seedUniquifier=@AtomicLong[-3282039941672302964], nextNextGaussian=@Double[0.0], haveNextNextGaussian=@Boolean[false], serialPersistentFields=@ObjectStreamField[][isEmpty=false;size=3], unsafe=@Unsafe[sun.misc.Unsafe@2eaa1027], seedOffset=@Long[24], ], illegalArgumentCount=@Integer[13159], ],] -x表示遍历深度，可以调整来打印具体的参数和结果内容，默认值是1。 条件表达式的例子1234567$ watch demo.MathGame primeFactors \"&#123;params[0],target&#125;\" \"params[0]&lt;0\"Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 68 ms.ts=2018-12-03 19:36:04; [cost=0.530255ms] result=@ArrayList[ @Integer[-18178089], @MathGame[demo.MathGame@41cf53f9],] 只有满足条件的调用，才会有响应。 观察异常信息的例子1234567891011$ watch demo.MathGame primeFactors \"&#123;params[0],throwExp&#125;\" -e -x 2Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 62 ms.ts=2018-12-03 19:38:00; [cost=1.414993ms] result=@ArrayList[ @Integer[-1120397038], java.lang.IllegalArgumentException: number is: -1120397038, need &gt;= 2 at demo.MathGame.primeFactors(MathGame.java:46) at demo.MathGame.run(MathGame.java:24) at demo.MathGame.main(MathGame.java:16),] -e\b表示抛出异常时才触发 express中，表示异常信息的变量是throwExp 按照耗时进行过滤123456789101112$ watch demo.MathGame primeFactors '&#123;params, returnObj&#125;' '#cost&gt;200' -x 2Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 66 ms.ts=2018-12-03 19:40:28; [cost=2112.168897ms] result=@ArrayList[ @Object[][ @Integer[2141897465], ], @ArrayList[ @Integer[5], @Integer[428379493], ],] #cost&gt;200(单位是ms)表示只有当耗时大于200ms时才会输出，过滤掉执行时间小于200ms的调用 观察当前对象中的属性如果想查看方法运行前后，当前对象中的属性，可以使用target关键字，代表当前对象 1234567$ watch demo.MathGame primeFactors 'target'Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 52 ms.ts=2018-12-03 19:41:52; [cost=0.477882ms] result=@MathGame[ random=@Random[java.util.Random@522b408a], illegalArgumentCount=@Integer[13355],] 然后使用target.field_name访问当前对象的某个属性 12345$ watch demo.MathGame primeFactors 'target.illegalArgumentCount'Press Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 67 ms.ts=2018-12-03 20:04:34; [cost=131.303498ms] result=@Integer[8]ts=2018-12-03 20:04:35; [cost=0.961441ms] result=@Integer[8]","categories":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/categories/greys/"}],"tags":[{"name":"greys","slug":"greys","permalink":"https://blog.milk4j.com/tags/greys/"}]},{"title":"java应用jvm配置参考","slug":"java应用jvm参数配置参考","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:35:16.768Z","comments":true,"path":"2018/07/05/java应用jvm参数配置参考/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/java应用jvm参数配置参考/","excerpt":"","text":"java应用jvm配置参考 一切配置在亲身测试之后，才比较靠谱。这里给出我们的经验值，仅供参考。 WEB服务器JVM配置容器内存4Gjava内存：4096m * 0.75 = 3072m 123456789-server//服务器模式-Xmx3072m //JVM最大允许分配的堆内存，按需分配-Xms3072m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存3Gjava内存：3072m * 0.7 = 2150m 123456789-server//服务器模式-Xmx2150m //JVM最大允许分配的堆内存，按需分配-Xms2150m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存2Gjava内存：2048m * 0.7 = 1434m 123456789-server//服务器模式-Xmx1434m //JVM最大允许分配的堆内存，按需分配-Xms1434m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存1.5Gjava内存：1536m * 0.7 = 1075m 123456789-server//服务器模式-Xmx1075m //JVM最大允许分配的堆内存，按需分配-Xms1075m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存1Gjava内存：1024m * 0.7 = 717m 123456789-server//服务器模式-Xmx717m //JVM最大允许分配的堆内存，按需分配-Xms717m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 常用参数说明参数设置在Java虚拟机的参数中，有3种表示方法： 标准参数（-），所有的JVM实现都必须实现这些参数的功能，而且向后兼容； 非标准参数（-X），默认jvm实现这些参数的功能，但是并不保证所有jvm实现都满足，且不保证向后兼容； 非Stable参数（-XX），此类参数各个jvm实现会有所不同，将来可能会随时取消，需要慎重使用（但是，这些参数往往是非常有用的）； 常用参数现在的JVM运行Java程序时在高效性和稳定性方面做的非常出色。自适应内存管理、垃圾收集、及时编译、动态类加载、锁优化等使得普通程序员几乎不会case内存相关的事情。但JVM仍然大量的参数，使得我们可以针对不同场景进行不同的配置和调优。 -client-server指定JVM的启动模式是client模式还是server模式，具体就是 Java HotSpot Client(Server) VM 版本。目前64位的JDK启动，一定是server模式，会忽略这个参数。 -Xmn设置初始最大的年轻代堆大小。 -Xms设置初始的堆大小。 -Xmx设置最大的内存分配大小。一般的服务端部署，-Xms和-Xmx设置为同样大小。 基础回顾JVM内存结构当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。 Hotspot VM将内存划分为不同的物理区，就是“分代”思想的体现。如图所示，JVM内存主要由新生代、老年代、永久代构成。 新生代大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC）后只有少量对象存活，所以选用复制算法，只需要少量的复制成本就可以完成回收。新生代内又分三个区：一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。对象每经历一次Minor GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。 老年代在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。 永久代主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。 jdk1.8中, 永久代最终被移除，方法区移至Metaspace，字符串常量移至Java Heap。永久代的垃圾回收主要两部分：废弃常量和无用类。 常见垃圾回收器不同的垃圾回收器，适用于不同的场景。常用的垃圾回收器： 串行（Serial）回收器是单线程的一个回收器，简单、易实现、效率高。 并行（ParNew）回收器是Serial的多线程版，可以充分的利用CPU资源，减少回收的时间。 吞吐量优先（Parallel Scavenge）回收器，侧重于吞吐量的控制。 并发标记清除（CMS，Concurrent Mark Sweep）回收器是一种以获取最短回收停顿时间为目标的回收器，该回收器是基于“标记-清除”算法实现的。 实用方法jstatjstat可以实时显示本地或远程JVM进程中类装载、内存、垃圾收集、JIT编译等数据（如果要显示远程JVM信息，需要远程主机开启RMI支持）。如果在服务启动时没有指定启动参数-verbose:gc，则可以用jstat实时查看gc情况。 如图，如我本机RemoteMavenServer的GC情况（后两个参数表示，每隔1秒打印1次）： 参数 解释 S0 第一个Survivor的使用大小 S1 第二个Survivor的使用大小 EU 伊甸园区的使用大小 O 老年代使用大小 M 方法区使用大小 CCS 压缩类空间使用大小 YGC 年轻代垃圾回收次数 YGCT 年轻代垃圾回收消耗时间 FGC 老年代垃圾回收次数 FGCT 老年代垃圾回收消耗时间 GCT 垃圾回收消耗总时间 gc logGC日志是一个很重要的工具，它准确记录了每一次的GC的执行时间和执行结果，通过分析GC日志可以优化堆设置和GC设置，或者改进应用程序的对象分配模式。不同的垃圾收集器，输出的日志格式各不相同，但也有一些相同的特征。熟悉各个常用垃圾收集器的GC日志，是进行JVM调优的必备一步。 参数 说明 -XX:+PrintGCDetails 打印GC详细信息 -XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式） -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -XX:+PrintTenuringDistribution 在进行GC时打印survivor中的对象年龄分布信息 -Xloggc:$CATALINA_HOME/logs/gc.log 指定输出路径收集日志到日志文件 这里以-XX:+UseConcMarkSweepGC日志为例。-XX:+UseConcMarkSweepGC会指定CMS收集器+ParNew收集器+Serial Old收集器组合，优先使用ParNew收集器+CMS收集器的组合，当出现ConcurrentMode Fail或者Promotion Failed时，则采用ParNew收集器+Serial Old收集器的组合。日志如下： 123456789101112131415161718192021222324252627282930313233Java HotSpot(TM) 64-Bit Server VM (25.131-b11) for windows-amd64 JRE (1.8.0_131-b11), built on Mar 15 2017 01:23:53 by &quot;java_re&quot; with MS VC++ 10.0 (VS2010)Memory: 4k page, physical 8303556k(2846816k free), swap 16215992k(7664596k free)CommandLine flags: -XX:InitialHeapSize=29360128 -XX:MaxHeapSize=29360128 -XX:MaxNewSize=14680064 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC 2018-05-09T20:53:14.086+0800: 0.590: [GC (Allocation Failure) 2018-08-09T11:53:14.086+0800: 0.590: [ParNew: 11520K-&gt;1407K(12928K), 0.0034803 secs] 11520K-&gt;2254K(27264K), 0.0039082 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2018-05-09T20:53:14.247+0800: 0.751: [Full GC (System.gc()) 2018-08-09T11:53:14.247+0800: 0.751: [CMS: 846K-&gt;1930K(14336K), 0.0103698 secs] 7165K-&gt;1930K(27264K), [Metaspace: 5963K-&gt;5963K(1056768K)], 0.0104529 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 2018-05-09T20:53:14.292+0800: 0.795: [GC (Allocation Failure) 2018-08-09T11:53:14.292+0800: 0.795: [ParNew: 11519K-&gt;1199K(12928K), 0.0085679 secs] 13450K-&gt;3129K(27264K), 0.0086244 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 2018-05-09T20:53:14.333+0800: 0.836: [GC (Allocation Failure) 2018-08-09T11:53:14.333+0800: 0.836: [ParNew: 12719K-&gt;300K(12928K), 0.0002620 secs] 14649K-&gt;2230K(27264K), 0.0003041 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2018-05-09T20:53:14.364+0800: 0.867: [GC (Allocation Failure) 2018-08-09T11:53:14.364+0800: 0.867: [ParNew: 11820K-&gt;75K(12928K), 0.0002787 secs] 13750K-&gt;2005K(27264K), 0.0003223 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] # 并发标记周期开始，根区域扫描2018-05-09T20:59:47.982+0800: 9.634: [GC concurrent-root-region-scan-start]2018-05-09T20:59:47.982+0800: 9.652: [GC concurrent-root-region-scan-end, 0.0184308 secs]# 并发标记2018-05-09T20:59:47.982+0800: 9.652: [GC concurrent-mark-start]2018-05-09T20:59:47.982+0800: 9.693: [GC concurrent-mark-end, 0.0406187 secs]# 重新标记2018-05-09T20:59:47.982+0800: 9.695: [GC remark 9.695: [Finalize Marking, 0.0005100 secs] 9.695: [GC ref-proc, 0.0003461 secs] 9.696: [Unloading, 0.0069466 secs], 0.0082011 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] # 独占清理2018-05-09T20:59:47.982+0800: 9.703: [GC cleanup 25M-&gt;21M(1024M), 0.0027119 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] # 并发清理2018-05-09T20:59:47.982+0800: 9.706: [GC concurrent-cleanup-start]2018-05-09T20:59:47.982+0800: 9.706: [GC concurrent-cleanup-end, 0.0000167 secs]2018-05-09T20:54:39.299+0800: 85.803: [Full GC (System.gc()) 2018-08-09T11:54:39.299+0800: 85.803: [CMS: 1930K-&gt;1832K(14336K), 0.0089015 secs] 12748K-&gt;1832K(27264K), [Metaspace: 6035K-&gt;6035K(1056768K)], 0.0089724 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap par new generation total 12928K, used 227K [0x00000000fe400000, 0x00000000ff200000, 0x00000000ff200000) eden space 11520K, 1% used [0x00000000fe400000, 0x00000000fe438cd8, 0x00000000fef40000) from space 1408K, 0% used [0x00000000fef40000, 0x00000000fef40000, 0x00000000ff0a0000) to space 1408K, 0% used [0x00000000ff0a0000, 0x00000000ff0a0000, 0x00000000ff200000) concurrent mark-sweep generation total 14336K, used 1832K [0x00000000ff200000, 0x0000000100000000, 0x0000000100000000) Metaspace used 6045K, capacity 6252K, committed 6400K, reserved 1056768K class space used 691K, capacity 761K, committed 768K, reserved 1048576K 第三行把当前使用的JVM参数打印出来，其中，-XX:MaxTenuringThreshold=6是指对象从新生代晋升到老年代需要对象年龄达到6岁，即经过6次GC。 第四行是新生代Young区的GC，首先是GC发生的时间。然后是GC发生的原因GC (Allocation Failure)，对象分配失败。[ParNew: 11520K-&gt;1407K(12928K), 0.0034803 secs]表示新生代回收前是11520K，回收后是1407K，新生代总大小12928K，回收耗时0.0034803 secs。11520K-&gt;2254K(27264K), 0.0039082 secs表示回收前堆大小11520K，回收后堆大小2254K，堆的总大小27264K。 第五行是老年代Old区的GC，首先是GC发生的时间。然后是GC发生的原因System.gc()，由于代码调用。[CMS: 846K-&gt;1930K(14336K), 0.0103698 secs]表示回收前老年代是846K，回收后1930K，老年代总大小14336K，回收耗时0.0103698 secs。7165K-&gt;1930K(27264K)表示回收前堆大小7165K，回收后堆大小1930K，堆的总大小27264K。 后面有一次并发标记周期，设置参数-XX:InitiatingHeapOccupancyPercent的值，可以指定堆占有率达到百分之多少时，触发并发标记，默认值是45%。 最后打印出了堆的整体使用情况，分为新生代、老年代、元空间。 调优方法请记住下面的原则： 多数的Java应用不需要在服务器上进行GC优化； 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC优化是到最后不得已才采用的手段； 在实际使用中，分析GC情况优化代码比优化GC参数要多得多。 GC优化的目的有两个： 将转移到老年代的对象数量降低到最小； 减少full GC的执行时间； 为了达到上面的目的，一般地，你需要做的事情有： 减少使用全局变量和大对象； 调整新生代的大小到最合适； 设置老年代的大小为最合适； 选择合适的GC收集器； 进行监控和调优的一般步骤： 监控GC的状态使用各种JVM工具，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和gc日志，根据实际的各区域内存划分和GC执行时间，觉得是否进行优化； 分析结果，判断是否需要优化如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化；如果GC时间超过1-3秒，或者频繁GC，则必须优化； 注：如果满足下面的指标，则一般不需要进行GC调优： Minor GC执行时间不到50ms；Minor GC执行不频繁，约10秒一次；Full GC执行时间不到1s；Full GC执行频率不算频繁，不低于10分钟1次； 调整GC类型和内存分配如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择； 不断的分析和调整通过不断的试验和试错，分析并找到最合适的参数 全面应用参数如果找到了最合适的参数，则将这些参数应用到所有服务器，并进行后续跟踪。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://blog.milk4j.com/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://blog.milk4j.com/tags/jvm/"}]},{"title":"SpringBoot配置文件","slug":"SpringBoot配置文件","date":"2018-07-05T14:59:00.000Z","updated":"2018-12-22T06:36:54.045Z","comments":true,"path":"2018/07/05/SpringBoot配置文件/","link":"","permalink":"https://blog.milk4j.com/2018/07/05/SpringBoot配置文件/","excerpt":"","text":"SpringBoot配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； application.properties application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） YAML A Markup Language：是一个标记语言 YAML isn’t Markup Language：不是一个标记语言； 标记语言： 以前的配置文件；大多都使用的是 xxxx.xml文件； YAML：以数据为中心，比json、xml等更适合做配置文件； YAML：配置例子 12server: port: 8081 XML： 123&lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 123server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔） k: v：字面直接来写； 字符串默认不用加上单引号或者双引号； “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思,eg: name: “zhangsan \\n lisi” ==&gt;输出；zhangsan 换行 lisi ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据name: ‘zhangsan \\n lisi’ ==&gt; 输出；zhangsan \\n lisi 对象、Map：k: v：在下一行来写对象的属性和值的关系；注意缩进 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 数组：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3、配置文件值注入配置文件 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = \"person\"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验123456789101112131415161718192021222324@Component@ConfigurationProperties(prefix = \"person\")@Validatedpublic class Person &#123; /** * &lt;bean class=\"Person\"&gt; * &lt;property name=\"lastName\" value=\"字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;\"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value(\"$&#123;person.last-name&#125;\") private String lastName; //@Value(\"#&#123;11*2&#125;\") private Integer age; //@Value(\"true\") private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp; @ImportResource&amp; @Bean@PropertySource：加载指定的配置文件； 1234567891011121314151617181920212223242526272829/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = \"person\"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = \"person\")默认从全局配置文件中获取值； * */@PropertySource(value = &#123;\"classpath:person.properties\"&#125;)@Component@ConfigurationProperties(prefix = \"person\")//@Validatedpublic class Person &#123; /** * &lt;bean class=\"Person\"&gt; * &lt;property name=\"lastName\" value=\"字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;\"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value(\"$&#123;person.last-name&#125;\") private String lastName; //@Value(\"#&#123;11*2&#125;\") private Integer age; //@Value(\"true\") private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 12@ImportResource(locations = &#123;\"classpath:beans.xml\"&#125;)导入Spring的配置文件让其生效 不来编写Spring的配置文件 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"helloService\" class=\"com.milk4j.springboot.service.HelloService\"&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类@Configuration ==&gt; Spring配置文件 2、使用@Bean给容器中添加组件 12345678910111213141516/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02()&#123; System.out.println(\"配置类@Bean给容器中添加组件了...\"); return new HelloService(); &#125;&#125; ##4、配置文件占位符 1、随机数12$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125; 2、占位符获取之前配置的值，如果没有可以是用&quot;:&quot;指定默认值123456789person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式1234567891011121314151617181920server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile1、在配置文件中指定 spring.profiles.active=dev 2、命令行： java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev； 可以直接在测试的时候，配置传入命令行参数 3、虚拟机参数； -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 – file:./config/ – file:./ – classpath:/config/ – classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar --spring.config.location=G:/application.properties 7、外部配置加载顺序==SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置== 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar --server.port=8087 --server.context-path=/abc 多个配置用空格分开； –配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 ==由jar包外向jar包内进行寻找；== ==优先加载带profile== 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ==再来加载不带profile== 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 1234SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 ==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；== 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； 12345678910111213141516171819202122232425262728@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 1234@ConfigurationProperties(prefix = \"spring.http.encoding\") //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF-8\"); 精髓： 1）、SpringBoot启动会加载大量的自动配置类​2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类；​3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了）​4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； ==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==，这样我们就可以很方便的知道哪些自动配置类生效； 1234567891011121314151617181920212223=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition)","categories":[{"name":"springboot","slug":"springboot","permalink":"https://blog.milk4j.com/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.milk4j.com/tags/springboot/"}]},{"title":"Docker基本使用","slug":"Docker基本使用","date":"2018-06-22T03:26:02.000Z","updated":"2018-10-22T11:13:20.539Z","comments":true,"path":"2018/06/22/Docker基本使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/22/Docker基本使用/","excerpt":"","text":"一. docker使用1. docker ps 查看运行中的容器2. docker images 查看docker镜像3. docker rm id(容器id) 删除容器（容器id可以通过docker ps查看，容器必须停止后才能删除）3.1 删除全部的容器 docker rm docker ps -a -q4. docker stop id(容器id) 停止容器运行5. docker rmi id(镜像id) 删除镜像6. docker pull ubuntu:16.04(镜像名称:版本号) 下载镜像7. docker run -it ubuntu:16.04 创建并运行容器容器 -t 表示在新容器内指定一个伪终端或终端 -i 表示允许我们对容器内的 (STDIN) 进行交互 -p 指定映射端口 -d 在后台运行容器并打印容器ID 7.1 docker run -dit ubuntu:16.04 创建并后台运行容器7.2 docker run -ditp 8080:8080（主机端口:容器端口） ubuntu:16.04 创建并后台运行容器且映射容器的端口8. docker attach id(容器id) 进入正在运行中的容器环境9. 退出容器9.1 exit 直接退出容器并终止容器运行9.2 [ctrl+p]+[ctrl+q]（快捷键） 退出容器，但是不会终止容器运行10. docker commit -m’版本标识’ id(容器id) ubuntu:16.04(镜像与版本号) 提交镜像且生成镜像（可以通过该命令把搭建好的容器打包成一个新的镜像或者覆盖原镜像（即是修改原镜像内容，生成的镜像名与版本号相同就可以直接覆盖））","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"ElasticSearch Rest 客户端使用(长文,待续...)","slug":"ElasticSearch-Rest-客户端使用","date":"2018-06-20T12:36:39.000Z","updated":"2018-10-31T01:38:12.054Z","comments":true,"path":"2018/06/20/ElasticSearch-Rest-客户端使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/20/ElasticSearch-Rest-客户端使用/","excerpt":"","text":"起步阅读文档须知,文档基于Elasticsearch 6.x,阅读要求,熟悉 ElasticSearch 的语法 兼容性高级客户端要求最低的 java 版本是1.8 ，它依赖 Elasticsearch 的核心工程，客户端的版本应该和 Elasticsearch 的版本保持一致，高级客户端和 TransportClient【TCP 连接客户端】 接受一样的请求参数，并且返回一样的响应结果，如果你想从 TransportClient 客户端迁移到 REST 客户端，请参考迁移手册 高级客户端保证能够与运行在相同主要版本和更高版本上的Elasticsearch节点进行通信。它不需要与通信的Elasticsearch节点处于相同的版本，因为它是向前兼容的，这意味着它支持与更高版本的Elasticsearch进行通信，而不是与其开发的版本进行通信。 6.0 客户端能够与任何6.x版本的 Elasticsearch节点通信，而6.1客户端肯定能够与6.1,6.2和任何更高版本的6.x版本通信，但在与老版的Elasticsearch节点通信时可能存在不兼容问题版本，例如6.1和6.0，6.1客户端为一些 api 添加了新的请求体字段支持，然而6.0节点却不支持。 建议在将Elasticsearch集群升级到新的主版本时升级高级客户端，因为REST API中断更改可能会导致意外结果，具体取决于请求所针对的节点，并且新添加的API仅支持新版本的客户端。一旦集群中的所有节点都升级到新的主版本，客户端应保持同步更新。 Java api 文档文档地址：&lt;https://artifacts.elastic.co/javadoc/org/elasticsearch/client/elasticsearch-rest-high-level-client/6.3.1/index.html&gt; maven 仓库高级Java REST客户端托管在 Maven Central上。所需的最低Java版本是1.8。 高级REST客户端与Elasticsearch具有相同的发布周期。将版本替换为所需的客户端版本。 如果您正在寻找SNAPSHOT版本，可以通过https://snapshots.elastic.co/maven/获取Elastic Maven Snapshot存储库。 Maven 配置12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.1&lt;/version&gt;&lt;/dependency&gt; Gradel 配置123dependencies &#123; compile 'org.elasticsearch.client:elasticsearch-rest-high-level-client:6.3.1'&#125; 依赖高级客户端依赖下面的组件及其传递依赖性： org.elasticsearch.client:elasticsearch-rest-client org.elasticsearch:elasticsearch 初始化一个RestHighLevelClient实例需要一个低级客户端的Builder 来构建如下： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"localhost\", 9200, \"http\"), new HttpHost(\"localhost\", 9201, \"http\"))); 高级客户端将在内部创建用于执行请求的低级客户端，低级客户端基于框架提供的builder，并管理其生命周期。 高级客户端实例应该在不再需要时关闭，以便正确释放它使用的所有资源，以及底层的http客户端实例及其线程。这可以通过close 方法完成，该方法将关闭内部RestClient实例。 1client.close(); Document APIJava高级REST客户端支持以下文档API： 单文档API： index api - 索引API get api - 获取API delete api - 删除API update api - 更新API 多文档API bulk api - 批量操作 api Multi-Get API - 批量获取 api Index APIIndex 请求体一个引索请求需要下面的参数： 12345678910IndexRequest request = new IndexRequest( \"posts\", //index 名 \"doc\", //type 名 \"1\"); //文档 IDString jsonString = \"&#123;\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"&#125;\";request.source(jsonString, XContentType.JSON);//设置 string 类型的文档source 构建文档 source 的方式除了String上面显示的示例之外，还可以以不同方式提供文档源 ： 方式一：以 Map 的方式提供的文档源，Map自动转换为JSON格式 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"user\", \"kimchy\");jsonMap.put(\"postDate\", new Date());jsonMap.put(\"message\", \"trying out Elasticsearch\");IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(jsonMap); 方式二：以XContentBuilder对象方式提供，Elasticsearch内置了helper生成JSON内容 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(\"user\", \"kimchy\"); builder.timeField(\"postDate\", new Date()); builder.field(\"message\", \"trying out Elasticsearch\");&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(builder); 方式三：以键值对方式提供，转换为JSON格式 1234IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"user\", \"kimchy\", \"postDate\", new Date(), \"message\", \"trying out Elasticsearch\"); 可选参数可以选择以下参数： 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1));request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);request.setRefreshPolicy(\"wait_for\"); 设置版本 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 设置文档操作类型 12request.opType(DocWriteRequest.OpType.CREATE); request.opType(\"create\"); 文档执行之前，设置 pipeline 名 1request.setPipeline(&quot;pipeline&quot;); 同步执行方式1IndexResponse indexResponse = client.index(request); 异步执行方式索引请求的异步执行需要将IndexRequest 实例和ActionListener实例都传递给异步方法： 123456789ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;IndexResponse indexResponse = client.index(request); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 引索响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 123456789101112131415161718String index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //创建文档操作&#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //更新文档操作&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; //处理成功分片数小于总分片数的情况&#125;if (shardInfo.getFailed() &gt; 0) &#123;//理潜在的失败情况 for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 如果存在文档版本冲突，则会抛出ElasticsearchException： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .version(1);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; 如果已存在具有相同索引，类型和ID的文档，opType设置为create也会发生冲突： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .opType(DocWriteRequest.OpType.CREATE);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Get APIGet 请求体构建 GetRequest 的参数如下： 1GetRequest getRequest = new GetRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置返回响应不包含任何字段，默认情况下返回响应包含该所有字段 1request.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回响应包含哪些字段 12345String[] includes = new String[]&#123;\"message\", \"*Date\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置返回响应不包含哪些字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;\"message\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置检索哪些存储字段 123request.storedFields(\"message\"); //为特定存储字段配置检索 (要求在映射中单独存储字段)GetResponse getResponse = client.get(request);String message = getResponse.getField(\"message\").getValue();//获取message存储的值 (要求将字段单独存储在映射中) 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置偏好 1request.preference(\"preference\"); 设置实时标识，默认 true 1request.realtime(false); 设置每次获取文档之前是否执行刷新操作，默认 false 1request.refresh(true); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1GetResponse getResponse = client.get(getRequest); 异步执行get请求的异步执行需要将GetRequest 实例和ActionListener实例都传递给异步方法 12345678910ActionListener&lt;GetResponse&gt; listener = new ActionListener&lt;GetResponse&gt;() &#123; @Override public void onResponse(GetResponse getResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;GetResponse getResponse = client.get(getRequest); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); byte[] sourceAsBytes = getResponse.getSourceAsBytes(); &#125; else &#123; //处理未找到文档的方案。注意，虽然返回的响应具有404状态代码，但他会返回一个有效GetResponse而不是抛出异常。此类响应不包含任何文档字段，而且isExists方法返回false。&#125; 当对不存在的索引(index)执行get请求时，响应会有404状态代码，但是会抛出ElasticsearchException，需要按如下方式处理： 12345678GetRequest request = new GetRequest(\"does_not_exist\", \"doc\", \"1\");try &#123; GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果请求特定版本的文档，并且现有文档具有不同的版本号，则会引发版本冲突： 12345678try &#123; GetRequest request = new GetRequest(\"posts\", \"doc\", \"1\").version(2); GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //处理版本冲突 &#125;&#125; Exists API如果文档存在就返回 true，否则返回 false Exists Request它的GetRequest就像Get API一样。支持所有可选参数 。由于exists()只返回true或false，所有建议关闭返回_source和任何存储的字段，以便请求更加轻量： 123456GetRequest getRequest = new GetRequest( \"posts\", \"doc\", \"1\"); getRequest.fetchSourceContext(new FetchSourceContext(false)); //不返回_sourcegetRequest.storedFields(\"_none_\"); //不返回存储字段 同步执行1boolean exists = client.exists(getRequest); 异步执行123456789ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.existsAsync(getRequest, listener); Delete APIDelete RequestDeleteRequest 参数如下： 1DeleteRequest request = new DeleteRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1DeleteResponse deleteResponse = client.delete(request); 异步执行123456789ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.deleteAsync(request, listener); Delete Response返回的DeleteResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 它还可以检查文档是否存在 12345DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"does_not_exist\");DeleteResponse deleteResponse = client.delete(request);if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) &#123; //如果找不到要删除的文档&#125; 如果请求的文档版本冲突，会抛ElasticsearchException异常 12345678try &#123; DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"1\").version(2); DeleteResponse deleteResponse = client.delete(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; Update APIUpdateRequest参数如下： 1UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\"); Update API允许使用脚本或传递部分文档来更新现有文档。 使用脚本更新文档使用内联脚本 12345Map&lt;String, Object&gt; parameters = singletonMap(\"count\", 4); //使用Map对象作为脚本参数Script inline = new Script(ScriptType.INLINE, \"painless\", \"ctx._source.field += params.count\", parameters); //使用painless语言和提供的参数创建内联脚本UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");request.script(inline); //将脚本设置为更新请求 或者使用存储在es 中的脚本 12Script stored =new Script(ScriptType.STORED, null, \"increment-field\", parameters);//使用存储在 es 中的painless脚本，脚本名为increment-fieldrequest.script(stored); 传递部分文档作为参数来更新文档当使用部分文档来更新现有的文档时，部分文档将与现有文档合并。 部分文档可以以不同方式提供： 123456UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");String jsonString = \"&#123;\" + \"\\\"updated\\\":\\\"2017-01-01\\\",\" + \"\\\"reason\\\":\\\"daily update\\\"\" + \"&#125;\";request.doc(jsonString, XContentType.JSON);//用json格式的字符串作为部分文档源 以 Map 提供部分文档源，会被自动转化成 json 格式，如下 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"updated\", new Date());jsonMap.put(\"reason\", \"daily update\");UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(jsonMap); 用XContentBuilder对象作为部分文档源，Elasticsearch内置的 helpers 会自动将它转化为 json 文档 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(\"updated\", new Date()); builder.field(\"reason\", \"daily update\");&#125;builder.endObject();UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(builder); 使用键值对作为部分文档源，他会被转换成 json 文本 123UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"updated\", new Date(), \"reason\", \"daily update\"); Upserts如果文档尚不存在，则可以使用以下upsert方法来将它作为新文档插入： 12String jsonString = \"&#123;\\\"created\\\":\\\"2017-01-01\\\"&#125;\";request.upsert(jsonString, XContentType.JSON); 和部分文档更新一样，upsert 方法接受String, Map, XContentBuilder or 键值对作为入参 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置重试更新操作的次数 如果要更新的文档已在更新操作的get和indexing阶段之间的另一个操作更改，则重试 1request.retryOnConflict(3); 设置是否获取新文档内容，默认 false 1request.fetchSource(true); 指定返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;//正则匹配String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定不返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 设置文档版本号 1request.version(2); 设置是否启用noop 检测 1request.detectNoop(false); 指示脚本必须运行，无论文档是否存在，即如果文档尚不存在，脚本将负责创建文档 1request.scriptedUpsert(true); 如果文档不存在，则表明必须将部分文档用作upsert文档 1request.docAsUpsert(true); 设置在执行更新操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); 同步执行1UpdateResponse updateResponse = client.update(request); 异步执行12345678client.updateAsync(request, new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;); UpdateResponse返回的UpdateResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //首次创建文档（upsert）&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; //文档未受更新影响，即未对文档执行任何操作（noop）&#125; UpdateRequest 通过fetchSource方法启用获取文档功能时，响应包含更新文档的来源： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); byte[] sourceAsBytes = result.source(); &#125; else &#123; &#125; 可以检查分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 当对一个不存在的文档执行UpdateRequest时，响应具有404状态代码，会抛出ElasticsearchException，需要按如下方式处理： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"type\", \"does_not_exist\") .doc(\"field\", \"value\");try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果发生文档版本冲突，会抛出异常： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"field\", \"value\") .version(1);try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Bulk APIBulkRequestBulkRequest可用于使用单个请求执行多个索引，更新和/或删除操作 它要求至少将一个操作添加到批量请求： 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(\"posts\", \"doc\", \"1\") .source(XContentType.JSON,\"field\", \"foo\"));request.add(new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON,\"field\", \"bar\"));request.add(new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON,\"field\", \"baz\")); 并且可以添加不同的操作类型BulkRequest： 123456BulkRequest request = new BulkRequest();request.add(new DeleteRequest(\"posts\", \"doc\", \"3\")); request.add(new UpdateRequest(\"posts\", \"doc\", \"2\") .doc(XContentType.JSON,\"other\", \"test\"));request.add(new IndexRequest(\"posts\", \"doc\", \"4\") .source(XContentType.JSON,\"field\", \"baz\")); 可选参数 设置超时时间 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置在索引/更新/删除操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); //可选ActiveShardCount.ALL、 ActiveShardCount.ONE 、 ActiveShardCount.DEFAULT 同步执行1BulkResponse bulkResponse = client.bulk(request); 异步执行123456789ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.bulkAsync(request, listener); BulkResponse响应结果，允许迭代每个结果，如下所示： 123456789101112131415for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; //可以是IndexResponse、UpdateResponse、DeleteResponse，他们可以全部被视为DocWriteResponse实例 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; &#125;&#125; 批量响应提供了一种快速检查一个或多个操作是否失败的方法： 123if（bulkResponse.hasFailures（））&#123; //如果至少有一个操作失败，则返回true&#125; 在这种情况下，有必要迭代所有操作结果，以检查操作是否失败，如果是，则获取相应的失败信息： 123456for（BulkItemResponse bulkItemResponse：bulkResponse）&#123; if（bulkItemResponse.isFailed（））&#123; BulkItemResponse.Failure failure = bulkItemResponse.getFailure（）; &#125;&#125; 批量处理器BulkProcessor提供了一个工具类简化操作，它可以透明地执行添加到 processor 中的 index/update/delete操作。 为了执行请求，BulkProcessor需要以下组件： RestHighLevelClient 此客户端用于执行BulkRequest 和获取BulkResponse BulkProcessor.Listener 在每次BulkRequest执行之前、之后或BulkRequest失败时调用器监听 然后该BulkProcessor.builder方法可用于构建新的BulkProcessor： 1234567891011121314151617181920BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); BulkProcessor.Builder提供了方法来配置BulkProcessor处理请求的行为： 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500);//根据当前添加的操作数设置何时刷新新的批量请求（默认为1000，使用-1禁用它） builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); //根据当前添加的操作内容大小设置何时刷新新的批量请求（默认为5Mb，使用-1禁用它）builder.setConcurrentRequests(0); //设置允许执行的并发请求数（默认为1，使用0只允许执行单个请求）builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); //BulkRequest如果间隔超过，则 设置刷新间隔刷新任何挂起（默认为未设置）builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3));//设置一个最初等待1秒的常量重试策略，最多重试3次。见BackoffPolicy.noBackoff()、BackoffPolicy.constantBackoff()、BackoffPolicy.exponentialBackoff() 提供更多的选择 一旦BulkProcessor被创建，请求可以被添加到processor： 12345678910111213IndexRequest one = new IndexRequest(\"posts\", \"doc\", \"1\"). source(XContentType.JSON, \"title\", \"In which order are my Elasticsearch queries executed?\");IndexRequest two = new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON, \"title\", \"Current status and upcoming changes in Elasticsearch\");IndexRequest three = new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON, \"title\", \"The Future of Federated Search in Elasticsearch\");bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行所有的请求，并且为每次的 BulkRequest 回调BulkProcessor.Listener，监听器提供了访问 BulkRequest 和 BulkResponse 的方法 12345678910111213141516171819202122232425BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); logger.debug(\"Executing bulk [&#123;&#125;] with &#123;&#125; requests\", executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; logger.warn(\"Bulk [&#123;&#125;] executed with failures\", executionId); &#125; else &#123; logger.debug(\"Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds\", executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; //执行失败后调用 logger.error(\"Failed to execute bulk\", failure); &#125;&#125;; 将所有请求添加到BulkProcessor后，需要关闭其实例，有两种关闭方式。 该awaitClose()方法可用于等待所有请求都已处理或指定的等待时间： 1boolean terminated = bulkProcessor.awaitClose（30L，TimeUnit.SECONDS）;//true：如果所有批量请求都已完成，false：在所有批量请求完成之前等待时间已过 close()方法可用于立即关闭BulkProcessor： 1bulkProcessor.close（）; 两种方法在关闭处理器之前刷新已经添加到处理器的请求，并且禁止添加新请求 Multi-Get APImultiGet API 可以在单个请求中执行多个 get 请求 Multi-Get Request获取一个 MultiGetRequest实例，然后添加多个 MultiGetRequest.Item: 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( \"index\", \"type\", \"example_id\")); request.add(new MultiGetRequest.Item(\"index\", \"type\", \"another_id\")); 可选参数multiGet和 get Api支持相同的可选参数. 你可以在 Item上设置可选参数: 设置不返回任何文档，默认返回文档 123request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE) ); 设置返回文档的哪些字段 123456String[] includes = new String[] &#123;\"foo\", \"*r\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 设置不返回文档的哪些字段 123456String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[] &#123;\"foo\", \"*r\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 配置返回指定的存储字段 12345request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .storedFields(\"foo\")); //设置返回存储字段 fooMultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];String value = item.getResponse().getField(\"foo\").getValue(); //获取存储字段foo的值 其他可选参数 12345678910request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_routing\") .routing(\"some_routing\"));//设置路由 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_parent\") .parent(\"some_parent\"));//设置父文档 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_version\") .versionType(VersionType.EXTERNAL)//设置文档版本类型 .version(10123L)); //设置版本号request.preference(\"some_preference\"); //设置偏好request.realtime(false); //设置实时标识，默认为 true request.refresh(true); //获取文档之前执行刷新操作，默认 false 同步执行1MultiGetResponse response = client.multiGet(request); 异步执行123456789101112ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;MultiGetResponse response = client.multiGet(request); MultiGetResponse返回的MultiGetResponse通过getResponses方法可以获取一个 MultiGetItemResponse 列表，列表中的响应与请求的顺序相同，如果 get 成功 MultiGetItemResponse包含一个 GetResponse，如果它失败了会包含一个MultiGetResponse.Failure 1234567891011121314MultiGetItemResponse firstItem = response.getResponses（）[0];assertNull（firstItem.getFailure（））;//如果成功，返回 null GetResponse firstGet = firstItem.getResponse（）; //获取 GetResponseString index = firstItem.getIndex（）;String type = firstItem.getType（）;String id = firstItem.getId（）;if（firstGet.isExists（））//判断文档是否存在 long version = firstGet.getVersion（）; String sourceAsString = firstGet.getSourceAsString（）; Map &lt;String，Object&gt; sourceAsMap = firstGet.getSourceAsMap（）; byte [] sourceAsBytes = firstGet.getSourceAsBytes（）; &#125; else &#123; &#125; 如果请求的 index 不存在，则返回响应会包含一个异常信息 1234567assertNull(missingIndexItem.getResponse()); Exception e = missingIndexItem.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(\"reason=no such index\")); 请求文档版本冲突，则返回响应会包含一个异常信息 12345678910111213MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .version(1000L));MultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];assertNull(item.getResponse()); Exception e = item.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.CONFLICT, ee.status()); assertThat(e.getMessage(), containsString(\"version conflict, current version [1] is \" + \"different than the one provided [1000]\")); Search API高级客户端支持下面的 Search API: Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequest1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); searchRequest.source(searchSourceBuilder); 可选参数12345SearchRequest searchRequest = new SearchRequest(\"posts\"); searchRequest.types(\"doc\"); searchRequest.routing(\"routing\"); searchRequest.indicesOptions(IndicesOptions.lenientExpandOpen());searchRequest.preference(\"_local\"); 使用 SearchBuilder12345SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.termQuery(\"user\", \"kimchy\")); sourceBuilder.from(0); sourceBuilder.size(5); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); 构建查询语句12345678MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(\"user\", \"kimchy\");matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); searchSourceBuilder.query(matchQueryBuilder); 设置排序12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); sourceBuilder.sort(new FieldSortBuilder(\"_uid\").order(SortOrder.ASC)); 文档过滤1234sourceBuilder.fetchSource(false);String[] includeFields = new String[] &#123;\"title\", \"user\", \"innerObject.*\"&#125;;String[] excludeFields = new String[] &#123;\"_type\"&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 字段高亮123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(\"title\"); highlightTitle.highlighterType(\"unified\"); highlightBuilder.field(highlightTitle); HighlightBuilder.Field highlightUser = new HighlightBuilder.Field(\"user\");highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 添加聚合查询123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(\"by_company\") .field(\"company.keyword\");aggregation.subAggregation(AggregationBuilders.avg(\"average_age\") .field(\"age\"));searchSourceBuilder.aggregation(aggregation); 请求建议词123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(\"user\").text(\"kmichy\"); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(\"suggest_user\", termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 分析查询和聚合profile API 可用于为特定搜索分析查询和聚合的执行情况。为了使用它, 必须在 SearchSourceBuilder 上设置profile标志为 true: 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行 SearchRequest 后, 相应的 SearchResponse 将包含分析结果。 同步执行1SearchResponse searchResponse = client.search(searchRequest); 异步执行执行 SearchRequest 也可以以异步方式进行, 以便客户端可以直接返回。用户需要通过将请求和监听器传递给异步搜索方法来指定如何处理响应或潜在故障: 123456789101112ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.searchAsync(searchRequest, listener); 异步方法不会阻止线程，也不会立即返回。完成该操作后, 如果执行成功则回调ActionListener的 onResponse 方法，失败则回调 onFailure` 方法 SearchResponse执行搜索返回的 SearchResponse 提供了有关搜索执行本身以及对返回访问的文档的详细信息。看下有关于请求执行操作的信息, 如 HTTP 状态代码、执行时间或请求是否提前终止或超时: 1234RestStatus status = searchResponse.status();TimeValue took = searchResponse.getTook();Boolean terminatedEarly = searchResponse.isTerminatedEarly();boolean timedOut = searchResponse.isTimedOut(); 其次, 响应还提供有关在分片级别上执行的信息, 提供有关受影响搜索的分片总数以及成功与失败的分片的统计数据。潜在的故障也可以通过迭代 ShardSearchFailure 数组来处理, 如下面的示例所示: 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; 获取搜索命中的文档要获得对返回的文档的访问权限, 我们首先需要得到响应中包含的 SearchHits： 123SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); SearchHits 提供有关所有命中的全局信息, 如命中总数或最大得分: 12long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); 嵌套在 SearchHits 中的是可以迭代的单个搜索结果: 1234SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit&#125; SearchHit 提供对基本信息的访问, 如索引、类型、docId 和每个搜索命中的分数: 1234String index = hit.getIndex();String type = hit.getType();String id = hit.getId();float score = hit.getScore(); 此外, 它还允许您返回文档源, 既可以是简单的 JSON 字符串, 也可以是键/值对的映射。在此映射中,通常键值对的键为字段名, 值为字段值。多值字段作为对象的列表返回, 嵌套对象作为另一个键/值映射。这些案件需要相应地强制执行: 123456String sourceAsString = hit.getSourceAsString();Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();String documentTitle = (String) sourceAsMap.get(\"title\");List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(\"user\");Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(\"innerObject\"); 获取高亮结果可以从结果中获取每个 SearchHit 中高亮显示的文本片段。SearchHit提供对 HighlightField 实例的访问, 其中每一个都包含一个或多个突出显示的文本片段: 1234567SearchHits hits = searchResponse.getHits();for (SearchHit hit : hits.getHits()) &#123; Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); HighlightField highlight = highlightFields.get(\"title\"); Text[] fragments = highlight.fragments(); String fragmentString = fragments[0].string();&#125; 获取聚合结果可以从 SearchResponse 获取聚合结果, 首先获取聚合树的根、聚合对象, 然后按名称获取聚合 12345Aggregations aggregations = searchResponse.getAggregations();Terms byCompanyAggregation = aggregations.get(\"by_company\"); Bucket elasticBucket = byCompanyAggregation.getBucketByKey(\"Elastic\"); Avg averageAge = elasticBucket.getAggregations().get(\"average_age\"); double avg = averageAge.getValue(); 请注意, 如果按名称访问聚合, 则需要根据所请求的聚合类型指定聚合接口, 否则将引发抛出: 1Range range = aggregations.get(\"by_company\"); //这将引发异常, 因为 \"by_company\" 是一个term聚合, 但这里尝试将它一范围聚合取出 还可以将所有的聚合 转化成 map ,以聚合名作为 key 值。在这种情况下,需要显示强制转换到正确的类型: 12Map&lt;String, Aggregation&gt; aggregationMap = aggregations.getAsMap();Terms companyAggregation = (Terms) aggregationMap.get(\"by_company\"); 还有一些 getter 将所有顶层聚合作为列表返回: 1List&lt;Aggregation&gt; aggregationList = aggregations.asList(); 最后, 可以遍历所有聚合, 然后根据它们的类型决定如何进一步处理它们: 1234567for (Aggregation agg : aggregations) &#123; String type = agg.getType(); if (type.equals(TermsAggregationBuilder.NAME)) &#123; Bucket elasticBucket = ((Terms) agg).getBucketByKey(\"Elastic\"); long numberOfDocs = elasticBucket.getDocCount(); &#125;&#125; 获取建议要从 SearchResponse 中返回suggestions, 请使用suggestion 对象作为入口点, 然后检索嵌套的建议对象: 1234567Suggest suggest = searchResponse.getSuggest(); TermSuggestion termSuggestion = suggest.getSuggestion(\"suggest_user\"); for (TermSuggestion.Entry entry : termSuggestion.getEntries()) &#123; for (TermSuggestion.Entry.Option option : entry) &#123; String suggestText = option.getText().string(); &#125;&#125; 获取性能分析结果使用 getProfileResults () 方法从 SearchResponse 检索性能分析结果。此方法返回一个Map,包含 SearchRequest 执行中所涉及的每个分片的 ProfileShardResult 对象。ProfileShardResult 存储在映射中, 使用唯一标识配置文件结果对应的碎片的键. 下面是一个示例代码, 它演示如何循环访问每个分片的所有性能分析结果: 123456Map&lt;String, ProfileShardResult&gt; profilingResults = searchResponse.getProfileResults(); for (Map.Entry&lt;String, ProfileShardResult&gt; profilingResult : profilingResults.entrySet()) &#123; String key = profilingResult.getKey(); ProfileShardResult profileShardResult = profilingResult.getValue(); &#125; ProfileShardResult 对象本身包含一个或多个QueryProfileShardResult: 12345List&lt;QueryProfileShardResult&gt; queryProfileShardResults = profileShardResult.getQueryProfileResults(); for (QueryProfileShardResult queryProfileResult : queryProfileShardResults) &#123; &#125; 12345for (ProfileResult profileResult : queryProfileResult.getQueryResults()) &#123; String queryName = profileResult.getQueryName(); long queryTimeInMillis = profileResult.getTime(); List&lt;ProfileResult&gt; profiledChildren = profileResult.getProfiledChildren(); &#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/tags/elasticsearch/"}]},{"title":"Mac后端开发环境搭建","slug":"Mac后端开发环境搭建","date":"2018-04-14T02:01:56.000Z","updated":"2018-10-24T09:53:47.494Z","comments":true,"path":"2018/04/14/Mac后端开发环境搭建/","link":"","permalink":"https://blog.milk4j.com/2018/04/14/Mac后端开发环境搭建/","excerpt":"","text":"作为一个开发人员，选择 Mac 是一个非常好的选择，首先 Mac 是 Unix 的内核，支持 Unix 内核的命令，使用 Mac 能帮助我们熟悉 Unix 的操作命令 1、HomeBrew1.1 简介Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。 简单点说，Homebrew 是以最简单、最灵活的方式来安装苹果公司在 MacOS 中不包含的 UNIX 工具。 1.2 安装与卸载安装打开终端，复制粘贴，大约1分钟左右，下载完成，过程中需要输入密码，其他无需任何操作： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 卸载有安装就要有卸载，打开终端，复制粘贴： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot; 其实只用把上面安装的install换成uninstall就行了。 使用Homebrew 常用命令，下面以安装 git 为例（使用 brew 安装默认安装软件包的最新版本） 123456789101112131415161718安装任意软件包：brew install git卸载已安装软件包：brew uninstall git搜索可用软件包：brew search git查看任意软件包信息：brew info git更新已安装的软件包：brew upgrade git查看所有已安装的软件包：brew list更新 Homebrew：brew update查看 HomeBrew 版本：brew -vHomeBrew 帮助信息：brew -h 使用 brew -h 看下官方帮助： 123456789101112131415161718192021222324$ brew -hExample usage: brew search [TEXT|/REGEX/] brew info [FORMULA...] brew install FORMULA... brew update brew upgrade [FORMULA...] brew uninstall FORMULA... brew list [FORMULA...]Troubleshooting: brew config brew doctor brew install --verbose --debug FORMULAContributing: brew create [URL [--no-fetch]] brew edit [FORMULA...]Further help: brew commands brew help [COMMAND] man brew https://docs.brew.sh 友情提示在Mac OS X 10.11系统以后，/usr/local/等系统目录下的文件读写是需要系统root权限的，以往的Homebrew安装如果没有指定安装路径，会默认安装在这些需要系统root用户读写权限的目录下，导致有些指令需要添加sudo前缀来执行，比如升级Homebrew需要：sudo brew update 推荐: 安装Homebrew时对安装路径进行指定，直接安装在不需要系统root用户授权就可以自由读写的目录下 1/usr/bin/ruby &lt;install path&gt; -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 下面是我的 HomeBrew 的版本： 123$ brew -vHomebrew 1.6.0Homebrew/homebrew-core (no git repository) 默认安装的所有的命令都在/usr/local/bin目录下，安装文件都在/usr/local/Cellar下，对应的配置文件都在/usr/local/etc下 1.3 CakebrewCakebrew 是 HomeBrew 的 GUI 版本，提供图形化的方式安装和管理软件包，安装方式： 1brew cask install cakebrew 1.4 homebrew-caskhomebrew-cask安装常用软件，比在网上下载安装文件安装的优势在于：（1）节省下载安装包的过程，一行命令即可安装（2）一些在网上搜不到安装文件的软件也可以通过这种方法安装 12brew tap phinze/homebrew-caskbrew install brew-cask 使用方法：将上面的brew换成brew cask即可，如 1brew cask install qq 使用 brew cask 安装常用的软件： brew cask 搜索地址 https://caskroom.github.io/search 12345678910111213141516171819202122232425262728brew cask install yybrew cask install qqbrew cask install dash # 帮助文档brew cask install atombrew cask install sequel-pro # mysql可视化工具brew cask install sourcetree # git可视化工具brew cask install neteasemusic # 网易云音乐brew cask install android-file-transfer # android 传输工具brew cask install android-studiobrew cask install intellij-ideabrew cask install visual-studio-codebrew cask install mockplus # 比较不错的画原型工具brew cask install alfred # 小红帽brew cask install the-unarchiver # 压缩工具brew cask install thunder # 迅雷brew cask install mplayerx # 播放器brew cask install iterm2 # mac上最好用的终端brew cask install cd-to # 当前目录在终端显示brew cask install duet # ipad做外接显示器brew cask install ckb # 海盗船机械键盘驱动brew cask install shadowsocksx # 翻墙工具brew cask install firefox # 火狐brew cask install foxmail # 邮箱客户端brew cask install rdm # redis 客户端brew cask install typora # markdown工具brew cask install macdownbrew cask install cyberduck # ftp工具brew cask install bearychat 2、iTerm22.1 简介ITERM2 是 MAC 下最好的终端工具。直接去官网下载安装包安装即可使用。 2.2 iTerm2 常用快捷键 切换 tab：⌘+← ，⌘+→ ，⌘+{ ， ⌘+} ，⌘+数字直接定位到该 tab 新建 tab：⌘+t 顺序切换 pane：⌘+[ ， ⌘+] 按方向切换 pane：⌘+Option+方向键 切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分 智能查找，支持正则查找：⌘+f 3、安装OH MY ZSH安装ZSH 是一种Shell指令集，Mac 自带 ZSH 的安装。但 Oh my zsh 可以让你能更简便的配置 ZSH。 安装方式如下: 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 等待安装完成即可 配置设置 zsh 为系统的默认的 shell 1chsh -s /bin/zsh 更改zsh主题编辑 ~/.zshrc ，将文本中的 ZSH_THEME 修改为如下（个人推荐主题：ys） 1ZSH_THEME=\"ys\" 注：主题文件在 ~/.oh-my-zsh/themes 目录 4、安装JDK安装通过 HomeBrew 安装 JDK 安装 jdk8 brew cask info java8 安装 jdk9 brew cask info java9 也可以通过官网下载安装包安装 上述两个文件安装完成后，执行下述命令 123echo \"alias setJdk9='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk9.0.4.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"alias setJdk8='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home\" &gt;&gt; ~/.zshrc 这样在命令行中默认设置当前环境变量为 JAVA 8 , 当我们需要切换到 JAVA 9 时只需在命令行中执行命令 setJdk9 即可 。 5、安装 Maven安装Maven 是Java生态中用来构建项目的工具。通过brew安装 1brew install maven 等待安装完成后即可 验证在命令行中输入下述命令验证MAVEN是否正确安装 1234567$ mvn -vApache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)Maven home: /usr/local/Cellar/maven/3.5.3/libexecJava version: 1.8.0_161, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: \"mac os x\", version: \"10.13.4\", arch: \"x86_64\", family: \"mac\" 如果有以上输出内容即标识安装完成 配置在 ~/.m2 目录下创建 settings.xml 文件，使用阿里云的 maven 仓库，内容如下 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt;&lt;/pluginGroups&gt; &lt;proxies&gt;&lt;/proxies&gt; &lt;servers&gt;&lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;JDK-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;JDK-1.8&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 6、安装 RedisRedis 是一款基于数据结构的内存数据库。在我们的项目中被用作高速集中式缓存的解决方案。 安装1brew install redis 等待安装完成即可 验证在命令行中输入下述命令查看 reids 版本 12$ redis-server -v Redis server v=2.8.3 sha=00000000:0 malloc=libc bits=64 build=e836d8ad888e21a1 如果有以上输出内容即表示安装完成 7、安装MySQLMysql 是业界主流的开源关系型数据库。在我们项目中用以持久化用户及系统数据。 安装1brew install mysql 等待安装完成即可 验证12$ mysql -Vmysql Ver 14.14 Distrib 5.6.15, for osx10.9 (x86_64) using EditLine wrapper 如果有以上输出内容即表示安装完成 8、安装 ElasticSearch安装Elasticsearch(简称ES）是一款基于lucene的全文搜索中间件。用于处理在大量文本中通过关键字搜索的场景（例如搜索商品、店铺等）。先在下面的链接中下载安装包（已集成相关插件）后解压, 将解压后的文件夹放到你想安装的目录。通过 brew 安装5.6版的 ES： 1brew install elasticsearch@5.6 验证打开Iterm2，进入 elasticsearch的安装目录，执行以下命令 1$ ./elasticsearch 就可以看到启动日志了 9、安装Nginx安装Nginx 是一款轻量的高性能的Http与反向代理服务器。可被用作转发页面的请求至后台的Tomcat服务器 1brew install nginx 等待安装完成即可 验证在命令行中输入下述命令验证 Nginx 是否正确安装 (版本可能有所不同) 12345$ nginx -Vnginx version: nginx/1.6.3built by clang 6.1.0 (clang-602.0.49) (based on LLVM 3.6.0svn)TLS SNI support enabledconfigure arguments: --prefix=/usr/local/Cellar/nginx/1.6.3 --with-http_ssl_module --with-pcre --with-ipv6 --sbin-path=/usr/local/Cellar/nginx/1.6.3/bin/nginx --with-cc-opt=&apos;-I/usr/local/Cellar/pcre/8.36/include -I/usr/local/Cellar/openssl/1.0.2a-1/include&apos; --with-ld-opt=&apos;-L/usr/local/Cellar/pcre/8.36/lib -L/usr/local/Cellar/openssl/1.0.2a-1/lib&apos; --conf-path=/usr/local/etc/nginx/nginx.conf --pid-path=/usr/local/var/run/nginx.pid --lock-path=/usr/local/var/run/nginx.lock --http-client-body-temp-path=/usr/local/var/run/nginx/client_body_temp --http-proxy-temp-path=/usr/local/var/run/nginx/proxy_temp --http-fastcgi-temp-path=/usr/local/var/run/nginx/fastcgi_temp --http-uwsgi-temp-path=/usr/local/var/run/nginx/uwsgi_temp --http-scgi-temp-path=/usr/local/var/run/nginx/scgi_temp --http-log-path=/usr/local/var/log/nginx/access.log --error-log-path=/usr/local/var/log/nginx/error.log --with-http_gzip_static_module 修改配置文件12345678910111213141516171819202122#user nobody;worker_processes 2;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip on; include servers/*.conf;&#125; 10、安装 SEQUEL PROSequel Pro 是一款免费的 MySQL 的图形管理工具。 安装在官网可下载最新版本 11、安装 IntelliJ IDEAIntelliJ IDEA 业界公认为最好的 Java 开发工具之一 安装【官网】，网上有很多破解方法，如果资金允许请支持正版 12、安装 Zookeeper安装通过 brew 安装 1brew install zookeeper 13、LaunchRocket简介是一个帮助管理Homebrew安装的服务的软件，比如你使用brew安装的Mysql、Redis、MongoDB，LaunchRocket 可以管理这些服务的生命周期和启动方式（自启动、手动启动），传统方式需要使用命令行的命令，而使用LaunchRocket则可以在图形界面中进行管理。 安装brew 安装 1brew cask install launchrocket 14、一些其他实用软件办公：1234567891011121314markdown 编辑器：BoostNote、Typora、YuWriter、Mou文本编辑工具：Atom、Visual Studio Code、Sublime时间/项目管理工具：2Do、OmniPlan、OmniForce流程图绘制：OmniGraffle脑图绘制：Xmind、MindNode、iThoughtsX文稿编辑/演示： KeyNote、Pages、Scrivener、Quiver状态栏图标隐藏工具：Bartender3压缩工具：Dr.Unarchiver技术文档离线阅读：Dash效率搜索：Alfred3数据库管理工具：Sequel Pro、Navicat、TablePlusGit 的 GUI 工具：SourceTree、GitUpREST 客户端：Postman、PawHosts 切换管理工具：SwitchHosts 上班必备12社交软件：微信、QQ、钉钉上班听音乐：网易云音乐、酷我音乐、QQ音乐","categories":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/categories/mac/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/tags/mac/"}]},{"title":"IDEA远程debug","slug":"IDEA远程DEBUG","date":"2017-09-21T15:20:36.000Z","updated":"2018-12-07T13:54:29.484Z","comments":true,"path":"2017/09/21/IDEA远程DEBUG/","link":"","permalink":"https://blog.milk4j.com/2017/09/21/IDEA远程DEBUG/","excerpt":"","text":"一. 背景：在测试工作中，为方便发现代码中的逻辑问题，尝试使用远程debug模式，在测试过程中走查代码，不仅可以辅助测试减少与开发的沟通成本，更便于了解业务提升测试深度。 二. 配置方式： 调试的配置方式主要为设置JVM的参数，使之工作在debug模式下，常用参数为： 1-Xdebug -Xrunjdwp:transport=dt_socket,address=8012,server=y,suspend=n 服务器端配置： 若项目为web项目，可在tomcat的启动程序如catalina.sh中添加如下： 1CATALINA_OPTS=\"-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=28888\" 若项目为javaapp项目，可在项目的default文件中添加如下： 123if [-z \"$XDEBUG_ADDRESS\"]; then JAVA_OPTS=\"$&#123;JAVA_OPTS&#125; -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=28888\"fi idea配置 打开idea中的run/debug configurations, 选择remote类型，地址配置为服务器地址，端口配置为上述配置参数中的address 重启项目，即可开启远程debug模式 三. 参数解释： JAVA支持调试功能，并提供了一个简单的调试工具JDB，其可支持设置断点及线程级的调试； 各参数解释： -Xdebug是通知JVM工作在DEBUG模式下 -Xrunjdwp是通知JVM使用(java debug wire protocol)来运行调试环境。该参数同时了一系列的调试选项： transport指定了调试数据的传送方式，dt_socket是指用SOCKET模式，另有dt_shmem指用共享内存方式，其中，dt_shmem只适用于Windows平台。 server参数是指是否支持在server模式的VM中. onthrow指明，当产生该类型的Exception时，JVM就会中断下来，进行调式。该参数可选。 launch指明，当JVM被中断下来时，执行的可执行程序。该参数可选 suspend指明，是否在调试客户端建立起来后，再执行JVM。 onuncaught(=y或n)指明出现uncaught exception 后，是否中断JVM的执行.","categories":[{"name":"idea","slug":"idea","permalink":"https://blog.milk4j.com/categories/idea/"}],"tags":[{"name":"idea","slug":"idea","permalink":"https://blog.milk4j.com/tags/idea/"},{"name":"远程debug","slug":"远程debug","permalink":"https://blog.milk4j.com/tags/远程debug/"}]},{"title":"Hexo基本使用","slug":"Hexo基本使用","date":"2015-04-21T15:20:36.000Z","updated":"2018-10-22T02:18:04.969Z","comments":true,"path":"2015/04/21/Hexo基本使用/","link":"","permalink":"https://blog.milk4j.com/2015/04/21/Hexo基本使用/","excerpt":"","text":"官网 Hexo| 文档 documentation | 社区 troubleshooting | Git地址 GitHub. 快速入门新建文章1$ hexo new \"My New Post\" 详细说明: Writing 运行1$ hexo server 详细说明: Server 生成静态文件1$ hexo generate 详细说明: Generating 发布到远程站点1$ hexo deploy 详细说明: Deployment","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/tags/hexo/"}]}]}