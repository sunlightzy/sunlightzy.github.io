{"meta":{"title":"Jerry Simple","subtitle":null,"description":null,"author":"John Doe","url":"https://blog.milk4j.com"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-10-21T15:06:58.893Z","updated":"2018-10-21T15:06:58.892Z","comments":false,"path":"/404.html","permalink":"https://blog.milk4j.com//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-10-21T15:07:09.476Z","updated":"2018-10-21T15:07:09.475Z","comments":false,"path":"about/index.html","permalink":"https://blog.milk4j.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"Github仓库","date":"2018-10-21T16:49:07.578Z","updated":"2018-10-21T16:49:07.578Z","comments":false,"path":"repository/index.html","permalink":"https://blog.milk4j.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-22T16:07:59.439Z","updated":"2018-10-22T16:07:59.436Z","comments":false,"path":"tags/index.html","permalink":"https://blog.milk4j.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-10-21T15:07:19.450Z","updated":"2018-10-21T15:07:19.450Z","comments":false,"path":"categories/index.html","permalink":"https://blog.milk4j.com/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-10-21T15:06:46.286Z","updated":"2018-10-21T15:06:46.286Z","comments":false,"path":"books/index.html","permalink":"https://blog.milk4j.com/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-21T15:07:32.536Z","updated":"2018-10-21T15:07:32.536Z","comments":true,"path":"links/index.html","permalink":"https://blog.milk4j.com/links/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL的一些遗忘点","slug":"MySQL的一些遗忘点","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-03T13:54:26.783Z","comments":true,"path":"2018/10/31/MySQL的一些遗忘点/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/MySQL的一些遗忘点/","excerpt":"","text":"一、Group By 和 Order By 一起使用order by 的列，必须是出现在group by 子句里的列 123456789SELECT MAX( `id` )FROM `order`GROUP BY `order_code` , `created_at`-- order by 的列，必须是出现在 group by 子句里的列 ORDER BY `created_at` DESC;","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"Junit","slug":"Junit","permalink":"https://blog.milk4j.com/tags/Junit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"}]},{"title":"SpringBoot Junit单元测试","slug":"SpringBoot Junit单元测试","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-03T08:51:50.530Z","comments":true,"path":"2018/10/31/SpringBoot Junit单元测试/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot Junit单元测试/","excerpt":"","text":"一、JUnit中的注解 @BeforeClass：针对所有测试，只执行一次，且必须为static void @Before：初始化方法，执行当前测试类的每个测试方法前执行。 @Test：测试方法，在这里可以测试期望异常和超时时间 @After：释放资源，执行当前测试类的每个测试方法后执行 @AfterClass：针对所有测试，只执行一次，且必须为static void @Ignore：忽略的测试方法（只在测试类的时候生效，单独执行该测试方法无效） @RunWith:可以更改测试运行器 ，缺省值 org.junit.runner.Runner 一个单元测试类执行顺序为： @BeforeClass –&gt; @Before –&gt; @Test –&gt; @After –&gt; @AfterClass 每一个测试方法的调用顺序为： @Before –&gt; @Test –&gt; @After","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"Junit","slug":"Junit","permalink":"https://blog.milk4j.com/tags/Junit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"}]},{"title":"SpringBoot+H2+Mybatis单元测试整合和坑","slug":"SpringBoot+H2+Mybatis单元测试整合和坑","date":"2018-10-31T05:59:00.000Z","updated":"2018-10-31T08:46:11.871Z","comments":true,"path":"2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","excerpt":"","text":"Maven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 配置文件1234567891011spring: datasource: driver-class-name: org.h2.Driver url: jdbc:h2:mem:testdb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false username: root # 随便填 password: 123456 # 随便填 schema: classpath:db/schema.sql # 建表SQL语句 data: classpath:db/data.sql # 数据导入SQL语句 platform: h2 profiles: active: test 然后在src/test/resources文件夹下面新建一个文件夹db ,然后新建 schema.sql和data.sql schema.sql 文件是建表语句,内容不能为空,否则报错 data.sql文件是数据导入的SQL语句,内容不能为空,否则报错 注意事项一、不支持表级别的Comment 建表SQL如下： 12345678CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除') ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 列名后面的COMMENT是支持的，但是最后面的 ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= &#39;区域路线信息列表&#39; 中的COMMENT不支持。删掉后面的COMMENT即可。 二、只支持最普通的引索结构,不支持BTREE引索结构 123456789CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除', PRIMARY KEY (`Id`) USING BTREE,) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 这种情况去掉 USING BTREE ,使用普通的引索就好了 三、插入语句的单引号中的\\’不支持 有如下SQL，其中一个字段存的里面带有单引号： 12345678910111213141516INSERT INTO `testTable`VALUES ( '1', '部门权限', 'LoginName=\\'&#123;1&#125;\\'', '1', '2', NULL, NULL, '2016-05-27 14:30:49', '1', '1', NULL, '1' ); MySQL支持双引号包含字符串，可以把内容中包含的单引号改为双引号，但其他情况可能会涉及到业务调整。另外，不能将包含字符串的单引号改为双引号，H2会把双引号中的内容当做列名处理。 四、H2 的 UNIQUE KEY是数据库级别的 H2 的 UNIQUE KEY不是表级别的，MySQL是表级别的，转为H2后容易出现UNIQUE KEY重复。删掉UNIQUE KEY或者修改KEY的名称即可。 五、无法使用子查询 目前没有办法解决,尽量避免使用吧","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"},{"name":"h2","slug":"h2","permalink":"https://blog.milk4j.com/tags/h2/"}]},{"title":"Docker安装nginx","slug":"Docker安装nginx","date":"2018-10-22T04:34:08.000Z","updated":"2018-10-24T09:53:47.517Z","comments":true,"path":"2018/10/22/Docker安装nginx/","link":"","permalink":"https://blog.milk4j.com/2018/10/22/Docker安装nginx/","excerpt":"","text":"方式一：通过 pull 仓库镜像一、下载镜像1docker pull nginx 二、使用镜像创建容器1234567891011121314151617181920212223242526cd ~mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf#www目录将映射为nginx容器配置的虚拟目录#logs目录将映射为nginx容器的日志目录#conf目录里的配置文件将映射为nginx容器的配置文件#找一份默认的 nginx.conf 配置文件放在 conf 目录下,否则下面启动会报错docker run -p 80:80 --name web -v $PWD/www:/www -v $PWD/logs:/wwwlogs -d nginxdocker cp web:/etc/nginx/nginx.conf #删除容器后再运行下面的命令docker run -p 80:80 --name web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/conf/servers:/etc/nginx/conf.d -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~#docker inspect [容器名|id]docker inspect mynginx 命令说明： -p 80:80：将容器的80端口映射到主机的80端口 –name web：将容器命名为web -v $PWD/www:/www：将主机中当前目录下的www挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf：将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs：将主机中当前目录下的logs挂载到容器的/wwwlogs 方式二：通过 Dockerfile构建构建准备工作123mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/confcd ~/nginxvi Dockerfile 在 Dockerfile 中输入如下内容：123456789101112131415161718#指定使用那个基础镜像FROM centosMAINTAINER ginkgoLABEL Discription=\"基于centos的nginx镜像\" version=\"1.0\"WORKDIR /usr/local/srcRUN yum install -y wgetRUN wget http://nginx.org/download/nginx-1.8.0.tar.gzRUN tar -zxvf nginx-1.8.0.tar.gzWORKDIR nginx-1.8.0#安装nginx所依赖的包RUN yum -y install gcc-c++RUN yum -y install pcre pcre-develRUN yum -y install zlib zlib-develRUN yum -y install openssl openssl-devel libssl-devRUN ./configureRUN makeRUN make installEXPOSE 80 通过Dockerfile 构建一个镜像1234# -t 镜像名 , \".\" 是Dockerfile 所在的目录，可以使用绝对路径docker build -t ginkgo/nginx .#查看镜像docker images 构建|运行容器1234567891011121314151617#找一份默认的 nginx.conf 配置文件放在 ~/nginx/conf 目录下,否则下面启动会报错docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~docker inspect [容器名|id]","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"Kotlin在IntelliJ Idea中无法生成 spring-configuration-metadata.json 文件","slug":"用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件","date":"2018-09-05T11:12:09.000Z","updated":"2018-10-31T01:32:08.944Z","comments":true,"path":"2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","link":"","permalink":"https://blog.milk4j.com/2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","excerpt":"","text":"问题描述在百度搜索关键词,搜索到了 Stack Overflow 有相关问题 spring-configuration-metadata.json file is not generated in IntelliJ Idea for Kotlin @ConfigurationProperties class 原文链接: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko 按照里面的方法试了一下,失败了,然后继续百度,在spring-boot的官方文档中找到了相关线索, 直达链接: https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties 在spring官方文档中找到了kotlin的官方示例,链接地址: https://kotlinlang.org/docs/reference/kapt.html#using-in-maven 下面是我参考上面的文档所得出来的可用方案 解决方案一、添加插件在pom文件中添加插件,没有写版本号是因为项目继承了spring-boot-starter-parent 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;proc&gt;none&lt;/proc&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- Replacing default-compile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;!-- Replacing default-testCompile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-testCompile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;configuration&gt; &lt;args&gt; &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt; &lt;/args&gt; &lt;compilerPlugins&gt; &lt;plugin&gt;spring&lt;/plugin&gt; &lt;/compilerPlugins&gt; &lt;jvmTarget&gt;$&#123;java.version&#125;&lt;/jvmTarget&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;kapt&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;kapt&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sourceDirs&gt; &lt;sourceDir&gt;src/main/kotlin&lt;/sourceDir&gt; &lt;sourceDir&gt;src/main/java&lt;/sourceDir&gt; &lt;/sourceDirs&gt; &lt;annotationProcessorPaths&gt; &lt;!-- Specify your annotation processors here. --&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;test-compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt; &lt;version&gt;1.2.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt;&lt;/plugins&gt; 二、使用插件生成我之前也是使用了同样的插件,但是始终生成不出来文件,直到看了kotlin官方文档我才发现有这么一句话 文字的意思是: “请注意，kapt仍然不支持IntelliJ IDEA自己的构建系统。当你想要重新运行注释处理器时，可以从“Maven Projects”工具栏启动构建。” 很是坑爹啊,你也不标红也不加粗是想怎样啊 好了,那就按照他说的做吧, 双击下面的插件按钮就可以生产spring-configuration-metadata.json文件了 参考文档: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties &lt;https://kotlinlang.org/docs/reference/kapt.html","categories":[{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/categories/kotlin/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"},{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/tags/kotlin/"}]},{"title":"Docker基本使用","slug":"Docker基本使用","date":"2018-06-22T03:26:02.000Z","updated":"2018-10-22T11:13:20.539Z","comments":true,"path":"2018/06/22/Docker基本使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/22/Docker基本使用/","excerpt":"","text":"一. docker使用1. docker ps 查看运行中的容器2. docker images 查看docker镜像3. docker rm id(容器id) 删除容器（容器id可以通过docker ps查看，容器必须停止后才能删除）3.1 删除全部的容器 docker rm docker ps -a -q4. docker stop id(容器id) 停止容器运行5. docker rmi id(镜像id) 删除镜像6. docker pull ubuntu:16.04(镜像名称:版本号) 下载镜像7. docker run -it ubuntu:16.04 创建并运行容器容器 -t 表示在新容器内指定一个伪终端或终端 -i 表示允许我们对容器内的 (STDIN) 进行交互 -p 指定映射端口 -d 在后台运行容器并打印容器ID 7.1 docker run -dit ubuntu:16.04 创建并后台运行容器7.2 docker run -ditp 8080:8080（主机端口:容器端口） ubuntu:16.04 创建并后台运行容器且映射容器的端口8. docker attach id(容器id) 进入正在运行中的容器环境9. 退出容器9.1 exit 直接退出容器并终止容器运行9.2 [ctrl+p]+[ctrl+q]（快捷键） 退出容器，但是不会终止容器运行10. docker commit -m’版本标识’ id(容器id) ubuntu:16.04(镜像与版本号) 提交镜像且生成镜像（可以通过该命令把搭建好的容器打包成一个新的镜像或者覆盖原镜像（即是修改原镜像内容，生成的镜像名与版本号相同就可以直接覆盖））","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"ElasticSearch Rest 客户端使用(长文,待续...)","slug":"ElasticSearch-Rest-客户端使用","date":"2018-06-20T12:36:39.000Z","updated":"2018-10-31T01:38:12.054Z","comments":true,"path":"2018/06/20/ElasticSearch-Rest-客户端使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/20/ElasticSearch-Rest-客户端使用/","excerpt":"","text":"起步阅读文档须知,文档基于Elasticsearch 6.x,阅读要求,熟悉 ElasticSearch 的语法 兼容性高级客户端要求最低的 java 版本是1.8 ，它依赖 Elasticsearch 的核心工程，客户端的版本应该和 Elasticsearch 的版本保持一致，高级客户端和 TransportClient【TCP 连接客户端】 接受一样的请求参数，并且返回一样的响应结果，如果你想从 TransportClient 客户端迁移到 REST 客户端，请参考迁移手册 高级客户端保证能够与运行在相同主要版本和更高版本上的Elasticsearch节点进行通信。它不需要与通信的Elasticsearch节点处于相同的版本，因为它是向前兼容的，这意味着它支持与更高版本的Elasticsearch进行通信，而不是与其开发的版本进行通信。 6.0 客户端能够与任何6.x版本的 Elasticsearch节点通信，而6.1客户端肯定能够与6.1,6.2和任何更高版本的6.x版本通信，但在与老版的Elasticsearch节点通信时可能存在不兼容问题版本，例如6.1和6.0，6.1客户端为一些 api 添加了新的请求体字段支持，然而6.0节点却不支持。 建议在将Elasticsearch集群升级到新的主版本时升级高级客户端，因为REST API中断更改可能会导致意外结果，具体取决于请求所针对的节点，并且新添加的API仅支持新版本的客户端。一旦集群中的所有节点都升级到新的主版本，客户端应保持同步更新。 Java api 文档文档地址：&lt;https://artifacts.elastic.co/javadoc/org/elasticsearch/client/elasticsearch-rest-high-level-client/6.3.1/index.html&gt; maven 仓库高级Java REST客户端托管在 Maven Central上。所需的最低Java版本是1.8。 高级REST客户端与Elasticsearch具有相同的发布周期。将版本替换为所需的客户端版本。 如果您正在寻找SNAPSHOT版本，可以通过https://snapshots.elastic.co/maven/获取Elastic Maven Snapshot存储库。 Maven 配置12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.1&lt;/version&gt;&lt;/dependency&gt; Gradel 配置123dependencies &#123; compile 'org.elasticsearch.client:elasticsearch-rest-high-level-client:6.3.1'&#125; 依赖高级客户端依赖下面的组件及其传递依赖性： org.elasticsearch.client:elasticsearch-rest-client org.elasticsearch:elasticsearch 初始化一个RestHighLevelClient实例需要一个低级客户端的Builder 来构建如下： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"localhost\", 9200, \"http\"), new HttpHost(\"localhost\", 9201, \"http\"))); 高级客户端将在内部创建用于执行请求的低级客户端，低级客户端基于框架提供的builder，并管理其生命周期。 高级客户端实例应该在不再需要时关闭，以便正确释放它使用的所有资源，以及底层的http客户端实例及其线程。这可以通过close 方法完成，该方法将关闭内部RestClient实例。 1client.close(); Document APIJava高级REST客户端支持以下文档API： 单文档API： index api - 索引API get api - 获取API delete api - 删除API update api - 更新API 多文档API bulk api - 批量操作 api Multi-Get API - 批量获取 api Index APIIndex 请求体一个引索请求需要下面的参数： 12345678910IndexRequest request = new IndexRequest( \"posts\", //index 名 \"doc\", //type 名 \"1\"); //文档 IDString jsonString = \"&#123;\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"&#125;\";request.source(jsonString, XContentType.JSON);//设置 string 类型的文档source 构建文档 source 的方式除了String上面显示的示例之外，还可以以不同方式提供文档源 ： 方式一：以 Map 的方式提供的文档源，Map自动转换为JSON格式 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"user\", \"kimchy\");jsonMap.put(\"postDate\", new Date());jsonMap.put(\"message\", \"trying out Elasticsearch\");IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(jsonMap); 方式二：以XContentBuilder对象方式提供，Elasticsearch内置了helper生成JSON内容 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(\"user\", \"kimchy\"); builder.timeField(\"postDate\", new Date()); builder.field(\"message\", \"trying out Elasticsearch\");&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(builder); 方式三：以键值对方式提供，转换为JSON格式 1234IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"user\", \"kimchy\", \"postDate\", new Date(), \"message\", \"trying out Elasticsearch\"); 可选参数可以选择以下参数： 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1));request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);request.setRefreshPolicy(\"wait_for\"); 设置版本 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 设置文档操作类型 12request.opType(DocWriteRequest.OpType.CREATE); request.opType(\"create\"); 文档执行之前，设置 pipeline 名 1request.setPipeline(&quot;pipeline&quot;); 同步执行方式1IndexResponse indexResponse = client.index(request); 异步执行方式索引请求的异步执行需要将IndexRequest 实例和ActionListener实例都传递给异步方法： 123456789ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;IndexResponse indexResponse = client.index(request); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 引索响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 123456789101112131415161718String index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //创建文档操作&#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //更新文档操作&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; //处理成功分片数小于总分片数的情况&#125;if (shardInfo.getFailed() &gt; 0) &#123;//理潜在的失败情况 for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 如果存在文档版本冲突，则会抛出ElasticsearchException： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .version(1);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; 如果已存在具有相同索引，类型和ID的文档，opType设置为create也会发生冲突： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .opType(DocWriteRequest.OpType.CREATE);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Get APIGet 请求体构建 GetRequest 的参数如下： 1GetRequest getRequest = new GetRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置返回响应不包含任何字段，默认情况下返回响应包含该所有字段 1request.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回响应包含哪些字段 12345String[] includes = new String[]&#123;\"message\", \"*Date\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置返回响应不包含哪些字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;\"message\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置检索哪些存储字段 123request.storedFields(\"message\"); //为特定存储字段配置检索 (要求在映射中单独存储字段)GetResponse getResponse = client.get(request);String message = getResponse.getField(\"message\").getValue();//获取message存储的值 (要求将字段单独存储在映射中) 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置偏好 1request.preference(\"preference\"); 设置实时标识，默认 true 1request.realtime(false); 设置每次获取文档之前是否执行刷新操作，默认 false 1request.refresh(true); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1GetResponse getResponse = client.get(getRequest); 异步执行get请求的异步执行需要将GetRequest 实例和ActionListener实例都传递给异步方法 12345678910ActionListener&lt;GetResponse&gt; listener = new ActionListener&lt;GetResponse&gt;() &#123; @Override public void onResponse(GetResponse getResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;GetResponse getResponse = client.get(getRequest); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); byte[] sourceAsBytes = getResponse.getSourceAsBytes(); &#125; else &#123; //处理未找到文档的方案。注意，虽然返回的响应具有404状态代码，但他会返回一个有效GetResponse而不是抛出异常。此类响应不包含任何文档字段，而且isExists方法返回false。&#125; 当对不存在的索引(index)执行get请求时，响应会有404状态代码，但是会抛出ElasticsearchException，需要按如下方式处理： 12345678GetRequest request = new GetRequest(\"does_not_exist\", \"doc\", \"1\");try &#123; GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果请求特定版本的文档，并且现有文档具有不同的版本号，则会引发版本冲突： 12345678try &#123; GetRequest request = new GetRequest(\"posts\", \"doc\", \"1\").version(2); GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //处理版本冲突 &#125;&#125; Exists API如果文档存在就返回 true，否则返回 false Exists Request它的GetRequest就像Get API一样。支持所有可选参数 。由于exists()只返回true或false，所有建议关闭返回_source和任何存储的字段，以便请求更加轻量： 123456GetRequest getRequest = new GetRequest( \"posts\", \"doc\", \"1\"); getRequest.fetchSourceContext(new FetchSourceContext(false)); //不返回_sourcegetRequest.storedFields(\"_none_\"); //不返回存储字段 同步执行1boolean exists = client.exists(getRequest); 异步执行123456789ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.existsAsync(getRequest, listener); Delete APIDelete RequestDeleteRequest 参数如下： 1DeleteRequest request = new DeleteRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1DeleteResponse deleteResponse = client.delete(request); 异步执行123456789ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.deleteAsync(request, listener); Delete Response返回的DeleteResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 它还可以检查文档是否存在 12345DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"does_not_exist\");DeleteResponse deleteResponse = client.delete(request);if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) &#123; //如果找不到要删除的文档&#125; 如果请求的文档版本冲突，会抛ElasticsearchException异常 12345678try &#123; DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"1\").version(2); DeleteResponse deleteResponse = client.delete(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; Update APIUpdateRequest参数如下： 1UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\"); Update API允许使用脚本或传递部分文档来更新现有文档。 使用脚本更新文档使用内联脚本 12345Map&lt;String, Object&gt; parameters = singletonMap(\"count\", 4); //使用Map对象作为脚本参数Script inline = new Script(ScriptType.INLINE, \"painless\", \"ctx._source.field += params.count\", parameters); //使用painless语言和提供的参数创建内联脚本UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");request.script(inline); //将脚本设置为更新请求 或者使用存储在es 中的脚本 12Script stored =new Script(ScriptType.STORED, null, \"increment-field\", parameters);//使用存储在 es 中的painless脚本，脚本名为increment-fieldrequest.script(stored); 传递部分文档作为参数来更新文档当使用部分文档来更新现有的文档时，部分文档将与现有文档合并。 部分文档可以以不同方式提供： 123456UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");String jsonString = \"&#123;\" + \"\\\"updated\\\":\\\"2017-01-01\\\",\" + \"\\\"reason\\\":\\\"daily update\\\"\" + \"&#125;\";request.doc(jsonString, XContentType.JSON);//用json格式的字符串作为部分文档源 以 Map 提供部分文档源，会被自动转化成 json 格式，如下 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"updated\", new Date());jsonMap.put(\"reason\", \"daily update\");UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(jsonMap); 用XContentBuilder对象作为部分文档源，Elasticsearch内置的 helpers 会自动将它转化为 json 文档 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(\"updated\", new Date()); builder.field(\"reason\", \"daily update\");&#125;builder.endObject();UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(builder); 使用键值对作为部分文档源，他会被转换成 json 文本 123UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"updated\", new Date(), \"reason\", \"daily update\"); Upserts如果文档尚不存在，则可以使用以下upsert方法来将它作为新文档插入： 12String jsonString = \"&#123;\\\"created\\\":\\\"2017-01-01\\\"&#125;\";request.upsert(jsonString, XContentType.JSON); 和部分文档更新一样，upsert 方法接受String, Map, XContentBuilder or 键值对作为入参 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置重试更新操作的次数 如果要更新的文档已在更新操作的get和indexing阶段之间的另一个操作更改，则重试 1request.retryOnConflict(3); 设置是否获取新文档内容，默认 false 1request.fetchSource(true); 指定返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;//正则匹配String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定不返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 设置文档版本号 1request.version(2); 设置是否启用noop 检测 1request.detectNoop(false); 指示脚本必须运行，无论文档是否存在，即如果文档尚不存在，脚本将负责创建文档 1request.scriptedUpsert(true); 如果文档不存在，则表明必须将部分文档用作upsert文档 1request.docAsUpsert(true); 设置在执行更新操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); 同步执行1UpdateResponse updateResponse = client.update(request); 异步执行12345678client.updateAsync(request, new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;); UpdateResponse返回的UpdateResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //首次创建文档（upsert）&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; //文档未受更新影响，即未对文档执行任何操作（noop）&#125; UpdateRequest 通过fetchSource方法启用获取文档功能时，响应包含更新文档的来源： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); byte[] sourceAsBytes = result.source(); &#125; else &#123; &#125; 可以检查分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 当对一个不存在的文档执行UpdateRequest时，响应具有404状态代码，会抛出ElasticsearchException，需要按如下方式处理： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"type\", \"does_not_exist\") .doc(\"field\", \"value\");try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果发生文档版本冲突，会抛出异常： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"field\", \"value\") .version(1);try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Bulk APIBulkRequestBulkRequest可用于使用单个请求执行多个索引，更新和/或删除操作 它要求至少将一个操作添加到批量请求： 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(\"posts\", \"doc\", \"1\") .source(XContentType.JSON,\"field\", \"foo\"));request.add(new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON,\"field\", \"bar\"));request.add(new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON,\"field\", \"baz\")); 并且可以添加不同的操作类型BulkRequest： 123456BulkRequest request = new BulkRequest();request.add(new DeleteRequest(\"posts\", \"doc\", \"3\")); request.add(new UpdateRequest(\"posts\", \"doc\", \"2\") .doc(XContentType.JSON,\"other\", \"test\"));request.add(new IndexRequest(\"posts\", \"doc\", \"4\") .source(XContentType.JSON,\"field\", \"baz\")); 可选参数 设置超时时间 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置在索引/更新/删除操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); //可选ActiveShardCount.ALL、 ActiveShardCount.ONE 、 ActiveShardCount.DEFAULT 同步执行1BulkResponse bulkResponse = client.bulk(request); 异步执行123456789ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.bulkAsync(request, listener); BulkResponse响应结果，允许迭代每个结果，如下所示： 123456789101112131415for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; //可以是IndexResponse、UpdateResponse、DeleteResponse，他们可以全部被视为DocWriteResponse实例 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; &#125;&#125; 批量响应提供了一种快速检查一个或多个操作是否失败的方法： 123if（bulkResponse.hasFailures（））&#123; //如果至少有一个操作失败，则返回true&#125; 在这种情况下，有必要迭代所有操作结果，以检查操作是否失败，如果是，则获取相应的失败信息： 123456for（BulkItemResponse bulkItemResponse：bulkResponse）&#123; if（bulkItemResponse.isFailed（））&#123; BulkItemResponse.Failure failure = bulkItemResponse.getFailure（）; &#125;&#125; 批量处理器BulkProcessor提供了一个工具类简化操作，它可以透明地执行添加到 processor 中的 index/update/delete操作。 为了执行请求，BulkProcessor需要以下组件： RestHighLevelClient 此客户端用于执行BulkRequest 和获取BulkResponse BulkProcessor.Listener 在每次BulkRequest执行之前、之后或BulkRequest失败时调用器监听 然后该BulkProcessor.builder方法可用于构建新的BulkProcessor： 1234567891011121314151617181920BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); BulkProcessor.Builder提供了方法来配置BulkProcessor处理请求的行为： 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500);//根据当前添加的操作数设置何时刷新新的批量请求（默认为1000，使用-1禁用它） builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); //根据当前添加的操作内容大小设置何时刷新新的批量请求（默认为5Mb，使用-1禁用它）builder.setConcurrentRequests(0); //设置允许执行的并发请求数（默认为1，使用0只允许执行单个请求）builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); //BulkRequest如果间隔超过，则 设置刷新间隔刷新任何挂起（默认为未设置）builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3));//设置一个最初等待1秒的常量重试策略，最多重试3次。见BackoffPolicy.noBackoff()、BackoffPolicy.constantBackoff()、BackoffPolicy.exponentialBackoff() 提供更多的选择 一旦BulkProcessor被创建，请求可以被添加到processor： 12345678910111213IndexRequest one = new IndexRequest(\"posts\", \"doc\", \"1\"). source(XContentType.JSON, \"title\", \"In which order are my Elasticsearch queries executed?\");IndexRequest two = new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON, \"title\", \"Current status and upcoming changes in Elasticsearch\");IndexRequest three = new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON, \"title\", \"The Future of Federated Search in Elasticsearch\");bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行所有的请求，并且为每次的 BulkRequest 回调BulkProcessor.Listener，监听器提供了访问 BulkRequest 和 BulkResponse 的方法 12345678910111213141516171819202122232425BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); logger.debug(\"Executing bulk [&#123;&#125;] with &#123;&#125; requests\", executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; logger.warn(\"Bulk [&#123;&#125;] executed with failures\", executionId); &#125; else &#123; logger.debug(\"Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds\", executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; //执行失败后调用 logger.error(\"Failed to execute bulk\", failure); &#125;&#125;; 将所有请求添加到BulkProcessor后，需要关闭其实例，有两种关闭方式。 该awaitClose()方法可用于等待所有请求都已处理或指定的等待时间： 1boolean terminated = bulkProcessor.awaitClose（30L，TimeUnit.SECONDS）;//true：如果所有批量请求都已完成，false：在所有批量请求完成之前等待时间已过 close()方法可用于立即关闭BulkProcessor： 1bulkProcessor.close（）; 两种方法在关闭处理器之前刷新已经添加到处理器的请求，并且禁止添加新请求 Multi-Get APImultiGet API 可以在单个请求中执行多个 get 请求 Multi-Get Request获取一个 MultiGetRequest实例，然后添加多个 MultiGetRequest.Item: 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( \"index\", \"type\", \"example_id\")); request.add(new MultiGetRequest.Item(\"index\", \"type\", \"another_id\")); 可选参数multiGet和 get Api支持相同的可选参数. 你可以在 Item上设置可选参数: 设置不返回任何文档，默认返回文档 123request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE) ); 设置返回文档的哪些字段 123456String[] includes = new String[] &#123;\"foo\", \"*r\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 设置不返回文档的哪些字段 123456String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[] &#123;\"foo\", \"*r\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 配置返回指定的存储字段 12345request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .storedFields(\"foo\")); //设置返回存储字段 fooMultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];String value = item.getResponse().getField(\"foo\").getValue(); //获取存储字段foo的值 其他可选参数 12345678910request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_routing\") .routing(\"some_routing\"));//设置路由 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_parent\") .parent(\"some_parent\"));//设置父文档 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_version\") .versionType(VersionType.EXTERNAL)//设置文档版本类型 .version(10123L)); //设置版本号request.preference(\"some_preference\"); //设置偏好request.realtime(false); //设置实时标识，默认为 true request.refresh(true); //获取文档之前执行刷新操作，默认 false 同步执行1MultiGetResponse response = client.multiGet(request); 异步执行123456789101112ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;MultiGetResponse response = client.multiGet(request); MultiGetResponse返回的MultiGetResponse通过getResponses方法可以获取一个 MultiGetItemResponse 列表，列表中的响应与请求的顺序相同，如果 get 成功 MultiGetItemResponse包含一个 GetResponse，如果它失败了会包含一个MultiGetResponse.Failure 1234567891011121314MultiGetItemResponse firstItem = response.getResponses（）[0];assertNull（firstItem.getFailure（））;//如果成功，返回 null GetResponse firstGet = firstItem.getResponse（）; //获取 GetResponseString index = firstItem.getIndex（）;String type = firstItem.getType（）;String id = firstItem.getId（）;if（firstGet.isExists（））//判断文档是否存在 long version = firstGet.getVersion（）; String sourceAsString = firstGet.getSourceAsString（）; Map &lt;String，Object&gt; sourceAsMap = firstGet.getSourceAsMap（）; byte [] sourceAsBytes = firstGet.getSourceAsBytes（）; &#125; else &#123; &#125; 如果请求的 index 不存在，则返回响应会包含一个异常信息 1234567assertNull(missingIndexItem.getResponse()); Exception e = missingIndexItem.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(\"reason=no such index\")); 请求文档版本冲突，则返回响应会包含一个异常信息 12345678910111213MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .version(1000L));MultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];assertNull(item.getResponse()); Exception e = item.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.CONFLICT, ee.status()); assertThat(e.getMessage(), containsString(\"version conflict, current version [1] is \" + \"different than the one provided [1000]\")); Search API高级客户端支持下面的 Search API: Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequest1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); searchRequest.source(searchSourceBuilder); 可选参数12345SearchRequest searchRequest = new SearchRequest(\"posts\"); searchRequest.types(\"doc\"); searchRequest.routing(\"routing\"); searchRequest.indicesOptions(IndicesOptions.lenientExpandOpen());searchRequest.preference(\"_local\"); 使用 SearchBuilder12345SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.termQuery(\"user\", \"kimchy\")); sourceBuilder.from(0); sourceBuilder.size(5); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); 构建查询语句12345678MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(\"user\", \"kimchy\");matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); searchSourceBuilder.query(matchQueryBuilder); 设置排序12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); sourceBuilder.sort(new FieldSortBuilder(\"_uid\").order(SortOrder.ASC)); 文档过滤1234sourceBuilder.fetchSource(false);String[] includeFields = new String[] &#123;\"title\", \"user\", \"innerObject.*\"&#125;;String[] excludeFields = new String[] &#123;\"_type\"&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 字段高亮123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(\"title\"); highlightTitle.highlighterType(\"unified\"); highlightBuilder.field(highlightTitle); HighlightBuilder.Field highlightUser = new HighlightBuilder.Field(\"user\");highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 添加聚合查询123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(\"by_company\") .field(\"company.keyword\");aggregation.subAggregation(AggregationBuilders.avg(\"average_age\") .field(\"age\"));searchSourceBuilder.aggregation(aggregation); 请求建议词123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(\"user\").text(\"kmichy\"); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(\"suggest_user\", termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 分析查询和聚合profile API 可用于为特定搜索分析查询和聚合的执行情况。为了使用它, 必须在 SearchSourceBuilder 上设置profile标志为 true: 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行 SearchRequest 后, 相应的 SearchResponse 将包含分析结果。 同步执行1SearchResponse searchResponse = client.search(searchRequest); 异步执行执行 SearchRequest 也可以以异步方式进行, 以便客户端可以直接返回。用户需要通过将请求和监听器传递给异步搜索方法来指定如何处理响应或潜在故障: 123456789101112ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.searchAsync(searchRequest, listener); 异步方法不会阻止线程，也不会立即返回。完成该操作后, 如果执行成功则回调ActionListener的 onResponse 方法，失败则回调 onFailure` 方法 SearchResponse执行搜索返回的 SearchResponse 提供了有关搜索执行本身以及对返回访问的文档的详细信息。看下有关于请求执行操作的信息, 如 HTTP 状态代码、执行时间或请求是否提前终止或超时: 1234RestStatus status = searchResponse.status();TimeValue took = searchResponse.getTook();Boolean terminatedEarly = searchResponse.isTerminatedEarly();boolean timedOut = searchResponse.isTimedOut(); 其次, 响应还提供有关在分片级别上执行的信息, 提供有关受影响搜索的分片总数以及成功与失败的分片的统计数据。潜在的故障也可以通过迭代 ShardSearchFailure 数组来处理, 如下面的示例所示: 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; 获取搜索命中的文档要获得对返回的文档的访问权限, 我们首先需要得到响应中包含的 SearchHits： 123SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); SearchHits 提供有关所有命中的全局信息, 如命中总数或最大得分: 12long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); 嵌套在 SearchHits 中的是可以迭代的单个搜索结果: 1234SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit&#125; SearchHit 提供对基本信息的访问, 如索引、类型、docId 和每个搜索命中的分数: 1234String index = hit.getIndex();String type = hit.getType();String id = hit.getId();float score = hit.getScore(); 此外, 它还允许您返回文档源, 既可以是简单的 JSON 字符串, 也可以是键/值对的映射。在此映射中,通常键值对的键为字段名, 值为字段值。多值字段作为对象的列表返回, 嵌套对象作为另一个键/值映射。这些案件需要相应地强制执行: 123456String sourceAsString = hit.getSourceAsString();Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();String documentTitle = (String) sourceAsMap.get(\"title\");List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(\"user\");Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(\"innerObject\"); 获取高亮结果可以从结果中获取每个 SearchHit 中高亮显示的文本片段。SearchHit提供对 HighlightField 实例的访问, 其中每一个都包含一个或多个突出显示的文本片段: 1234567SearchHits hits = searchResponse.getHits();for (SearchHit hit : hits.getHits()) &#123; Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); HighlightField highlight = highlightFields.get(\"title\"); Text[] fragments = highlight.fragments(); String fragmentString = fragments[0].string();&#125; 获取聚合结果可以从 SearchResponse 获取聚合结果, 首先获取聚合树的根、聚合对象, 然后按名称获取聚合 12345Aggregations aggregations = searchResponse.getAggregations();Terms byCompanyAggregation = aggregations.get(\"by_company\"); Bucket elasticBucket = byCompanyAggregation.getBucketByKey(\"Elastic\"); Avg averageAge = elasticBucket.getAggregations().get(\"average_age\"); double avg = averageAge.getValue(); 请注意, 如果按名称访问聚合, 则需要根据所请求的聚合类型指定聚合接口, 否则将引发抛出: 1Range range = aggregations.get(\"by_company\"); //这将引发异常, 因为 \"by_company\" 是一个term聚合, 但这里尝试将它一范围聚合取出 还可以将所有的聚合 转化成 map ,以聚合名作为 key 值。在这种情况下,需要显示强制转换到正确的类型: 12Map&lt;String, Aggregation&gt; aggregationMap = aggregations.getAsMap();Terms companyAggregation = (Terms) aggregationMap.get(\"by_company\"); 还有一些 getter 将所有顶层聚合作为列表返回: 1List&lt;Aggregation&gt; aggregationList = aggregations.asList(); 最后, 可以遍历所有聚合, 然后根据它们的类型决定如何进一步处理它们: 1234567for (Aggregation agg : aggregations) &#123; String type = agg.getType(); if (type.equals(TermsAggregationBuilder.NAME)) &#123; Bucket elasticBucket = ((Terms) agg).getBucketByKey(\"Elastic\"); long numberOfDocs = elasticBucket.getDocCount(); &#125;&#125; 获取建议要从 SearchResponse 中返回suggestions, 请使用suggestion 对象作为入口点, 然后检索嵌套的建议对象: 1234567Suggest suggest = searchResponse.getSuggest(); TermSuggestion termSuggestion = suggest.getSuggestion(\"suggest_user\"); for (TermSuggestion.Entry entry : termSuggestion.getEntries()) &#123; for (TermSuggestion.Entry.Option option : entry) &#123; String suggestText = option.getText().string(); &#125;&#125; 获取性能分析结果使用 getProfileResults () 方法从 SearchResponse 检索性能分析结果。此方法返回一个Map,包含 SearchRequest 执行中所涉及的每个分片的 ProfileShardResult 对象。ProfileShardResult 存储在映射中, 使用唯一标识配置文件结果对应的碎片的键. 下面是一个示例代码, 它演示如何循环访问每个分片的所有性能分析结果: 123456Map&lt;String, ProfileShardResult&gt; profilingResults = searchResponse.getProfileResults(); for (Map.Entry&lt;String, ProfileShardResult&gt; profilingResult : profilingResults.entrySet()) &#123; String key = profilingResult.getKey(); ProfileShardResult profileShardResult = profilingResult.getValue(); &#125; ProfileShardResult 对象本身包含一个或多个QueryProfileShardResult: 12345List&lt;QueryProfileShardResult&gt; queryProfileShardResults = profileShardResult.getQueryProfileResults(); for (QueryProfileShardResult queryProfileResult : queryProfileShardResults) &#123; &#125; 12345for (ProfileResult profileResult : queryProfileResult.getQueryResults()) &#123; String queryName = profileResult.getQueryName(); long queryTimeInMillis = profileResult.getTime(); List&lt;ProfileResult&gt; profiledChildren = profileResult.getProfiledChildren(); &#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/tags/elasticsearch/"}]},{"title":"Mac后端开发环境搭建","slug":"Mac后端开发环境搭建","date":"2018-04-14T02:01:56.000Z","updated":"2018-10-24T09:53:47.494Z","comments":true,"path":"2018/04/14/Mac后端开发环境搭建/","link":"","permalink":"https://blog.milk4j.com/2018/04/14/Mac后端开发环境搭建/","excerpt":"","text":"作为一个开发人员，选择 Mac 是一个非常好的选择，首先 Mac 是 Unix 的内核，支持 Unix 内核的命令，使用 Mac 能帮助我们熟悉 Unix 的操作命令 1、HomeBrew1.1 简介Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。 简单点说，Homebrew 是以最简单、最灵活的方式来安装苹果公司在 MacOS 中不包含的 UNIX 工具。 1.2 安装与卸载安装打开终端，复制粘贴，大约1分钟左右，下载完成，过程中需要输入密码，其他无需任何操作： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 卸载有安装就要有卸载，打开终端，复制粘贴： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot; 其实只用把上面安装的install换成uninstall就行了。 使用Homebrew 常用命令，下面以安装 git 为例（使用 brew 安装默认安装软件包的最新版本） 123456789101112131415161718安装任意软件包：brew install git卸载已安装软件包：brew uninstall git搜索可用软件包：brew search git查看任意软件包信息：brew info git更新已安装的软件包：brew upgrade git查看所有已安装的软件包：brew list更新 Homebrew：brew update查看 HomeBrew 版本：brew -vHomeBrew 帮助信息：brew -h 使用 brew -h 看下官方帮助： 123456789101112131415161718192021222324$ brew -hExample usage: brew search [TEXT|/REGEX/] brew info [FORMULA...] brew install FORMULA... brew update brew upgrade [FORMULA...] brew uninstall FORMULA... brew list [FORMULA...]Troubleshooting: brew config brew doctor brew install --verbose --debug FORMULAContributing: brew create [URL [--no-fetch]] brew edit [FORMULA...]Further help: brew commands brew help [COMMAND] man brew https://docs.brew.sh 友情提示在Mac OS X 10.11系统以后，/usr/local/等系统目录下的文件读写是需要系统root权限的，以往的Homebrew安装如果没有指定安装路径，会默认安装在这些需要系统root用户读写权限的目录下，导致有些指令需要添加sudo前缀来执行，比如升级Homebrew需要：sudo brew update 推荐: 安装Homebrew时对安装路径进行指定，直接安装在不需要系统root用户授权就可以自由读写的目录下 1/usr/bin/ruby &lt;install path&gt; -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 下面是我的 HomeBrew 的版本： 123$ brew -vHomebrew 1.6.0Homebrew/homebrew-core (no git repository) 默认安装的所有的命令都在/usr/local/bin目录下，安装文件都在/usr/local/Cellar下，对应的配置文件都在/usr/local/etc下 1.3 CakebrewCakebrew 是 HomeBrew 的 GUI 版本，提供图形化的方式安装和管理软件包，安装方式： 1brew cask install cakebrew 1.4 homebrew-caskhomebrew-cask安装常用软件，比在网上下载安装文件安装的优势在于：（1）节省下载安装包的过程，一行命令即可安装（2）一些在网上搜不到安装文件的软件也可以通过这种方法安装 12brew tap phinze/homebrew-caskbrew install brew-cask 使用方法：将上面的brew换成brew cask即可，如 1brew cask install qq 使用 brew cask 安装常用的软件： brew cask 搜索地址 https://caskroom.github.io/search 12345678910111213141516171819202122232425262728brew cask install yybrew cask install qqbrew cask install dash # 帮助文档brew cask install atombrew cask install sequel-pro # mysql可视化工具brew cask install sourcetree # git可视化工具brew cask install neteasemusic # 网易云音乐brew cask install android-file-transfer # android 传输工具brew cask install android-studiobrew cask install intellij-ideabrew cask install visual-studio-codebrew cask install mockplus # 比较不错的画原型工具brew cask install alfred # 小红帽brew cask install the-unarchiver # 压缩工具brew cask install thunder # 迅雷brew cask install mplayerx # 播放器brew cask install iterm2 # mac上最好用的终端brew cask install cd-to # 当前目录在终端显示brew cask install duet # ipad做外接显示器brew cask install ckb # 海盗船机械键盘驱动brew cask install shadowsocksx # 翻墙工具brew cask install firefox # 火狐brew cask install foxmail # 邮箱客户端brew cask install rdm # redis 客户端brew cask install typora # markdown工具brew cask install macdownbrew cask install cyberduck # ftp工具brew cask install bearychat 2、iTerm22.1 简介ITERM2 是 MAC 下最好的终端工具。直接去官网下载安装包安装即可使用。 2.2 iTerm2 常用快捷键 切换 tab：⌘+← ，⌘+→ ，⌘+{ ， ⌘+} ，⌘+数字直接定位到该 tab 新建 tab：⌘+t 顺序切换 pane：⌘+[ ， ⌘+] 按方向切换 pane：⌘+Option+方向键 切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分 智能查找，支持正则查找：⌘+f 3、安装OH MY ZSH安装ZSH 是一种Shell指令集，Mac 自带 ZSH 的安装。但 Oh my zsh 可以让你能更简便的配置 ZSH。 安装方式如下: 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 等待安装完成即可 配置设置 zsh 为系统的默认的 shell 1chsh -s /bin/zsh 更改zsh主题编辑 ~/.zshrc ，将文本中的 ZSH_THEME 修改为如下（个人推荐主题：ys） 1ZSH_THEME=\"ys\" 注：主题文件在 ~/.oh-my-zsh/themes 目录 4、安装JDK安装通过 HomeBrew 安装 JDK 安装 jdk8 brew cask info java8 安装 jdk9 brew cask info java9 也可以通过官网下载安装包安装 上述两个文件安装完成后，执行下述命令 123echo \"alias setJdk9='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk9.0.4.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"alias setJdk8='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home\" &gt;&gt; ~/.zshrc 这样在命令行中默认设置当前环境变量为 JAVA 8 , 当我们需要切换到 JAVA 9 时只需在命令行中执行命令 setJdk9 即可 。 5、安装 Maven安装Maven 是Java生态中用来构建项目的工具。通过brew安装 1brew install maven 等待安装完成后即可 验证在命令行中输入下述命令验证MAVEN是否正确安装 1234567$ mvn -vApache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)Maven home: /usr/local/Cellar/maven/3.5.3/libexecJava version: 1.8.0_161, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: \"mac os x\", version: \"10.13.4\", arch: \"x86_64\", family: \"mac\" 如果有以上输出内容即标识安装完成 配置在 ~/.m2 目录下创建 settings.xml 文件，使用阿里云的 maven 仓库，内容如下 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt;&lt;/pluginGroups&gt; &lt;proxies&gt;&lt;/proxies&gt; &lt;servers&gt;&lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;JDK-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;JDK-1.8&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 6、安装 RedisRedis 是一款基于数据结构的内存数据库。在我们的项目中被用作高速集中式缓存的解决方案。 安装1brew install redis 等待安装完成即可 验证在命令行中输入下述命令查看 reids 版本 12$ redis-server -v Redis server v=2.8.3 sha=00000000:0 malloc=libc bits=64 build=e836d8ad888e21a1 如果有以上输出内容即表示安装完成 7、安装MySQLMysql 是业界主流的开源关系型数据库。在我们项目中用以持久化用户及系统数据。 安装1brew install mysql 等待安装完成即可 验证12$ mysql -Vmysql Ver 14.14 Distrib 5.6.15, for osx10.9 (x86_64) using EditLine wrapper 如果有以上输出内容即表示安装完成 8、安装 ElasticSearch安装Elasticsearch(简称ES）是一款基于lucene的全文搜索中间件。用于处理在大量文本中通过关键字搜索的场景（例如搜索商品、店铺等）。先在下面的链接中下载安装包（已集成相关插件）后解压, 将解压后的文件夹放到你想安装的目录。通过 brew 安装5.6版的 ES： 1brew install elasticsearch@5.6 验证打开Iterm2，进入 elasticsearch的安装目录，执行以下命令 1$ ./elasticsearch 就可以看到启动日志了 9、安装Nginx安装Nginx 是一款轻量的高性能的Http与反向代理服务器。可被用作转发页面的请求至后台的Tomcat服务器 1brew install nginx 等待安装完成即可 验证在命令行中输入下述命令验证 Nginx 是否正确安装 (版本可能有所不同) 12345$ nginx -Vnginx version: nginx/1.6.3built by clang 6.1.0 (clang-602.0.49) (based on LLVM 3.6.0svn)TLS SNI support enabledconfigure arguments: --prefix=/usr/local/Cellar/nginx/1.6.3 --with-http_ssl_module --with-pcre --with-ipv6 --sbin-path=/usr/local/Cellar/nginx/1.6.3/bin/nginx --with-cc-opt=&apos;-I/usr/local/Cellar/pcre/8.36/include -I/usr/local/Cellar/openssl/1.0.2a-1/include&apos; --with-ld-opt=&apos;-L/usr/local/Cellar/pcre/8.36/lib -L/usr/local/Cellar/openssl/1.0.2a-1/lib&apos; --conf-path=/usr/local/etc/nginx/nginx.conf --pid-path=/usr/local/var/run/nginx.pid --lock-path=/usr/local/var/run/nginx.lock --http-client-body-temp-path=/usr/local/var/run/nginx/client_body_temp --http-proxy-temp-path=/usr/local/var/run/nginx/proxy_temp --http-fastcgi-temp-path=/usr/local/var/run/nginx/fastcgi_temp --http-uwsgi-temp-path=/usr/local/var/run/nginx/uwsgi_temp --http-scgi-temp-path=/usr/local/var/run/nginx/scgi_temp --http-log-path=/usr/local/var/log/nginx/access.log --error-log-path=/usr/local/var/log/nginx/error.log --with-http_gzip_static_module 修改配置文件12345678910111213141516171819202122#user nobody;worker_processes 2;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip on; include servers/*.conf;&#125; 10、安装 SEQUEL PROSequel Pro 是一款免费的 MySQL 的图形管理工具。 安装在官网可下载最新版本 11、安装 IntelliJ IDEAIntelliJ IDEA 业界公认为最好的 Java 开发工具之一 安装【官网】，网上有很多破解方法，如果资金允许请支持正版 12、安装 Zookeeper安装通过 brew 安装 1brew install zookeeper 13、LaunchRocket简介是一个帮助管理Homebrew安装的服务的软件，比如你使用brew安装的Mysql、Redis、MongoDB，LaunchRocket 可以管理这些服务的生命周期和启动方式（自启动、手动启动），传统方式需要使用命令行的命令，而使用LaunchRocket则可以在图形界面中进行管理。 安装brew 安装 1brew cask install launchrocket 14、一些其他实用软件办公：1234567891011121314markdown 编辑器：BoostNote、Typora、YuWriter、Mou文本编辑工具：Atom、Visual Studio Code、Sublime时间/项目管理工具：2Do、OmniPlan、OmniForce流程图绘制：OmniGraffle脑图绘制：Xmind、MindNode、iThoughtsX文稿编辑/演示： KeyNote、Pages、Scrivener、Quiver状态栏图标隐藏工具：Bartender3压缩工具：Dr.Unarchiver技术文档离线阅读：Dash效率搜索：Alfred3数据库管理工具：Sequel Pro、Navicat、TablePlusGit 的 GUI 工具：SourceTree、GitUpREST 客户端：Postman、PawHosts 切换管理工具：SwitchHosts 上班必备12社交软件：微信、QQ、钉钉上班听音乐：网易云音乐、酷我音乐、QQ音乐","categories":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/categories/mac/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/tags/mac/"}]},{"title":"Hexo基本使用","slug":"Hexo基本使用","date":"2015-04-21T15:20:36.000Z","updated":"2018-10-22T02:18:04.969Z","comments":true,"path":"2015/04/21/Hexo基本使用/","link":"","permalink":"https://blog.milk4j.com/2015/04/21/Hexo基本使用/","excerpt":"","text":"官网 Hexo| 文档 documentation | 社区 troubleshooting | Git地址 GitHub. 快速入门新建文章1$ hexo new \"My New Post\" 详细说明: Writing 运行1$ hexo server 详细说明: Server 生成静态文件1$ hexo generate 详细说明: Generating 发布到远程站点1$ hexo deploy 详细说明: Deployment","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/tags/hexo/"}]}]}