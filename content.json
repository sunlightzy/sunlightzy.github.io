{"meta":{"title":"Jerry Simple","subtitle":null,"description":null,"author":"John Doe","url":"https://blog.milk4j.com"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-10-21T15:06:58.893Z","updated":"2018-10-21T15:06:58.892Z","comments":false,"path":"/404.html","permalink":"https://blog.milk4j.com//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-10-21T15:07:09.476Z","updated":"2018-10-21T15:07:09.475Z","comments":false,"path":"about/index.html","permalink":"https://blog.milk4j.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2018-10-21T15:06:46.286Z","updated":"2018-10-21T15:06:46.286Z","comments":false,"path":"books/index.html","permalink":"https://blog.milk4j.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-10-21T15:07:19.450Z","updated":"2018-10-21T15:07:19.450Z","comments":false,"path":"categories/index.html","permalink":"https://blog.milk4j.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-21T15:07:32.536Z","updated":"2018-10-21T15:07:32.536Z","comments":true,"path":"links/index.html","permalink":"https://blog.milk4j.com/links/index.html","excerpt":"","text":""},{"title":"Github仓库","date":"2018-10-21T16:49:07.578Z","updated":"2018-10-21T16:49:07.578Z","comments":false,"path":"repository/index.html","permalink":"https://blog.milk4j.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-22T16:07:59.439Z","updated":"2018-10-22T16:07:59.436Z","comments":false,"path":"tags/index.html","permalink":"https://blog.milk4j.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Docker构建Epics","date":"2018-11-20T07:43:25.517Z","updated":"2018-11-20T10:56:03.384Z","comments":true,"path":"2018/11/20/Docker构建Epics/","link":"","permalink":"https://blog.milk4j.com/2018/11/20/Docker构建Epics/","excerpt":"","text":"Docker构建Epics基于MySQL:5.7.24镜像123456789101112131415docker pull mysql:5.7.24docker run -p 3307:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7.24docker exec -it mysql /bin/bash# mysql 镜像是基于debian发行版Linux系统apt-get update # 更新源apt-get install build-essential # 这个命令最方便，把所有要安装的全部安装好：build-essential是c语言的开发包，包含了gcc make gdb和libc函数库等很多工具。# 保证perl gcc g++ c++ 都已安装which perl which gccwhich g++which c++# 编译中可能出现缺少 readline.hapt-get install libreadline-dev 准备安装12345678910111213141516171819202122232425262728cd ~mkdir epics cd epicsmkdir extensions # 存放扩展程序cd /usr/srcwget https://epics.anl.gov/download/base/base-3.15.5.tar.gztar -vxzf base-3.15.5.tar.gzln -s base-3.15.5.tar.gz base #创建软连接cd base./startup/EpicsHostArch # 获取系统架构, 我的是linux-x86_64pwd # 输出 /home/parallels/epics/basecd ~vi .bashrc# 添加# export EPICS_HOST_ARCH=linux-x86_64# export HOST_ARCH=linux-x86_64# 上面的linux-x86_64根据系统情况设置，具体参考base/configure/CONFIG_SITE# export EPICS_EXTENSIONS=/home/parallels/epics/extensions# export EPICS_BASE=/home/parallels/epics/basesource .bashrc # 使环境变量生效cd ~/epics/base/startup./EpicsHostArch # 获取系统架构, 我的是linux-x86_64cd ~/epics/base/configurevim CONFIG_SITE# 填写下面几项值 , 下面的值来自于获取系统架构的输出CROSS_COMPILER_TARGET_ARCHS=linux-x86_64CROSS_COMPILER_HOST_ARCHS=linux-x86_64CROSS_COMPILER_RUNTEST_ARCHS=linux-x86_64 安装Python3 1apt-get install python3 安装pip3 1apt-get install python3-pip","categories":[],"tags":[]},{"title":"","slug":"Epics编译安装","date":"2018-11-20T01:14:18.886Z","updated":"2018-11-21T05:21:01.666Z","comments":true,"path":"2018/11/20/Epics编译安装/","link":"","permalink":"https://blog.milk4j.com/2018/11/20/Epics编译安装/","excerpt":"","text":"Epics编译安装我的系统环境 macOS Mojave parallels desktop虚拟机系统: centos 7 linux-x86_64 Epics版本: 3.15.5 下载链接 记一笔:parallels desktop下载的centos7 默认用户名是parallels 密码是需要设置的。软件没有自动设置。密码必须大于8位； 并且无法进行su命令，提示 Authentication failure。 这个问题产生的原因是由于系统默认是没有激活root用户的，需要我们手工进行操作，在命令行界面下，或者在终端中输入如下命令： 1234sudo passwdPassword：你当前的密码Enter new UNIX password：这个是root的密码Retype new UNIX password：重复root的密码 然后会提示成功的信息。 在说明一点，使用su和sudo是有区别的，使用su切换用户需要输入所切换到的用户的密码，而使用sudo则是当前用户的密码。 安装准备12345678910111213141516171819202122232425262728cd ~mkdir epics cd epicsmkdir extensions # 存放扩展程序cd .. wget https://epics.anl.gov/download/base/base-3.15.5.tar.gztar -vxzf base-3.15.5.tar.gzln -s base-3.15.5.tar.gz base #创建软连接cd base./startup/EpicsHostArch # 获取系统架构, 我的是linux-x86_64pwd # 输出 /home/parallels/epics/basecd ~vi .bashrc# 添加# export EPICS_HOST_ARCH=linux-x86_64# export HOST_ARCH=linux-x86_64# 上面的linux-x86_64根据系统情况设置，具体参考base/configure/CONFIG_SITE# export EPICS_EXTENSIONS=/home/parallels/epics/extensions# export EPICS_BASE=/home/parallels/epics/basesource .bashrc # 使环境变量生效cd ~/epics/base/startup./EpicsHostArch # 获取系统架构, 我的是linux-x86_64cd ~/epics/base/configurevim CONFIG_SITE# 填写下面几项值 , 下面的值来自于获取系统架构的输出CROSS_COMPILER_TARGET_ARCHS=linux-x86_64CROSS_COMPILER_HOST_ARCHS=linux-x86_64CROSS_COMPILER_RUNTEST_ARCHS=linux-x86_64 为了确保安装过程顺利 123456# 编译中可能出现缺少 readline.hsudo yum install readline-static.x86_64# 确保环境安装了 g++ c++ gcc perlwhich perl # 输出 /usr/bin/perl表示安装了perl,其他三个类似# 由于我的环境没有g++ 和 c++ ,安装一下sudo yum install gcc gcc-c++ Make安装 123456789101112131415cd ~/epics/base # 回到epics base的根目录make # 下面就是漫长的等待...# 如果没有什么问题就成功了,如果编译报缺失什么文件,安装后再依次执行 # make distclean # make# 我的make过程很顺利,花了大概1分钟,但是我在云主机上花了30多分钟ls # bin configure db dbd documentation html include lib LICENSE Makefile README src startup templatesvi ~/.bashrc# 添加PATH=$PATH:/home/parallels/epics/base/bin/linux-x86_64export PATH# 生效环境变量source ~/.bashrc 创建example软件和IOC环境 12345678910111213141516171819202122232425262728293031323334353637383940cd ~/epicsmkdir -p iocs/examplecd iocscd examplemakeBaseApp.pl -t example examplemakeBaseApp.pl -i -t example examplels# configure exampleApp iocBoot Makefilemake # 等待完成ls# bin configure db dbd exampleApp include iocBoot lib Makefilecd iocBoot/iocexample/ls# envPaths Makefile README st.cmdsudo chmod +x ./st.cmd./st.cmdepics&gt; dblparallels:xxxExampleparallels:compressExampleparallels:calcExampleparallels:calcExample1parallels:calc1parallels:calcExample2parallels:calc2parallels:calcExample3parallels:calc3parallels:aSubExampleparallels:subExampleparallels:aiExampleparallels:aiExample1parallels:ai1parallels:aiExample2parallels:ai2parallels:aiExample3parallels:ai3epics&gt; dbpr parallels:ai1ASG: DESC: Analog input No. 1 DISA: 0DISP: 0 DISV: 1 NAME: parallels:aiExample1RVAL: 0 SEVR: MAJOR STAT: LOLO SVAL: 0TPRO: 0 VAL: 0 开启一个新终端,继续输入 1camonitor parallels:aiExample mac os 安装问题 EXTERN.h 文件缺失:是因为perl的原因, 解决方案 brew install perl-build","categories":[],"tags":[]},{"title":"Spring Boot 自动配置(autoconfigure)原理","slug":"Spring Boot 自动配置(autoconfigure)原理","date":"2018-11-11T15:59:59.000Z","updated":"2018-11-27T14:31:09.109Z","comments":true,"path":"2018/11/11/Spring Boot 自动配置(autoconfigure)原理/","link":"","permalink":"https://blog.milk4j.com/2018/11/11/Spring Boot 自动配置(autoconfigure)原理/","excerpt":"","text":"0. 说明环境配置清单 java version “1.8.0_161”Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)Spring Boot 2.1.0.RELEASE 项目 GitHub 1. 前提知识一、SPI扩展机制1. 解释SPI: Service Provider Interface , 即 服务提供接口 2. 如何写一个Java SPI呢? 定义一组接口， 接口是 com.glmapper.spi.FilterProvider； 接口的一个或多个实现(com.glmapper.spi.provider.FileFilterProvider [从文件系统加载filter], com.glmapper.spi.provider.DataSourceFilterProvider [从数据源中加载filter])； 在 src/main/resources/ 下建立 /META-INF/services 目录， 新增一个以接口命名的文件 com.glmapper.spi.FilterProvider, 内容是要对应的实现类(com.glmapper.spi.provider.FileFilterProvider 或 com.glmapper.spi.provider.DataSourceFilterProvider 或两者)； 使用 ServiceLoader 来加载配置文件中指定的实现。 3. SPI应用案例 Dubbo 中有大量的SPI应用,不过Dubbo不是原生的java spi机制,他是原生的一个变种 . Dubbo SPI 约定: 扩展点约定 : 扩展点必须是 Interface 类型 ， 必须被 @SPI 注解 ， 满足这两点才是一个扩展点。 扩展定义约定 ： 在 META-INF/services/、META-INF/dubbo/、META-INF/dubbo/internal/目录下新建扩展点文件,这些路径下定义的文件名称为扩展点接口的全类名 , 文件中以键值对的方式配置扩展点的扩展实现。例如文件 META-INF/dubbo/internal/com.alibaba.dubbo.common.extension.ExtensionFactory 中定义的扩展 ： 123adaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactoryspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactoryspring=com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory 关于Dubbo SPI扩展机制在此不再继续展开描述 JDBC 数据库驱动包: java mysql 驱动采用原生的spi机制mysql-connector-java-xxx.jar 就有一个 /META-INF/services/java.sql.Driver 里面内容是 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当然还有今天的主角 spring boot ,他也是原生spi的变种,它的约定是在src/main/resorces/下建立META-INF/spring.factories, 当springboot服务启动时，对象实例化过程会加载META-INF/spring.factories文件，将该配置文件中的配置的类载入到Spring容器中.下面是spring-boot-autoconfigure jar包中spring.factories 的内容: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnClassCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\# 这里省略了一堆# Failure analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer# Template availability providersorg.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.web.JspTemplateAvailabilityProvider 2. Spring Boot 自动配置机制0. 总体流程概述1. 几个重要的事件回调机制ApplicationContextInitializer配置在META-INF/spring.factories 1234# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer ApplicationContextInitializer 是上下文初始化入口 SpringApplicationRunListener配置在META-INF/spring.factories 123# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer SpringApplicationRunListener 的功能是监听容器启动过程也就是SpringApplication.run()方法, ApplicationRunner &amp; CommandLineRunnerCommandLineRunner &amp; ApplicationRunner 接口是在容器启动成功后的最后一步回调（类似开机自启动）, 两者功能差不多, 只需要将其实现类放在IOC容器中,应用启动后会自动回调接口方法 2. 自动配置注解@EnableAutoConfiguration@EnableAutoConfiguration是自动配置的开关, 下面看看他的结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Enable auto-configuration of the Spring Application Context, attempting to guess and * configure beans that you are likely to need. Auto-configuration classes are usually * applied based on your classpath and what beans you have defined. For example, if you * have &#123;@code tomcat-embedded.jar&#125; on your classpath you are likely to want a * &#123;@link TomcatServletWebServerFactory&#125; (unless you have defined your own * &#123;@link ServletWebServerFactory&#125; bean). * &lt;p&gt; * When using &#123;@link SpringBootApplication&#125;, the auto-configuration of the context is * automatically enabled and adding this annotation has therefore no additional effect. * &lt;p&gt; * Auto-configuration tries to be as intelligent as possible and will back-away as you * define more of your own configuration. You can always manually &#123;@link #exclude()&#125; any * configuration that you never want to apply (use &#123;@link #excludeName()&#125; if you don't * have access to them). You can also exclude them via the * &#123;@code spring.autoconfigure.exclude&#125; property. Auto-configuration is always applied * after user-defined beans have been registered. * &lt;p&gt; * The package of the class that is annotated with &#123;@code @EnableAutoConfiguration&#125;, * usually via &#123;@code @SpringBootApplication&#125;, has specific significance and is often used * as a 'default'. For example, it will be used when scanning for &#123;@code @Entity&#125; classes. * It is generally recommended that you place &#123;@code @EnableAutoConfiguration&#125; (if you're * not using &#123;@code @SpringBootApplication&#125;) in a root package so that all sub-packages * and classes can be searched. * &lt;p&gt; * Auto-configuration classes are regular Spring &#123;@link Configuration&#125; beans. They are * located using the &#123;@link SpringFactoriesLoader&#125; mechanism (keyed against this class). * Generally auto-configuration beans are &#123;@link Conditional @Conditional&#125; beans (most * often using &#123;@link ConditionalOnClass @ConditionalOnClass&#125; and * &#123;@link ConditionalOnMissingBean @ConditionalOnMissingBean&#125; annotations). * * @author Phillip Webb * @author Stephane Nicoll * @see ConditionalOnBean * @see ConditionalOnMissingBean * @see ConditionalOnClass * @see AutoConfigureAfter * @see SpringBootApplication */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited// 自动配置包,注册扫描包@AutoConfigurationPackage// 导入的这个AutoConfigurationImportSelector是自动配置的关键@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; 进入AutoConfigurationImportSelector找到selectImports()方法，他调用了getCandidateConfigurations()方法，在这里，这个方法又调用了Spring Core包中的loadFactoryNames()方法。这个方法的作用是，会查询META-INF/spring.factories文件中包含的JAR文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //1. 得到注解信息 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry( autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125;/** * Return the &#123;@link AutoConfigurationEntry&#125; based on the &#123;@link AnnotationMetadata&#125; * of the importing &#123;@link Configuration @Configuration&#125; class. * @param autoConfigurationMetadata the auto-configuration metadata * @param annotationMetadata the annotation metadata of the configuration class * @return the auto-configurations that should be imported */protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; // 2. 得到注解中的所有属性信息 AnnotationAttributes attributes = getAttributes(annotationMetadata); // 3. 得到spring.factories中配置在EnableAutoConfiguration下的字符串列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 4. 去重 configurations = removeDuplicates(configurations); // 5. 根据注解中的exclude信息去除不需要的 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); // 7. 派发事件 fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125;/** * 获取所有的自动配置类,也就是配置在spring.factories中 EnableAutoConfiguration 下的所有字符串列表 * Return the auto-configuration class names that should be considered. By default * this method will load candidates using &#123;@link SpringFactoriesLoader&#125; with * &#123;@link #getSpringFactoriesLoaderFactoryClass()&#125;. * @param metadata the source metadata * @param attributes the &#123;@link #getAttributes(AnnotationMetadata) annotation * attributes&#125; * @return a list of candidate configurations */protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; // getSpringFactoriesLoaderFactoryClass()直接返回EnableAutoConfiguration.class // 所以这一步加载了所有的自动配置类 List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations;&#125;/** * Return the class used by &#123;@link SpringFactoriesLoader&#125; to load configuration * candidates. * @return the factory class */protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class;&#125; 下面进入org.springframework.core.io.support.SpringFactoriesLoader#loadFactoryNames 12345678910111213141516/** * Load the fully qualified class names of factory implementations of the * given type from &#123;@value #FACTORIES_RESOURCE_LOCATION&#125;, using the given * class loader. * @param factoryClass the interface or abstract class representing the factory * @param classLoader the ClassLoader to use for loading resources; can be * &#123;@code null&#125; to use the default * @throws IllegalArgumentException if an error occurs while loading factory names * @see #loadFactories */public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; // 获取全类名 String factoryClassName = factoryClass.getName(); // 加载所有的spring.factories中的配置,然后筛选出factoryClassName下的配置的值 return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());&#125; 在上面的spring-boot-autoconfigure.jar里的spring.factories文件下我们可以看到有这么一段关于EnableAutoConfiguration的配置(放一小段) 1234567891011121314# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 在SpringBoot启动配置类上面打上@EnableAutoConfiguration注解之后springboot就会实例化配置文件中这些XxxAutoConfiguration类启用这些类的功能, ==需要注意的是: 加了@EableAutoConfiguration注解的配置类只会为这个类所在的包以及子包下面的类自动配置== @EnableAutoConfiguration是自动配置的开关 ,如果要自己写自动配置类,还有一些Conditional的注解类需要掌握 @ConditionalOnXxx系列注解SpringBoot的自动配置全都依赖于这个系列的注解,下面列举了一些: ConditionalOnBean 当指定bean存在时, 配置生效ConditionalOnClass 当指定类存在时, 配置生效ConditionalOnCloudPlatform 当项目环境为指定云平台环境时, 配置生效ConditionalOnEnableResourceChain 当ResourceChain是启用状态时, 配置生效ConditionalOnExpression 当表达式为true时, 配置生效ConditionalOnJava 当环境的java为指定版本时,配置生效ConditionalOnJndi 当指定的JNDI存在时, 配置生效ConditionalOnMissingBean 当指定的bean不存在时, 配置生效ConditionalOnMissingClass 当指定的类不存在时, 配置生效ConditionalOnNotWebApplication 当项目为非web项目时, 配置生效ConditionalOnProperty 当指定的配置存在时, 配置生效ConditionalOnResource 当指定的资源存在时, 配置生效ConditionalOnSingleCandidate 当指定的类是单例时, 配置生效ConditionalOnWebApplication 当项目是web项目时, 配置生效 举个栗子下面以HttpEncodingAutoConfiguration为例来看一下自动配置 @ConditionalOnProperty注解的玩法很多, 详细使用案例参考本文文末附件@ConditionalOnProperty注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * &#123;@link EnableAutoConfiguration Auto-configuration&#125; for configuring the encoding to use * in web applications. * * @author Stephane Nicoll * @author Brian Clozel * @since 1.2.0 */@Configuration// 启用HttpProperties配置并加入到IOC容器@EnableConfigurationProperties(HttpProperties.class)// 当项目是servlet容器下的web项目时,这个配置类才生效@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET)// 当CharacterEncodingFilter类存在时,这个配置类才生效@ConditionalOnClass(CharacterEncodingFilter.class)// 当spring.http.encoding.enabled这个环境变量存在且值不为false时,这个配置类才生效// @ConditionalOnProperty这个注解的玩法很多@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true)public class HttpEncodingAutoConfiguration &#123; private final HttpProperties.Encoding properties; public HttpEncodingAutoConfiguration(HttpProperties properties) &#123; this.properties = properties.getEncoding(); &#125; @Bean // 当容器中没有CharacterEncodingFilter类型的实例时,这个方法生效 @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; @Bean public LocaleCharsetMappingsCustomizer localeCharsetMappingsCustomizer() &#123; return new LocaleCharsetMappingsCustomizer(this.properties); &#125; private static class LocaleCharsetMappingsCustomizer implements WebServerFactoryCustomizer&lt;ConfigurableServletWebServerFactory&gt;, Ordered &#123; private final HttpProperties.Encoding properties; LocaleCharsetMappingsCustomizer(HttpProperties.Encoding properties) &#123; this.properties = properties; &#125; @Override public void customize(ConfigurableServletWebServerFactory factory) &#123; if (this.properties.getMapping() != null) &#123; factory.setLocaleCharsetMappings(this.properties.getMapping()); &#125; &#125; @Override public int getOrder() &#123; return 0; &#125; &#125;&#125; 3. SpringBoot启动过程0. 总体流程概述1. 创建启动类1.1. 创建启动类 1234567@SpringBootApplicationpublic class Bootstrap &#123; public static void main(String[] args) &#123; // 调用SpringApplication静态方法run为入口 SpringApplication.run(Bootstrap.class, args); &#125;&#125; 1.2. 跟踪进入org.springframework.boot.SpringApplication#run(java.lang.String...) 123456789101112131415161718192021222324252627282930313233343536373839 /** * Static helper that can be used to run a &#123;@link SpringApplication&#125; from the * specified sources using default settings and user supplied arguments. * @param sources the sources to load * @param args the application arguments (usually passed from a Java main method) * @return the running &#123;@link ApplicationContext&#125; */ public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 进入构造器,会有初始化过程 return new SpringApplication(sources).run(args); &#125;/** * Create a new &#123;@link SpringApplication&#125; instance. The application context will load * beans from the specified sources (see &#123;@link SpringApplication class-level&#125; * documentation for details. The instance can be customized before calling * &#123;@link #run(String...)&#125;. * @param sources the bean sources * @see #run(Object, String[]) * @see #SpringApplication(ResourceLoader, Object...) */public SpringApplication(Object... sources) &#123; // 初始化 initialize(sources);&#125;@SuppressWarnings(&#123; \"unchecked\", \"rawtypes\" &#125;)private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; // 推断是否为web环境 this.webEnvironment = deduceWebEnvironment(); // 获取所有的配置在spring.factores中的ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 获取所有的配置在spring.factores中的ApplicationContextInitializer setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 推断启动类,我们这里就是Bootstrap.class this.mainApplicationClass = deduceMainApplicationClass();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 运行spring应用,创建一个新的spring上ApplicationContext下文环境 * Run the Spring application, creating and refreshing a new * &#123;@link ApplicationContext&#125;. * @param args the application arguments (usually passed from a Java main method) * @return a running &#123;@link ApplicationContext&#125; */public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 加载java的AWT图形化相关的系统配置变量, 可以忽略 configureHeadlessProperty(); // 实例化spring.factories中配置的所有SpringApplicationRunListener并返回到 listeners 中 // SpringApplicationRunListeners内部是一个List&lt;SpringApplicationRunListener&gt; SpringApplicationRunListeners listeners = getRunListeners(args); // 启动应用监听器,回调starting方法, // spring应用进行到某一阶段时会广播通知所有的监听器, 监听器的方法就会被回调执行 listeners.starting(); try &#123; // 包装命令行启动参数 也就是 Bootstrap.main(String[] args)中的args // 我们可以通过命令号启动应用 java -jar demo.jar --server.port=8989 这个server.port=8989就是启动参数 // 他可以接受多个启动参数,包括指定profile [dev/test/pre/prod] ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 准备应用环境, 包括读取系统环境变量/yml,properties等配置文件, // 同时回调listeners的environmentPrepared方法 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 打印Banner 也就是我们启动应用时控制台打印出的Spring 的 logo了,这个也可以自定义 // 有兴趣的自行百度自定义springboot banner, 我不喜欢这些花里胡哨的东西(才怪) Banner printedBanner = printBanner(environment); // 创建上下文,决定创建web的ioc还是普通的ioc context = createApplicationContext(); // 实例化配置在spring.factories中的FailureAnalyzer应用启动失败的分析器,并返回 analyzers = new FailureAnalyzers(context); // 上下文准备,会广播通知listeners回调contextPrepared方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新上下文 refreshContext(context); // 上下文刷新后的一些擦屁股工作 afterRefresh(context, applicationArguments); // 容器已经创建和刷新完成,广播通知listeners回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; // 到此如果没有启动报错,那你的应用就已经启动完成了 return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 我们要说的是springboot自动配置, 但是我写这些做什么呢? 因为自动配置就是在上面的一些步骤中完成的,下面继续 总结一下,应用启动过程经历了哪些阶段呢. getRunListeners(...)获取SpringApplicationRunListener监听器 prepareEnvironment(...)应用环境准备 createApplicationContext(...)创建应用上下文 prepareContext(...)上下文准备 refreshContext(...)刷新上下文 afterRefresh(...)上下文刷新完后的一些收尾工作 2. prepareEnvironment容器环境准备阶段 123456789101112131415161718192021private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // 存在就获取环境,不存在就创建环境 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 环境配置: // 1. 收集用户自定义的配置和系统环境变量 // 2. 收集Profiles信息 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 遍历listeners 调用 environmentPrepared listeners.environmentPrepared(environment); // 把环境绑定到SpringApplication, 实际上是增加了一个K-V键值对==&gt; // \"spring.main\" = SpringApplication的Bindable对象 bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; // 推断项目的环境,并把当前环境转换成项目所需要的环境 environment = new EnvironmentConverter(getClassLoader()) .convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 3. createApplicationContext根据是否为web环境来决定创建一个web应用或者非web应用的上下文 1234567891011121314151617181920212223242526272829protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; // 根据环境来创建对应的上下文, 下面的值的包名我省略了 //DEFAULT_CONTEXT_CLASS: \"AnnotationConfigApplicationContext\"; //DEFAULT_SERVLET_WEB_CONTEXT_CLASS: \"AnnotationConfigServletWebServerApplicationContext\"; //DEFAULT_REACTIVE_WEB_CONTEXT_CLASS: \"AnnotationConfigReactiveWebServerApplicationContext\"; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Unable create a default ApplicationContext, \" + \"please specify an ApplicationContextClass\", ex); &#125; &#125; // 创建并返回应用上下文 return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 4. prepareContext上下文的一些成员变量初始化工作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); // 做了三件事: // 1. 注册beanNameGenerator到Context中 // 2. 为Context设置资源加载器resourceLoader // 3. 为Context设置类加载器 // 4. 为Context设置ConversionService, ConversionService是提供值转换服务的 postProcessApplicationContext(context); // 触发ApplicationContextInitializer初始化方法,初始化上下文 applyInitializers(context); // 遍历触发listener的contextPrepared方法 listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans 把命令行参数添加到ioc中 context.getBeanFactory().registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(\"springBootBanner\", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // Load the sources Set&lt;Object&gt; sources = getSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); // 加载上下文: // 1. 实例化 BeanDefinitionLoader // 2. 执行load()方法 // 2.1 加载启动类上的注解、解析注解元信息、 load(context, sources.toArray(new Object[sources.size()])); // 遍历listener调动contextLoaded上下文加载完成方法 listeners.contextLoaded(context);&#125;// load()最终会到AnnotatedBeanDefinitionReader#doRegisterBean方法,看看做了些啥&lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &#123; // 分析启动类的注解的信息 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass); if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; // Supplier无参数有返回值的接口方法 abd.setInstanceSupplier(instanceSupplier); //检查scope，实例中没有指定，默认是singleton ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); ////获取bean的名字，这里是启动类 String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); // 对于是否是@lazy，是否使用了@primary AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); if (qualifiers != null) &#123; for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &#123; customizer.customize(abd); &#125; // 根据注解信息生产BeanDefinition BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); // 根据Bean的作用域，创建相应的代理对象 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); // 将Bean加入到beanDefinitionMap中 BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);&#125; 5. refreshContext最终会定位到org.springframework.context.support.AbstractApplicationContext#refresh方法, 除此之外最后还会注册ShutdownHook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 1. 清除缓存 // 2. 初始化所有在上下文环境中的占位符配置 // 3. 校验所有required的配置是否已经被解析完成 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 通知子类刷新Bean工厂 // 1. 为BeanFactory设置了一个ID, 就是在yaml文件中配置的spring.application.name ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 1. 为BeanFactory设置类加载器 // 2. 设置表达式解析器StandardBeanExpressionResolver // 3. 设置配置文件注册器ResourceEditorRegistrar // 4. 设置Bean的后置处理器 // 不一一列举了,下面看图 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 1. 添加子类自定义的Bean后置处理器 // 2. 扫描basePackage下的类,按照需求加入到容器 // 3. 把带有Spring注解的类加入到容器 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用IOC容器中所有的Bean工厂处理器 BeanDefinitionRegistryPostProcessor、BeanFactoryPostProcessor // 1. 配置类后置处理器 ConfigurationClassPostProcessor 解析 配置类 转换为 BeanDefinition // 1.1 @ComponentScan注解配置的basePackage // 1.2 @Import注解导入的配置类 // 1.3 @ImportResource注解导入的xml文件 // 1.4 @Bean注解的方法 // 1.5 @PropertySource注解导入的.properties配置文件 // 1.6 处理所有的SpringBoot配置类 // 2. 后置处理器太多了, 功能列不过来了 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册所有 用于拦截Bean创建的BeanProcessor registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化MessageSource, 供i18n用的 initMessageSource(); // Initialize event multicaster for this context. // 初始化事件广播器, 在这之前的listener都是遍历直接调用的方法, 从这里开始,listener会通过接受广播的方式回调 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化其他特定的Bean在指定的容器中,比如父子容器 // 比如在web容器中会初始化TomcatWebServer onRefresh(); // Check for listener beans and register them. // 检查并注册listener到广播器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 初始化所有的非懒加载的单例对象 // 需要注意的是在AbstractAutowireCapableBeanFactory#createBean(String, RootBeanDefinition, Object[]) // 这个方法中有一段如下代码 // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 这个方法注释的意思是给BeanPostProcessor一个返回目标接口的代理对象的机会, 具体可查阅和 // InstantiationAwareBeanPostProcessor相关的资料 // Object bean = resolveBeforeInstantiation(beanName, mbdToUse); finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // 完成刷新: // 1. 清除各种缓存 // 2. 初始化生命周期处理器 // 3. 发布ContextRefreshedEvent事件 // 4. 启动WebServer // 5. 发布ServletWebServerInitializedEvent时间 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; prepareBeanFactory 6. afterRefresh这个阶段SpringBoot没有具体的实现,留给开发者自定义子类去实现 12345678/** * Called after the context has been refreshed. * @param context the application context * @param args the application arguments */protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) &#123;&#125; 4. 附件@ConditionalOnProperty注解一、@ConditionalOnProperty 结构1234567891011121314151617181920212223@Retention(RetentionPolicy.RUNTIME) @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Documented @Conditional(&#123;OnPropertyCondition.class&#125;) public @interface ConditionalOnProperty &#123; //数组，获取对应property名称的值，不可与name同时使用 String[] value() default &#123;&#125;; //property名称的前缀，可有可无 String prefix() default \"\"; //数组，property完整名称或部分名称（可与prefix组合使用，组成完整的property名称），不可与value同时使用 String[] name() default &#123;&#125;; //可与name组合使用，比较获取到的属性值与havingValue给定的值是否相同，相同才加载配置 String havingValue() default \"\"; //缺少该property时是否可以加载。如果为true，没有该property也会正常加载；反之报错 boolean matchIfMissing() default false; //是否可以松散匹配 boolean relaxedNames() default true;&#125; 二、@ConditionalOnProperty 用法1. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(value = \"object.pool.size\") public class ObjectPoolConfig &#123; &#125; yml配置如下：12345678910object.pool: size: true //正常 object.pool: size: //正常，空字符时 object.pool: size: false //失败 object.pool: size: null //正常 object.pool: size: 30 //正常 2. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(value = \"object.pool.size\",havingValue=\"30\") public class ObjectPoolConfig &#123; &#125; yml配置如下：123456object.pool: size: 1234 //失败,与havingValue给定的值不一致 object.pool: size: false //失败,与havingValue给定的值不一致 object.pool: size: 30 //正常 当且仅当配置文件中的Value和havingValue的值一致时才加载成功3. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\") public class ObjectPoolConfig &#123; &#125; yml配置如下：123456object.pool: size: 1234 //失败,与havingValue给定的值不一致object.pool: size: false //失败,与havingValue给定的值不一致object.pool: size: 30 //正常 4. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\",matchIfMissing = true) public class ObjectPoolConfig &#123; &#125; yml不配置相关参数,正常启动，当 matchIfMissing = true 时，即使没有 object.pool.size 属性也会加载正常5. 有如下spring boot代码和yml配置 123456@Configuration //matchIfMissing的缺省值为false@ConditionalOnProperty(prefix = \"object.pool\",name = \"size\",havingValue=\"30\",matchIfMissing = false) public class ObjectPoolConfig &#123; &#125; yml配置如下： yml不配置相关参数,加载失败,当 matchIfMissing = false 时，必须要有对应的属性配置123456object.pool: size: 1234 //失败,与havingValue给定的值不一致object.pool: size: false //失败,与havingValue给定的值不一致object.pool: size: 30 //正常 6. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = &#123;\"size\",\"timeout\"&#125;) //name中的属性需要两个都存在且都不为false才会加载正常 public class ObjectPoolConfig &#123; &#125; yml配置如下：123456789object.pool: timeout: true size: 1234 //正常object.pool: timeout: true size: false //失败,两个值都不能为 falseobject.pool: timeout: true size: true //正常 7. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\",name = &#123;\"size\",\"timeout\"&#125;,havingValue=\"false\") public class ObjectPoolConfig &#123; &#125; .yml配置如下：123object.pool: timeout: false size: false //正常 8. 有如下spring boot代码和yml配置 12345@Configuration @ConditionalOnProperty(prefix = \"object.pool\", name = &#123;\"size\", \"timeout\"&#125;, havingValue = \"123\", matchIfMissing = true) public class ObjectPoolConfig &#123; &#125; yml配置如下：123456789object.pool: timeout: 123 size: false //失败,和havingValue的值不一致object.pool: timeout: 123 size: 1234 //失败,和havingValue的值不一致object.pool: timeout: 123 size: 123 //正常 matchIfMissing = true , 不配置参数也正常 三、 @ConditionalOnProperty 应用场景 通过 @ConditionalOnProperty 来控制 Configuration 是否生效","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"}]},{"title":"MySQL的一些遗忘点","slug":"MySQL的一些遗忘点","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-19T10:33:48.724Z","comments":true,"path":"2018/10/31/MySQL的一些遗忘点/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/MySQL的一些遗忘点/","excerpt":"","text":"一、Group By 和 Order By 一起使用order by 的列，必须是出现在group by 子句里的列 1234SELECT MAX( `id` ) FROM `order`GROUP BY `order_code` , `created_at`-- order by 的列，必须是出现在 group by 子句里的列 ORDER BY `created_at` DESC; 二、忘记root密码具体步骤如下： 修改MySQL的配置文件（默认为/etc/my.cnf）,在[mysqld]下添加一行skip-grant-tables 保存配置文件后，重启MySQL服务 service mysqld restart 再次进入MySQL命令行 mysql -uroot -p,输入密码时直接回车，就会进入MySQL数据库了，这个时候按照常规流程修改root密码即可。依次输入： use mysql; 更改数据库UPDATE user SET authentication_string=password(“passwd”) WHERE USER= ‘root’; 重设密码,注意我用的是5.7.22的数据库密码存储在authentication_string字段, 之前有的版本存储在password字段,具体看情况吧flush privileges; 刷新MySQL的系统权限相关表，以防止更改后拒绝访问；或或者重启MySQL服务器 密码修改完毕后，再按照步骤1中的流程，删掉配置文件中的那行，并且重启MySQL服务，新密码就生效了。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://blog.milk4j.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.milk4j.com/tags/mysql/"}]},{"title":"SpringBoot+H2+Mybatis单元测试整合和坑","slug":"SpringBoot+H2+Mybatis单元测试整合和坑","date":"2018-10-31T05:59:00.000Z","updated":"2018-10-31T08:46:11.871Z","comments":true,"path":"2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot+H2+Mybatis单元测试整合和坑/","excerpt":"","text":"Maven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 配置文件1234567891011spring: datasource: driver-class-name: org.h2.Driver url: jdbc:h2:mem:testdb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false username: root # 随便填 password: 123456 # 随便填 schema: classpath:db/schema.sql # 建表SQL语句 data: classpath:db/data.sql # 数据导入SQL语句 platform: h2 profiles: active: test 然后在src/test/resources文件夹下面新建一个文件夹db ,然后新建 schema.sql和data.sql schema.sql 文件是建表语句,内容不能为空,否则报错 data.sql文件是数据导入的SQL语句,内容不能为空,否则报错 注意事项一、不支持表级别的Comment 建表SQL如下： 12345678CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除') ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 列名后面的COMMENT是支持的，但是最后面的 ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= &#39;区域路线信息列表&#39; 中的COMMENT不支持。删掉后面的COMMENT即可。 二、只支持最普通的引索结构,不支持BTREE引索结构 123456789CREATE TABLE `testTable` ( `Id` varchar(36) NOT NULL COMMENT '序号', `StartArea` int(11) DEFAULT NULL COMMENT '出发区域', `ArrivalArea` int(11) DEFAULT NULL COMMENT '目的区域', `Updater` varchar(36) DEFAULT NULL COMMENT '更新人', `UpdateTime` datetime DEFAULT NULL COMMENT '更新时间' , `Status` int(11) DEFAULT NULL COMMENT '是否删除', PRIMARY KEY (`Id`) USING BTREE,) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT= '区域路线信息列表' ; 这种情况去掉 USING BTREE ,使用普通的引索就好了 三、插入语句的单引号中的\\’不支持 有如下SQL，其中一个字段存的里面带有单引号： 12345678910111213141516INSERT INTO `testTable`VALUES ( '1', '部门权限', 'LoginName=\\'&#123;1&#125;\\'', '1', '2', NULL, NULL, '2016-05-27 14:30:49', '1', '1', NULL, '1' ); MySQL支持双引号包含字符串，可以把内容中包含的单引号改为双引号，但其他情况可能会涉及到业务调整。另外，不能将包含字符串的单引号改为双引号，H2会把双引号中的内容当做列名处理。 四、H2 的 UNIQUE KEY是数据库级别的 H2 的 UNIQUE KEY不是表级别的，MySQL是表级别的，转为H2后容易出现UNIQUE KEY重复。删掉UNIQUE KEY或者修改KEY的名称即可。 五、无法使用子查询 目前没有办法解决,尽量避免使用吧","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"},{"name":"h2","slug":"h2","permalink":"https://blog.milk4j.com/tags/h2/"}]},{"title":"我的ElasticSearch命令简记","slug":"我的ElasticSearch命令简记","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-06T11:59:22.121Z","comments":true,"path":"2018/10/31/我的ElasticSearch命令简记/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/我的ElasticSearch命令简记/","excerpt":"","text":"常用简单命令条件删除数据1234567# 条件删除curl -XPOST \"http://localhost:9200/opt-log-index/opt-log-type/_delete_by_query\" -H 'Content-Type: application/json' -d'&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;&#125;' 删除index和数据1curl -XDELETE \"http://localhost:9200/opt-log-index\" 获取 mapping 结构12345# 获取所有的index的mappingcurl -XGET \"http://localhost:9200/_mapping\"# 获取指定的index的mapping结构curl -XGET \"http://localhost:9200/opt-log-index/_mapping\" 创建index和mapping123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 创建index和mappingcurl -XPUT \"http://localhost:9200/opt-log-index\" -H 'Content-Type: application/json' -d'&#123; \"settings\":&#123; \"analysis\":&#123; \"analyzer\":&#123; \"ik\":&#123; \"tokenizer\":\"ik_max_word\" &#125; &#125; &#125; &#125;, \"mappings\":&#123; \"opt-log-type\":&#123; \"properties\":&#123; \"id\":&#123; \"type\":\"keyword\" &#125;, \"operator\":&#123; \"type\":\"keyword\" &#125;, \"role\":&#123; \"type\":\"keyword\" &#125;, \"operatorName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"remark\":&#123; \"type\":\"keyword\" &#125;, \"operateType\":&#123; \"type\":\"keyword\" &#125;, \"txId\":&#123; \"type\":\"long\" &#125;, \"schemaName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"tableName\":&#123; \"type\":\"text\", \"analyzer\":\"ik\", \"search_analyzer\":\"ik_max_word\" &#125;, \"afterData\":&#123; \"type\":\"keyword\" &#125;, \"beforeData\":&#123; \"type\":\"keyword\" &#125;, \"changeFields\":&#123; \"type\":\"keyword\" &#125;, \"createdAt\":&#123; \"type\":\"date\", \"format\":\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" &#125;, \"updatedAt\":&#123; \"type\":\"date\", \"format\":\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" &#125; &#125; &#125; &#125;&#125;' 查询数据查询所有数据12345678910111213141516171819curl -XGET \"http://localhost:9200/opt-log-index/opt-log-type/_search\" -H 'Content-Type: application/json' -d'&#123; \"from\": 0, \"size\": 20, \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match_all\": &#123;&#125; &#125; ] &#125; &#125;, \"_source\": &#123; \"excludes\": [ \"beforeData\" ] &#125;&#125;' 精准匹配1234567891011121314151617181920212223242526curl -XGET \"http://localhost:9200/opt-log-index/opt-log-type/_search\" -H 'Content-Type: application/json' -d'&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"term\": &#123; \"tableName\": \"parana_item_detail\" &#125; &#125; ] &#125; &#125;, \"_source\": &#123; \"excludes\": [ \"beforeData\",\"schemaName\" ] &#125;, \"sort\": [ &#123; \"createdAt\": &#123; \"order\": \"desc\" &#125; &#125; ]&#125;'","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/tags/elasticsearch/"}]},{"title":"SpringBoot Junit单元测试","slug":"SpringBoot Junit单元测试","date":"2018-10-31T05:59:00.000Z","updated":"2018-11-03T08:51:50.530Z","comments":true,"path":"2018/10/31/SpringBoot Junit单元测试/","link":"","permalink":"https://blog.milk4j.com/2018/10/31/SpringBoot Junit单元测试/","excerpt":"","text":"一、JUnit中的注解 @BeforeClass：针对所有测试，只执行一次，且必须为static void @Before：初始化方法，执行当前测试类的每个测试方法前执行。 @Test：测试方法，在这里可以测试期望异常和超时时间 @After：释放资源，执行当前测试类的每个测试方法后执行 @AfterClass：针对所有测试，只执行一次，且必须为static void @Ignore：忽略的测试方法（只在测试类的时候生效，单独执行该测试方法无效） @RunWith:可以更改测试运行器 ，缺省值 org.junit.runner.Runner 一个单元测试类执行顺序为： @BeforeClass –&gt; @Before –&gt; @Test –&gt; @After –&gt; @AfterClass 每一个测试方法的调用顺序为： @Before –&gt; @Test –&gt; @After","categories":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/categories/spring-boot/"}],"tags":[{"name":"Junit","slug":"Junit","permalink":"https://blog.milk4j.com/tags/Junit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://blog.milk4j.com/tags/单元测试/"}]},{"title":"Docker安装nginx","slug":"Docker安装nginx","date":"2018-10-22T04:34:08.000Z","updated":"2018-10-24T09:53:47.517Z","comments":true,"path":"2018/10/22/Docker安装nginx/","link":"","permalink":"https://blog.milk4j.com/2018/10/22/Docker安装nginx/","excerpt":"","text":"方式一：通过 pull 仓库镜像一、下载镜像1docker pull nginx 二、使用镜像创建容器1234567891011121314151617181920212223242526cd ~mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf#www目录将映射为nginx容器配置的虚拟目录#logs目录将映射为nginx容器的日志目录#conf目录里的配置文件将映射为nginx容器的配置文件#找一份默认的 nginx.conf 配置文件放在 conf 目录下,否则下面启动会报错docker run -p 80:80 --name web -v $PWD/www:/www -v $PWD/logs:/wwwlogs -d nginxdocker cp web:/etc/nginx/nginx.conf #删除容器后再运行下面的命令docker run -p 80:80 --name web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/conf/servers:/etc/nginx/conf.d -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~#docker inspect [容器名|id]docker inspect mynginx 命令说明： -p 80:80：将容器的80端口映射到主机的80端口 –name web：将容器命名为web -v $PWD/www:/www：将主机中当前目录下的www挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf：将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs：将主机中当前目录下的logs挂载到容器的/wwwlogs 方式二：通过 Dockerfile构建构建准备工作123mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/confcd ~/nginxvi Dockerfile 在 Dockerfile 中输入如下内容：123456789101112131415161718#指定使用那个基础镜像FROM centosMAINTAINER ginkgoLABEL Discription=\"基于centos的nginx镜像\" version=\"1.0\"WORKDIR /usr/local/srcRUN yum install -y wgetRUN wget http://nginx.org/download/nginx-1.8.0.tar.gzRUN tar -zxvf nginx-1.8.0.tar.gzWORKDIR nginx-1.8.0#安装nginx所依赖的包RUN yum -y install gcc-c++RUN yum -y install pcre pcre-develRUN yum -y install zlib zlib-develRUN yum -y install openssl openssl-devel libssl-devRUN ./configureRUN makeRUN make installEXPOSE 80 通过Dockerfile 构建一个镜像1234# -t 镜像名 , \".\" 是Dockerfile 所在的目录，可以使用绝对路径docker build -t ginkgo/nginx .#查看镜像docker images 构建|运行容器1234567891011121314151617#找一份默认的 nginx.conf 配置文件放在 ~/nginx/conf 目录下,否则下面启动会报错docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~docker inspect [容器名|id]","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"","slug":"java应用jvm参数配置参考","date":"2018-10-22T01:48:39.617Z","updated":"2018-11-25T09:58:47.002Z","comments":true,"path":"2018/10/22/java应用jvm参数配置参考/","link":"","permalink":"https://blog.milk4j.com/2018/10/22/java应用jvm参数配置参考/","excerpt":"","text":"java应用jvm配置参考 一切配置在亲身测试之后，才比较靠谱。这里给出我们的经验值，仅供参考。 WEB服务器JVM配置容器内存4Gjava内存：4096m * 0.75 = 3072m 123456789-server//服务器模式-Xmx3072m //JVM最大允许分配的堆内存，按需分配-Xms3072m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存3Gjava内存：3072m * 0.7 = 2150m 123456789-server//服务器模式-Xmx2150m //JVM最大允许分配的堆内存，按需分配-Xms2150m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存2Gjava内存：2048m * 0.7 = 1434m 123456789-server//服务器模式-Xmx1434m //JVM最大允许分配的堆内存，按需分配-Xms1434m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存1.5Gjava内存：1536m * 0.7 = 1075m 123456789-server//服务器模式-Xmx1075m //JVM最大允许分配的堆内存，按需分配-Xms1075m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 容器内存1Gjava内存：1024m * 0.7 = 717m 123456789-server//服务器模式-Xmx717m //JVM最大允许分配的堆内存，按需分配-Xms717m //JVM初始分配的堆内存，一般和Xmx配置成一样以避免每次gc后JVM重新分配内存。-XX:NewRatio=1 //表示年轻代与年老代所占比值为1:1 -XX:+DisableExplicitGC //忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC //并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled //降低标记停顿-XX:+UseCMSCompactAtFullCollection //在FULL GC的时候对年老代的压缩-XX:CMSInitiatingOccupancyFraction=70 //使用cms作为垃圾回收使用70％后开始CMS收集 常用参数说明参数设置在Java虚拟机的参数中，有3种表示方法： 标准参数（-），所有的JVM实现都必须实现这些参数的功能，而且向后兼容； 非标准参数（-X），默认jvm实现这些参数的功能，但是并不保证所有jvm实现都满足，且不保证向后兼容； 非Stable参数（-XX），此类参数各个jvm实现会有所不同，将来可能会随时取消，需要慎重使用（但是，这些参数往往是非常有用的）； 常用参数现在的JVM运行Java程序时在高效性和稳定性方面做的非常出色。自适应内存管理、垃圾收集、及时编译、动态类加载、锁优化等使得普通程序员几乎不会case内存相关的事情。但JVM仍然大量的参数，使得我们可以针对不同场景进行不同的配置和调优。 -client-server指定JVM的启动模式是client模式还是server模式，具体就是 Java HotSpot Client(Server) VM 版本。目前64位的JDK启动，一定是server模式，会忽略这个参数。 -Xmn设置初始最大的年轻代堆大小。 -Xms设置初始的堆大小。 -Xmx设置最大的内存分配大小。一般的服务端部署，-Xms和-Xmx设置为同样大小。 基础回顾JVM内存结构当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。 Hotspot VM将内存划分为不同的物理区，就是“分代”思想的体现。如图所示，JVM内存主要由新生代、老年代、永久代构成。 新生代大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC）后只有少量对象存活，所以选用复制算法，只需要少量的复制成本就可以完成回收。新生代内又分三个区：一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。对象每经历一次Minor GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。 老年代在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。 永久代主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。 jdk1.8中, 永久代最终被移除，方法区移至Metaspace，字符串常量移至Java Heap。永久代的垃圾回收主要两部分：废弃常量和无用类。 常见垃圾回收器不同的垃圾回收器，适用于不同的场景。常用的垃圾回收器： 串行（Serial）回收器是单线程的一个回收器，简单、易实现、效率高。 并行（ParNew）回收器是Serial的多线程版，可以充分的利用CPU资源，减少回收的时间。 吞吐量优先（Parallel Scavenge）回收器，侧重于吞吐量的控制。 并发标记清除（CMS，Concurrent Mark Sweep）回收器是一种以获取最短回收停顿时间为目标的回收器，该回收器是基于“标记-清除”算法实现的。 实用方法jstatjstat可以实时显示本地或远程JVM进程中类装载、内存、垃圾收集、JIT编译等数据（如果要显示远程JVM信息，需要远程主机开启RMI支持）。如果在服务启动时没有指定启动参数-verbose:gc，则可以用jstat实时查看gc情况。 如图，如我本机RemoteMavenServer的GC情况（后两个参数表示，每隔1秒打印1次）： 参数 解释 S0 第一个Survivor的使用大小 S1 第二个Survivor的使用大小 EU 伊甸园区的使用大小 O 老年代使用大小 M 方法区使用大小 CCS 压缩类空间使用大小 YGC 年轻代垃圾回收次数 YGCT 年轻代垃圾回收消耗时间 FGC 老年代垃圾回收次数 FGCT 老年代垃圾回收消耗时间 GCT 垃圾回收消耗总时间 gc logGC日志是一个很重要的工具，它准确记录了每一次的GC的执行时间和执行结果，通过分析GC日志可以优化堆设置和GC设置，或者改进应用程序的对象分配模式。不同的垃圾收集器，输出的日志格式各不相同，但也有一些相同的特征。熟悉各个常用垃圾收集器的GC日志，是进行JVM调优的必备一步。 参数 说明 -XX:+PrintGCDetails 打印GC详细信息 -XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式） -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -XX:+PrintTenuringDistribution 在进行GC时打印survivor中的对象年龄分布信息 -Xloggc:$CATALINA_HOME/logs/gc.log 指定输出路径收集日志到日志文件 这里以-XX:+UseConcMarkSweepGC日志为例。-XX:+UseConcMarkSweepGC会指定CMS收集器+ParNew收集器+Serial Old收集器组合，优先使用ParNew收集器+CMS收集器的组合，当出现ConcurrentMode Fail或者Promotion Failed时，则采用ParNew收集器+Serial Old收集器的组合。日志如下： 123456789101112131415161718192021222324252627282930313233Java HotSpot(TM) 64-Bit Server VM (25.131-b11) for windows-amd64 JRE (1.8.0_131-b11), built on Mar 15 2017 01:23:53 by &quot;java_re&quot; with MS VC++ 10.0 (VS2010)Memory: 4k page, physical 8303556k(2846816k free), swap 16215992k(7664596k free)CommandLine flags: -XX:InitialHeapSize=29360128 -XX:MaxHeapSize=29360128 -XX:MaxNewSize=14680064 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC 2018-05-09T20:53:14.086+0800: 0.590: [GC (Allocation Failure) 2018-08-09T11:53:14.086+0800: 0.590: [ParNew: 11520K-&gt;1407K(12928K), 0.0034803 secs] 11520K-&gt;2254K(27264K), 0.0039082 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2018-05-09T20:53:14.247+0800: 0.751: [Full GC (System.gc()) 2018-08-09T11:53:14.247+0800: 0.751: [CMS: 846K-&gt;1930K(14336K), 0.0103698 secs] 7165K-&gt;1930K(27264K), [Metaspace: 5963K-&gt;5963K(1056768K)], 0.0104529 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 2018-05-09T20:53:14.292+0800: 0.795: [GC (Allocation Failure) 2018-08-09T11:53:14.292+0800: 0.795: [ParNew: 11519K-&gt;1199K(12928K), 0.0085679 secs] 13450K-&gt;3129K(27264K), 0.0086244 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 2018-05-09T20:53:14.333+0800: 0.836: [GC (Allocation Failure) 2018-08-09T11:53:14.333+0800: 0.836: [ParNew: 12719K-&gt;300K(12928K), 0.0002620 secs] 14649K-&gt;2230K(27264K), 0.0003041 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2018-05-09T20:53:14.364+0800: 0.867: [GC (Allocation Failure) 2018-08-09T11:53:14.364+0800: 0.867: [ParNew: 11820K-&gt;75K(12928K), 0.0002787 secs] 13750K-&gt;2005K(27264K), 0.0003223 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] # 并发标记周期开始，根区域扫描2018-05-09T20:59:47.982+0800: 9.634: [GC concurrent-root-region-scan-start]2018-05-09T20:59:47.982+0800: 9.652: [GC concurrent-root-region-scan-end, 0.0184308 secs]# 并发标记2018-05-09T20:59:47.982+0800: 9.652: [GC concurrent-mark-start]2018-05-09T20:59:47.982+0800: 9.693: [GC concurrent-mark-end, 0.0406187 secs]# 重新标记2018-05-09T20:59:47.982+0800: 9.695: [GC remark 9.695: [Finalize Marking, 0.0005100 secs] 9.695: [GC ref-proc, 0.0003461 secs] 9.696: [Unloading, 0.0069466 secs], 0.0082011 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] # 独占清理2018-05-09T20:59:47.982+0800: 9.703: [GC cleanup 25M-&gt;21M(1024M), 0.0027119 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] # 并发清理2018-05-09T20:59:47.982+0800: 9.706: [GC concurrent-cleanup-start]2018-05-09T20:59:47.982+0800: 9.706: [GC concurrent-cleanup-end, 0.0000167 secs]2018-05-09T20:54:39.299+0800: 85.803: [Full GC (System.gc()) 2018-08-09T11:54:39.299+0800: 85.803: [CMS: 1930K-&gt;1832K(14336K), 0.0089015 secs] 12748K-&gt;1832K(27264K), [Metaspace: 6035K-&gt;6035K(1056768K)], 0.0089724 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap par new generation total 12928K, used 227K [0x00000000fe400000, 0x00000000ff200000, 0x00000000ff200000) eden space 11520K, 1% used [0x00000000fe400000, 0x00000000fe438cd8, 0x00000000fef40000) from space 1408K, 0% used [0x00000000fef40000, 0x00000000fef40000, 0x00000000ff0a0000) to space 1408K, 0% used [0x00000000ff0a0000, 0x00000000ff0a0000, 0x00000000ff200000) concurrent mark-sweep generation total 14336K, used 1832K [0x00000000ff200000, 0x0000000100000000, 0x0000000100000000) Metaspace used 6045K, capacity 6252K, committed 6400K, reserved 1056768K class space used 691K, capacity 761K, committed 768K, reserved 1048576K 第三行把当前使用的JVM参数打印出来，其中，-XX:MaxTenuringThreshold=6是指对象从新生代晋升到老年代需要对象年龄达到6岁，即经过6次GC。 第四行是新生代Young区的GC，首先是GC发生的时间。然后是GC发生的原因GC (Allocation Failure)，对象分配失败。[ParNew: 11520K-&gt;1407K(12928K), 0.0034803 secs]表示新生代回收前是11520K，回收后是1407K，新生代总大小12928K，回收耗时0.0034803 secs。11520K-&gt;2254K(27264K), 0.0039082 secs表示回收前堆大小11520K，回收后堆大小2254K，堆的总大小27264K。 第五行是老年代Old区的GC，首先是GC发生的时间。然后是GC发生的原因System.gc()，由于代码调用。[CMS: 846K-&gt;1930K(14336K), 0.0103698 secs]表示回收前老年代是846K，回收后1930K，老年代总大小14336K，回收耗时0.0103698 secs。7165K-&gt;1930K(27264K)表示回收前堆大小7165K，回收后堆大小1930K，堆的总大小27264K。 后面有一次并发标记周期，设置参数-XX:InitiatingHeapOccupancyPercent的值，可以指定堆占有率达到百分之多少时，触发并发标记，默认值是45%。 最后打印出了堆的整体使用情况，分为新生代、老年代、元空间。 调优方法请记住下面的原则： 多数的Java应用不需要在服务器上进行GC优化； 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC优化是到最后不得已才采用的手段； 在实际使用中，分析GC情况优化代码比优化GC参数要多得多。 GC优化的目的有两个： 将转移到老年代的对象数量降低到最小； 减少full GC的执行时间； 为了达到上面的目的，一般地，你需要做的事情有： 减少使用全局变量和大对象； 调整新生代的大小到最合适； 设置老年代的大小为最合适； 选择合适的GC收集器； 进行监控和调优的一般步骤： 监控GC的状态使用各种JVM工具，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和gc日志，根据实际的各区域内存划分和GC执行时间，觉得是否进行优化； 分析结果，判断是否需要优化如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化；如果GC时间超过1-3秒，或者频繁GC，则必须优化； 注：如果满足下面的指标，则一般不需要进行GC调优： Minor GC执行时间不到50ms；Minor GC执行不频繁，约10秒一次；Full GC执行时间不到1s；Full GC执行频率不算频繁，不低于10分钟1次； 调整GC类型和内存分配如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择； 不断的分析和调整通过不断的试验和试错，分析并找到最合适的参数 全面应用参数如果找到了最合适的参数，则将这些参数应用到所有服务器，并进行后续跟踪。","categories":[],"tags":[]},{"title":"Kotlin在IntelliJ Idea中无法生成 spring-configuration-metadata.json 文件","slug":"用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件","date":"2018-09-05T11:12:09.000Z","updated":"2018-10-31T01:32:08.944Z","comments":true,"path":"2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","link":"","permalink":"https://blog.milk4j.com/2018/09/05/用Kotlin在IntelliJ-Idea中无法生成-spring-configuration-metadata-json-文件/","excerpt":"","text":"问题描述在百度搜索关键词,搜索到了 Stack Overflow 有相关问题 spring-configuration-metadata.json file is not generated in IntelliJ Idea for Kotlin @ConfigurationProperties class 原文链接: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko 按照里面的方法试了一下,失败了,然后继续百度,在spring-boot的官方文档中找到了相关线索, 直达链接: https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties 在spring官方文档中找到了kotlin的官方示例,链接地址: https://kotlinlang.org/docs/reference/kapt.html#using-in-maven 下面是我参考上面的文档所得出来的可用方案 解决方案一、添加插件在pom文件中添加插件,没有写版本号是因为项目继承了spring-boot-starter-parent 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;proc&gt;none&lt;/proc&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- Replacing default-compile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;!-- Replacing default-testCompile as it is treated specially by maven --&gt; &lt;execution&gt; &lt;id&gt;default-testCompile&lt;/id&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;java-test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;configuration&gt; &lt;args&gt; &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt; &lt;/args&gt; &lt;compilerPlugins&gt; &lt;plugin&gt;spring&lt;/plugin&gt; &lt;/compilerPlugins&gt; &lt;jvmTarget&gt;$&#123;java.version&#125;&lt;/jvmTarget&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;kapt&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;kapt&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sourceDirs&gt; &lt;sourceDir&gt;src/main/kotlin&lt;/sourceDir&gt; &lt;sourceDir&gt;src/main/java&lt;/sourceDir&gt; &lt;/sourceDirs&gt; &lt;annotationProcessorPaths&gt; &lt;!-- Specify your annotation processors here. --&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;test-compile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;test-compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt; &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt; &lt;version&gt;1.2.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt;&lt;/plugins&gt; 二、使用插件生成我之前也是使用了同样的插件,但是始终生成不出来文件,直到看了kotlin官方文档我才发现有这么一句话 文字的意思是: “请注意，kapt仍然不支持IntelliJ IDEA自己的构建系统。当你想要重新运行注释处理器时，可以从“Maven Projects”工具栏启动构建。” 很是坑爹啊,你也不标红也不加粗是想怎样啊 好了,那就按照他说的做吧, 双击下面的插件按钮就可以生产spring-configuration-metadata.json文件了 参考文档: https://stackoverflow.com/questions/37858833/spring-configuration-metadata-json-file-is-not-generated-in-intellij-idea-for-ko https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-kotlin.html#boot-features-kotlin-configuration-properties &lt;https://kotlinlang.org/docs/reference/kapt.html","categories":[{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/categories/kotlin/"}],"tags":[{"name":"kotlin","slug":"kotlin","permalink":"https://blog.milk4j.com/tags/kotlin/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.milk4j.com/tags/spring-boot/"}]},{"title":"Docker基本使用","slug":"Docker基本使用","date":"2018-06-22T03:26:02.000Z","updated":"2018-10-22T11:13:20.539Z","comments":true,"path":"2018/06/22/Docker基本使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/22/Docker基本使用/","excerpt":"","text":"一. docker使用1. docker ps 查看运行中的容器2. docker images 查看docker镜像3. docker rm id(容器id) 删除容器（容器id可以通过docker ps查看，容器必须停止后才能删除）3.1 删除全部的容器 docker rm docker ps -a -q4. docker stop id(容器id) 停止容器运行5. docker rmi id(镜像id) 删除镜像6. docker pull ubuntu:16.04(镜像名称:版本号) 下载镜像7. docker run -it ubuntu:16.04 创建并运行容器容器 -t 表示在新容器内指定一个伪终端或终端 -i 表示允许我们对容器内的 (STDIN) 进行交互 -p 指定映射端口 -d 在后台运行容器并打印容器ID 7.1 docker run -dit ubuntu:16.04 创建并后台运行容器7.2 docker run -ditp 8080:8080（主机端口:容器端口） ubuntu:16.04 创建并后台运行容器且映射容器的端口8. docker attach id(容器id) 进入正在运行中的容器环境9. 退出容器9.1 exit 直接退出容器并终止容器运行9.2 [ctrl+p]+[ctrl+q]（快捷键） 退出容器，但是不会终止容器运行10. docker commit -m’版本标识’ id(容器id) ubuntu:16.04(镜像与版本号) 提交镜像且生成镜像（可以通过该命令把搭建好的容器打包成一个新的镜像或者覆盖原镜像（即是修改原镜像内容，生成的镜像名与版本号相同就可以直接覆盖））","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.milk4j.com/tags/docker/"}]},{"title":"ElasticSearch Rest 客户端使用(长文,待续...)","slug":"ElasticSearch-Rest-客户端使用","date":"2018-06-20T12:36:39.000Z","updated":"2018-10-31T01:38:12.054Z","comments":true,"path":"2018/06/20/ElasticSearch-Rest-客户端使用/","link":"","permalink":"https://blog.milk4j.com/2018/06/20/ElasticSearch-Rest-客户端使用/","excerpt":"","text":"起步阅读文档须知,文档基于Elasticsearch 6.x,阅读要求,熟悉 ElasticSearch 的语法 兼容性高级客户端要求最低的 java 版本是1.8 ，它依赖 Elasticsearch 的核心工程，客户端的版本应该和 Elasticsearch 的版本保持一致，高级客户端和 TransportClient【TCP 连接客户端】 接受一样的请求参数，并且返回一样的响应结果，如果你想从 TransportClient 客户端迁移到 REST 客户端，请参考迁移手册 高级客户端保证能够与运行在相同主要版本和更高版本上的Elasticsearch节点进行通信。它不需要与通信的Elasticsearch节点处于相同的版本，因为它是向前兼容的，这意味着它支持与更高版本的Elasticsearch进行通信，而不是与其开发的版本进行通信。 6.0 客户端能够与任何6.x版本的 Elasticsearch节点通信，而6.1客户端肯定能够与6.1,6.2和任何更高版本的6.x版本通信，但在与老版的Elasticsearch节点通信时可能存在不兼容问题版本，例如6.1和6.0，6.1客户端为一些 api 添加了新的请求体字段支持，然而6.0节点却不支持。 建议在将Elasticsearch集群升级到新的主版本时升级高级客户端，因为REST API中断更改可能会导致意外结果，具体取决于请求所针对的节点，并且新添加的API仅支持新版本的客户端。一旦集群中的所有节点都升级到新的主版本，客户端应保持同步更新。 Java api 文档文档地址：&lt;https://artifacts.elastic.co/javadoc/org/elasticsearch/client/elasticsearch-rest-high-level-client/6.3.1/index.html&gt; maven 仓库高级Java REST客户端托管在 Maven Central上。所需的最低Java版本是1.8。 高级REST客户端与Elasticsearch具有相同的发布周期。将版本替换为所需的客户端版本。 如果您正在寻找SNAPSHOT版本，可以通过https://snapshots.elastic.co/maven/获取Elastic Maven Snapshot存储库。 Maven 配置12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.1&lt;/version&gt;&lt;/dependency&gt; Gradel 配置123dependencies &#123; compile 'org.elasticsearch.client:elasticsearch-rest-high-level-client:6.3.1'&#125; 依赖高级客户端依赖下面的组件及其传递依赖性： org.elasticsearch.client:elasticsearch-rest-client org.elasticsearch:elasticsearch 初始化一个RestHighLevelClient实例需要一个低级客户端的Builder 来构建如下： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"localhost\", 9200, \"http\"), new HttpHost(\"localhost\", 9201, \"http\"))); 高级客户端将在内部创建用于执行请求的低级客户端，低级客户端基于框架提供的builder，并管理其生命周期。 高级客户端实例应该在不再需要时关闭，以便正确释放它使用的所有资源，以及底层的http客户端实例及其线程。这可以通过close 方法完成，该方法将关闭内部RestClient实例。 1client.close(); Document APIJava高级REST客户端支持以下文档API： 单文档API： index api - 索引API get api - 获取API delete api - 删除API update api - 更新API 多文档API bulk api - 批量操作 api Multi-Get API - 批量获取 api Index APIIndex 请求体一个引索请求需要下面的参数： 12345678910IndexRequest request = new IndexRequest( \"posts\", //index 名 \"doc\", //type 名 \"1\"); //文档 IDString jsonString = \"&#123;\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"&#125;\";request.source(jsonString, XContentType.JSON);//设置 string 类型的文档source 构建文档 source 的方式除了String上面显示的示例之外，还可以以不同方式提供文档源 ： 方式一：以 Map 的方式提供的文档源，Map自动转换为JSON格式 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"user\", \"kimchy\");jsonMap.put(\"postDate\", new Date());jsonMap.put(\"message\", \"trying out Elasticsearch\");IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(jsonMap); 方式二：以XContentBuilder对象方式提供，Elasticsearch内置了helper生成JSON内容 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(\"user\", \"kimchy\"); builder.timeField(\"postDate\", new Date()); builder.field(\"message\", \"trying out Elasticsearch\");&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(builder); 方式三：以键值对方式提供，转换为JSON格式 1234IndexRequest indexRequest = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"user\", \"kimchy\", \"postDate\", new Date(), \"message\", \"trying out Elasticsearch\"); 可选参数可以选择以下参数： 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1));request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);request.setRefreshPolicy(\"wait_for\"); 设置版本 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 设置文档操作类型 12request.opType(DocWriteRequest.OpType.CREATE); request.opType(\"create\"); 文档执行之前，设置 pipeline 名 1request.setPipeline(&quot;pipeline&quot;); 同步执行方式1IndexResponse indexResponse = client.index(request); 异步执行方式索引请求的异步执行需要将IndexRequest 实例和ActionListener实例都传递给异步方法： 123456789ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;IndexResponse indexResponse = client.index(request); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 引索响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 123456789101112131415161718String index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //创建文档操作&#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //更新文档操作&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; //处理成功分片数小于总分片数的情况&#125;if (shardInfo.getFailed() &gt; 0) &#123;//理潜在的失败情况 for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 如果存在文档版本冲突，则会抛出ElasticsearchException： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .version(1);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; 如果已存在具有相同索引，类型和ID的文档，opType设置为create也会发生冲突： 12345678910IndexRequest request = new IndexRequest(\"posts\", \"doc\", \"1\") .source(\"field\", \"value\") .opType(DocWriteRequest.OpType.CREATE);try &#123; IndexResponse response = client.index(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Get APIGet 请求体构建 GetRequest 的参数如下： 1GetRequest getRequest = new GetRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置返回响应不包含任何字段，默认情况下返回响应包含该所有字段 1request.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回响应包含哪些字段 12345String[] includes = new String[]&#123;\"message\", \"*Date\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置返回响应不包含哪些字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;\"message\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.fetchSourceContext(fetchSourceContext); 设置检索哪些存储字段 123request.storedFields(\"message\"); //为特定存储字段配置检索 (要求在映射中单独存储字段)GetResponse getResponse = client.get(request);String message = getResponse.getField(\"message\").getValue();//获取message存储的值 (要求将字段单独存储在映射中) 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置偏好 1request.preference(\"preference\"); 设置实时标识，默认 true 1request.realtime(false); 设置每次获取文档之前是否执行刷新操作，默认 false 1request.refresh(true); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1GetResponse getResponse = client.get(getRequest); 异步执行get请求的异步执行需要将GetRequest 实例和ActionListener实例都传递给异步方法 12345678910ActionListener&lt;GetResponse&gt; listener = new ActionListener&lt;GetResponse&gt;() &#123; @Override public void onResponse(GetResponse getResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;GetResponse getResponse = client.get(getRequest); 异步方法不会阻塞并立即返回。一旦完成，如果执行成功，则使用该方法ActionListener回调onResponse，如果失败则回调onFailure方法。 响应结果返回的IndexResponse包含了有关已执行操作的信息，如下所示： 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); byte[] sourceAsBytes = getResponse.getSourceAsBytes(); &#125; else &#123; //处理未找到文档的方案。注意，虽然返回的响应具有404状态代码，但他会返回一个有效GetResponse而不是抛出异常。此类响应不包含任何文档字段，而且isExists方法返回false。&#125; 当对不存在的索引(index)执行get请求时，响应会有404状态代码，但是会抛出ElasticsearchException，需要按如下方式处理： 12345678GetRequest request = new GetRequest(\"does_not_exist\", \"doc\", \"1\");try &#123; GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果请求特定版本的文档，并且现有文档具有不同的版本号，则会引发版本冲突： 12345678try &#123; GetRequest request = new GetRequest(\"posts\", \"doc\", \"1\").version(2); GetResponse getResponse = client.get(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //处理版本冲突 &#125;&#125; Exists API如果文档存在就返回 true，否则返回 false Exists Request它的GetRequest就像Get API一样。支持所有可选参数 。由于exists()只返回true或false，所有建议关闭返回_source和任何存储的字段，以便请求更加轻量： 123456GetRequest getRequest = new GetRequest( \"posts\", \"doc\", \"1\"); getRequest.fetchSourceContext(new FetchSourceContext(false)); //不返回_sourcegetRequest.storedFields(\"_none_\"); //不返回存储字段 同步执行1boolean exists = client.exists(getRequest); 异步执行123456789ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.existsAsync(getRequest, listener); Delete APIDelete RequestDeleteRequest 参数如下： 1DeleteRequest request = new DeleteRequest(\"posts\",\"doc\",\"1\"); 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置版本号 1request.version(2); 设置版本类型 1request.versionType(VersionType.EXTERNAL); 同步执行1DeleteResponse deleteResponse = client.delete(request); 异步执行123456789ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.deleteAsync(request, listener); Delete Response返回的DeleteResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 它还可以检查文档是否存在 12345DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"does_not_exist\");DeleteResponse deleteResponse = client.delete(request);if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) &#123; //如果找不到要删除的文档&#125; 如果请求的文档版本冲突，会抛ElasticsearchException异常 12345678try &#123; DeleteRequest request = new DeleteRequest(\"posts\", \"doc\", \"1\").version(2); DeleteResponse deleteResponse = client.delete(request);&#125; catch (ElasticsearchException exception) &#123; if (exception.status() == RestStatus.CONFLICT) &#123; //引发的异常表示返回了版本冲突错误 &#125;&#125; Update APIUpdateRequest参数如下： 1UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\"); Update API允许使用脚本或传递部分文档来更新现有文档。 使用脚本更新文档使用内联脚本 12345Map&lt;String, Object&gt; parameters = singletonMap(\"count\", 4); //使用Map对象作为脚本参数Script inline = new Script(ScriptType.INLINE, \"painless\", \"ctx._source.field += params.count\", parameters); //使用painless语言和提供的参数创建内联脚本UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");request.script(inline); //将脚本设置为更新请求 或者使用存储在es 中的脚本 12Script stored =new Script(ScriptType.STORED, null, \"increment-field\", parameters);//使用存储在 es 中的painless脚本，脚本名为increment-fieldrequest.script(stored); 传递部分文档作为参数来更新文档当使用部分文档来更新现有的文档时，部分文档将与现有文档合并。 部分文档可以以不同方式提供： 123456UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\");String jsonString = \"&#123;\" + \"\\\"updated\\\":\\\"2017-01-01\\\",\" + \"\\\"reason\\\":\\\"daily update\\\"\" + \"&#125;\";request.doc(jsonString, XContentType.JSON);//用json格式的字符串作为部分文档源 以 Map 提供部分文档源，会被自动转化成 json 格式，如下 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(\"updated\", new Date());jsonMap.put(\"reason\", \"daily update\");UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(jsonMap); 用XContentBuilder对象作为部分文档源，Elasticsearch内置的 helpers 会自动将它转化为 json 文档 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(\"updated\", new Date()); builder.field(\"reason\", \"daily update\");&#125;builder.endObject();UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(builder); 使用键值对作为部分文档源，他会被转换成 json 文本 123UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"updated\", new Date(), \"reason\", \"daily update\"); Upserts如果文档尚不存在，则可以使用以下upsert方法来将它作为新文档插入： 12String jsonString = \"&#123;\\\"created\\\":\\\"2017-01-01\\\"&#125;\";request.upsert(jsonString, XContentType.JSON); 和部分文档更新一样，upsert 方法接受String, Map, XContentBuilder or 键值对作为入参 可选参数 设置路由 1request.routing(\"routing\"); 设置父文档 1request.parent(\"parent\"); 设置超时时间 12request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\"1s\"); 设置刷新策略 12request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); request.setRefreshPolicy(\"wait_for\"); 设置重试更新操作的次数 如果要更新的文档已在更新操作的get和indexing阶段之间的另一个操作更改，则重试 1request.retryOnConflict(3); 设置是否获取新文档内容，默认 false 1request.fetchSource(true); 指定返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;//正则匹配String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定不返回哪些字段 123String[] includes = new String[]&#123;\"updated\", \"r*\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;request.fetchSource(new FetchSourceContext(true, includes, excludes)); 设置文档版本号 1request.version(2); 设置是否启用noop 检测 1request.detectNoop(false); 指示脚本必须运行，无论文档是否存在，即如果文档尚不存在，脚本将负责创建文档 1request.scriptedUpsert(true); 如果文档不存在，则表明必须将部分文档用作upsert文档 1request.docAsUpsert(true); 设置在执行更新操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); 同步执行1UpdateResponse updateResponse = client.update(request); 异步执行12345678client.updateAsync(request, new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;); UpdateResponse返回的UpdateResponse包含了有关已执行操作的信息，如下所示： 12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; //首次创建文档（upsert）&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; //文档更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; //文档未受更新影响，即未对文档执行任何操作（noop）&#125; UpdateRequest 通过fetchSource方法启用获取文档功能时，响应包含更新文档的来源： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); byte[] sourceAsBytes = result.source(); &#125; else &#123; &#125; 可以检查分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); &#125;&#125; 当对一个不存在的文档执行UpdateRequest时，响应具有404状态代码，会抛出ElasticsearchException，需要按如下方式处理： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"type\", \"does_not_exist\") .doc(\"field\", \"value\");try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch (ElasticsearchException e) &#123; if (e.status() == RestStatus.NOT_FOUND) &#123; &#125;&#125; 如果发生文档版本冲突，会抛出异常： 123456789UpdateRequest request = new UpdateRequest(\"posts\", \"doc\", \"1\") .doc(\"field\", \"value\") .version(1);try &#123; UpdateResponse updateResponse = client.update(request);&#125; catch(ElasticsearchException e) &#123; if (e.status() == RestStatus.CONFLICT) &#123; &#125;&#125; Bulk APIBulkRequestBulkRequest可用于使用单个请求执行多个索引，更新和/或删除操作 它要求至少将一个操作添加到批量请求： 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(\"posts\", \"doc\", \"1\") .source(XContentType.JSON,\"field\", \"foo\"));request.add(new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON,\"field\", \"bar\"));request.add(new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON,\"field\", \"baz\")); 并且可以添加不同的操作类型BulkRequest： 123456BulkRequest request = new BulkRequest();request.add(new DeleteRequest(\"posts\", \"doc\", \"3\")); request.add(new UpdateRequest(\"posts\", \"doc\", \"2\") .doc(XContentType.JSON,\"other\", \"test\"));request.add(new IndexRequest(\"posts\", \"doc\", \"4\") .source(XContentType.JSON,\"field\", \"baz\")); 可选参数 设置超时时间 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置刷新策略 12request.timeout(TimeValue.timeValueMinutes(2)); request.timeout(\"2m\"); 设置在索引/更新/删除操作之前必须处于活动状态的分片副本数 12request.waitForActiveShards(2); request.waitForActiveShards(ActiveShardCount.ALL); //可选ActiveShardCount.ALL、 ActiveShardCount.ONE 、 ActiveShardCount.DEFAULT 同步执行1BulkResponse bulkResponse = client.bulk(request); 异步执行123456789ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.bulkAsync(request, listener); BulkResponse响应结果，允许迭代每个结果，如下所示： 123456789101112131415for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; //可以是IndexResponse、UpdateResponse、DeleteResponse，他们可以全部被视为DocWriteResponse实例 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; &#125;&#125; 批量响应提供了一种快速检查一个或多个操作是否失败的方法： 123if（bulkResponse.hasFailures（））&#123; //如果至少有一个操作失败，则返回true&#125; 在这种情况下，有必要迭代所有操作结果，以检查操作是否失败，如果是，则获取相应的失败信息： 123456for（BulkItemResponse bulkItemResponse：bulkResponse）&#123; if（bulkItemResponse.isFailed（））&#123; BulkItemResponse.Failure failure = bulkItemResponse.getFailure（）; &#125;&#125; 批量处理器BulkProcessor提供了一个工具类简化操作，它可以透明地执行添加到 processor 中的 index/update/delete操作。 为了执行请求，BulkProcessor需要以下组件： RestHighLevelClient 此客户端用于执行BulkRequest 和获取BulkResponse BulkProcessor.Listener 在每次BulkRequest执行之前、之后或BulkRequest失败时调用器监听 然后该BulkProcessor.builder方法可用于构建新的BulkProcessor： 1234567891011121314151617181920BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); BulkProcessor.Builder提供了方法来配置BulkProcessor处理请求的行为： 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500);//根据当前添加的操作数设置何时刷新新的批量请求（默认为1000，使用-1禁用它） builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); //根据当前添加的操作内容大小设置何时刷新新的批量请求（默认为5Mb，使用-1禁用它）builder.setConcurrentRequests(0); //设置允许执行的并发请求数（默认为1，使用0只允许执行单个请求）builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); //BulkRequest如果间隔超过，则 设置刷新间隔刷新任何挂起（默认为未设置）builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3));//设置一个最初等待1秒的常量重试策略，最多重试3次。见BackoffPolicy.noBackoff()、BackoffPolicy.constantBackoff()、BackoffPolicy.exponentialBackoff() 提供更多的选择 一旦BulkProcessor被创建，请求可以被添加到processor： 12345678910111213IndexRequest one = new IndexRequest(\"posts\", \"doc\", \"1\"). source(XContentType.JSON, \"title\", \"In which order are my Elasticsearch queries executed?\");IndexRequest two = new IndexRequest(\"posts\", \"doc\", \"2\") .source(XContentType.JSON, \"title\", \"Current status and upcoming changes in Elasticsearch\");IndexRequest three = new IndexRequest(\"posts\", \"doc\", \"3\") .source(XContentType.JSON, \"title\", \"The Future of Federated Search in Elasticsearch\");bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行所有的请求，并且为每次的 BulkRequest 回调BulkProcessor.Listener，监听器提供了访问 BulkRequest 和 BulkResponse 的方法 12345678910111213141516171819202122232425BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); logger.debug(\"Executing bulk [&#123;&#125;] with &#123;&#125; requests\", executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; logger.warn(\"Bulk [&#123;&#125;] executed with failures\", executionId); &#125; else &#123; logger.debug(\"Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds\", executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; //执行失败后调用 logger.error(\"Failed to execute bulk\", failure); &#125;&#125;; 将所有请求添加到BulkProcessor后，需要关闭其实例，有两种关闭方式。 该awaitClose()方法可用于等待所有请求都已处理或指定的等待时间： 1boolean terminated = bulkProcessor.awaitClose（30L，TimeUnit.SECONDS）;//true：如果所有批量请求都已完成，false：在所有批量请求完成之前等待时间已过 close()方法可用于立即关闭BulkProcessor： 1bulkProcessor.close（）; 两种方法在关闭处理器之前刷新已经添加到处理器的请求，并且禁止添加新请求 Multi-Get APImultiGet API 可以在单个请求中执行多个 get 请求 Multi-Get Request获取一个 MultiGetRequest实例，然后添加多个 MultiGetRequest.Item: 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( \"index\", \"type\", \"example_id\")); request.add(new MultiGetRequest.Item(\"index\", \"type\", \"another_id\")); 可选参数multiGet和 get Api支持相同的可选参数. 你可以在 Item上设置可选参数: 设置不返回任何文档，默认返回文档 123request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE) ); 设置返回文档的哪些字段 123456String[] includes = new String[] &#123;\"foo\", \"*r\"&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 设置不返回文档的哪些字段 123456String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[] &#123;\"foo\", \"*r\"&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .fetchSourceContext(fetchSourceContext)); 配置返回指定的存储字段 12345request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .storedFields(\"foo\")); //设置返回存储字段 fooMultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];String value = item.getResponse().getField(\"foo\").getValue(); //获取存储字段foo的值 其他可选参数 12345678910request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_routing\") .routing(\"some_routing\"));//设置路由 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_parent\") .parent(\"some_parent\"));//设置父文档 request.add(new MultiGetRequest.Item(\"index\", \"type\", \"with_version\") .versionType(VersionType.EXTERNAL)//设置文档版本类型 .version(10123L)); //设置版本号request.preference(\"some_preference\"); //设置偏好request.realtime(false); //设置实时标识，默认为 true request.refresh(true); //获取文档之前执行刷新操作，默认 false 同步执行1MultiGetResponse response = client.multiGet(request); 异步执行123456789101112ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;MultiGetResponse response = client.multiGet(request); MultiGetResponse返回的MultiGetResponse通过getResponses方法可以获取一个 MultiGetItemResponse 列表，列表中的响应与请求的顺序相同，如果 get 成功 MultiGetItemResponse包含一个 GetResponse，如果它失败了会包含一个MultiGetResponse.Failure 1234567891011121314MultiGetItemResponse firstItem = response.getResponses（）[0];assertNull（firstItem.getFailure（））;//如果成功，返回 null GetResponse firstGet = firstItem.getResponse（）; //获取 GetResponseString index = firstItem.getIndex（）;String type = firstItem.getType（）;String id = firstItem.getId（）;if（firstGet.isExists（））//判断文档是否存在 long version = firstGet.getVersion（）; String sourceAsString = firstGet.getSourceAsString（）; Map &lt;String，Object&gt; sourceAsMap = firstGet.getSourceAsMap（）; byte [] sourceAsBytes = firstGet.getSourceAsBytes（）; &#125; else &#123; &#125; 如果请求的 index 不存在，则返回响应会包含一个异常信息 1234567assertNull(missingIndexItem.getResponse()); Exception e = missingIndexItem.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(\"reason=no such index\")); 请求文档版本冲突，则返回响应会包含一个异常信息 12345678910111213MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item(\"index\", \"type\", \"example_id\") .version(1000L));MultiGetResponse response = client.multiGet(request);MultiGetItemResponse item = response.getResponses()[0];assertNull(item.getResponse()); Exception e = item.getFailure().getFailure(); ElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.CONFLICT, ee.status()); assertThat(e.getMessage(), containsString(\"version conflict, current version [1] is \" + \"different than the one provided [1000]\")); Search API高级客户端支持下面的 Search API: Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequest1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); searchRequest.source(searchSourceBuilder); 可选参数12345SearchRequest searchRequest = new SearchRequest(\"posts\"); searchRequest.types(\"doc\"); searchRequest.routing(\"routing\"); searchRequest.indicesOptions(IndicesOptions.lenientExpandOpen());searchRequest.preference(\"_local\"); 使用 SearchBuilder12345SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.termQuery(\"user\", \"kimchy\")); sourceBuilder.from(0); sourceBuilder.size(5); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); 构建查询语句12345678MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(\"user\", \"kimchy\");matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); matchQueryBuilder.fuzziness(Fuzziness.AUTO); matchQueryBuilder.prefixLength(3); matchQueryBuilder.maxExpansions(10); searchSourceBuilder.query(matchQueryBuilder); 设置排序12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); sourceBuilder.sort(new FieldSortBuilder(\"_uid\").order(SortOrder.ASC)); 文档过滤1234sourceBuilder.fetchSource(false);String[] includeFields = new String[] &#123;\"title\", \"user\", \"innerObject.*\"&#125;;String[] excludeFields = new String[] &#123;\"_type\"&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 字段高亮123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(\"title\"); highlightTitle.highlighterType(\"unified\"); highlightBuilder.field(highlightTitle); HighlightBuilder.Field highlightUser = new HighlightBuilder.Field(\"user\");highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 添加聚合查询123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(\"by_company\") .field(\"company.keyword\");aggregation.subAggregation(AggregationBuilders.avg(\"average_age\") .field(\"age\"));searchSourceBuilder.aggregation(aggregation); 请求建议词123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(\"user\").text(\"kmichy\"); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(\"suggest_user\", termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 分析查询和聚合profile API 可用于为特定搜索分析查询和聚合的执行情况。为了使用它, 必须在 SearchSourceBuilder 上设置profile标志为 true: 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行 SearchRequest 后, 相应的 SearchResponse 将包含分析结果。 同步执行1SearchResponse searchResponse = client.search(searchRequest); 异步执行执行 SearchRequest 也可以以异步方式进行, 以便客户端可以直接返回。用户需要通过将请求和监听器传递给异步搜索方法来指定如何处理响应或潜在故障: 123456789101112ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.searchAsync(searchRequest, listener); 异步方法不会阻止线程，也不会立即返回。完成该操作后, 如果执行成功则回调ActionListener的 onResponse 方法，失败则回调 onFailure` 方法 SearchResponse执行搜索返回的 SearchResponse 提供了有关搜索执行本身以及对返回访问的文档的详细信息。看下有关于请求执行操作的信息, 如 HTTP 状态代码、执行时间或请求是否提前终止或超时: 1234RestStatus status = searchResponse.status();TimeValue took = searchResponse.getTook();Boolean terminatedEarly = searchResponse.isTerminatedEarly();boolean timedOut = searchResponse.isTimedOut(); 其次, 响应还提供有关在分片级别上执行的信息, 提供有关受影响搜索的分片总数以及成功与失败的分片的统计数据。潜在的故障也可以通过迭代 ShardSearchFailure 数组来处理, 如下面的示例所示: 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; 获取搜索命中的文档要获得对返回的文档的访问权限, 我们首先需要得到响应中包含的 SearchHits： 123SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); SearchHits 提供有关所有命中的全局信息, 如命中总数或最大得分: 12long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore(); 嵌套在 SearchHits 中的是可以迭代的单个搜索结果: 1234SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit&#125; SearchHit 提供对基本信息的访问, 如索引、类型、docId 和每个搜索命中的分数: 1234String index = hit.getIndex();String type = hit.getType();String id = hit.getId();float score = hit.getScore(); 此外, 它还允许您返回文档源, 既可以是简单的 JSON 字符串, 也可以是键/值对的映射。在此映射中,通常键值对的键为字段名, 值为字段值。多值字段作为对象的列表返回, 嵌套对象作为另一个键/值映射。这些案件需要相应地强制执行: 123456String sourceAsString = hit.getSourceAsString();Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();String documentTitle = (String) sourceAsMap.get(\"title\");List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(\"user\");Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(\"innerObject\"); 获取高亮结果可以从结果中获取每个 SearchHit 中高亮显示的文本片段。SearchHit提供对 HighlightField 实例的访问, 其中每一个都包含一个或多个突出显示的文本片段: 1234567SearchHits hits = searchResponse.getHits();for (SearchHit hit : hits.getHits()) &#123; Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); HighlightField highlight = highlightFields.get(\"title\"); Text[] fragments = highlight.fragments(); String fragmentString = fragments[0].string();&#125; 获取聚合结果可以从 SearchResponse 获取聚合结果, 首先获取聚合树的根、聚合对象, 然后按名称获取聚合 12345Aggregations aggregations = searchResponse.getAggregations();Terms byCompanyAggregation = aggregations.get(\"by_company\"); Bucket elasticBucket = byCompanyAggregation.getBucketByKey(\"Elastic\"); Avg averageAge = elasticBucket.getAggregations().get(\"average_age\"); double avg = averageAge.getValue(); 请注意, 如果按名称访问聚合, 则需要根据所请求的聚合类型指定聚合接口, 否则将引发抛出: 1Range range = aggregations.get(\"by_company\"); //这将引发异常, 因为 \"by_company\" 是一个term聚合, 但这里尝试将它一范围聚合取出 还可以将所有的聚合 转化成 map ,以聚合名作为 key 值。在这种情况下,需要显示强制转换到正确的类型: 12Map&lt;String, Aggregation&gt; aggregationMap = aggregations.getAsMap();Terms companyAggregation = (Terms) aggregationMap.get(\"by_company\"); 还有一些 getter 将所有顶层聚合作为列表返回: 1List&lt;Aggregation&gt; aggregationList = aggregations.asList(); 最后, 可以遍历所有聚合, 然后根据它们的类型决定如何进一步处理它们: 1234567for (Aggregation agg : aggregations) &#123; String type = agg.getType(); if (type.equals(TermsAggregationBuilder.NAME)) &#123; Bucket elasticBucket = ((Terms) agg).getBucketByKey(\"Elastic\"); long numberOfDocs = elasticBucket.getDocCount(); &#125;&#125; 获取建议要从 SearchResponse 中返回suggestions, 请使用suggestion 对象作为入口点, 然后检索嵌套的建议对象: 1234567Suggest suggest = searchResponse.getSuggest(); TermSuggestion termSuggestion = suggest.getSuggestion(\"suggest_user\"); for (TermSuggestion.Entry entry : termSuggestion.getEntries()) &#123; for (TermSuggestion.Entry.Option option : entry) &#123; String suggestText = option.getText().string(); &#125;&#125; 获取性能分析结果使用 getProfileResults () 方法从 SearchResponse 检索性能分析结果。此方法返回一个Map,包含 SearchRequest 执行中所涉及的每个分片的 ProfileShardResult 对象。ProfileShardResult 存储在映射中, 使用唯一标识配置文件结果对应的碎片的键. 下面是一个示例代码, 它演示如何循环访问每个分片的所有性能分析结果: 123456Map&lt;String, ProfileShardResult&gt; profilingResults = searchResponse.getProfileResults(); for (Map.Entry&lt;String, ProfileShardResult&gt; profilingResult : profilingResults.entrySet()) &#123; String key = profilingResult.getKey(); ProfileShardResult profileShardResult = profilingResult.getValue(); &#125; ProfileShardResult 对象本身包含一个或多个QueryProfileShardResult: 12345List&lt;QueryProfileShardResult&gt; queryProfileShardResults = profileShardResult.getQueryProfileResults(); for (QueryProfileShardResult queryProfileResult : queryProfileShardResults) &#123; &#125; 12345for (ProfileResult profileResult : queryProfileResult.getQueryResults()) &#123; String queryName = profileResult.getQueryName(); long queryTimeInMillis = profileResult.getTime(); List&lt;ProfileResult&gt; profiledChildren = profileResult.getProfiledChildren(); &#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.milk4j.com/tags/elasticsearch/"}]},{"title":"","slug":"Docker 安装 redis","date":"2018-05-25T16:33:36.246Z","updated":"2018-06-08T06:26:41.693Z","comments":true,"path":"2018/05/26/Docker 安装 redis/","link":"","permalink":"https://blog.milk4j.com/2018/05/26/Docker 安装 redis/","excerpt":"","text":"Docker 安装 Redis下载镜像|创建运行容器123docker pull redis#创建|运行容器docker run -d --name=myredis -p 6379:6379 redis 其他容器与 redis 容器通讯nginx容器需要与redis容器通信的话首先要知道它的ip地址，但是每次都手工获取容器的ip地址显然是一件繁琐的事情，于是我们需要修改容器的启动方式，加–link参数，建立其他容器与redis容器之间的联系。 删除掉之前的容器，现在重新修改 nginx容器的启动方式： 1234# 使用 pwd 变量cd ~/nginx &amp;&amp; docker run -it -p 80:80 --name=mynginx --link=myredis:db -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginxdocker run -it -p 80:80 --name=web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx 这次加入了两个参数： -v /code:/usr/src/app 表示把宿主机上的/code目录挂载到容器内的/usr/src/app目录，可以通过直接管理宿主机上的挂载目录来管理容器内部的挂载目录。 –link=redis:db 表示把redis容器以db别名与该容器建立关系，在该容器内以db作为主机名表示了redis容器的主机地址。 现在进入到其他容器，通过ping命令确认nginx容器能访问到redis容器： 1234567$ ping dbPING db (192.168.32.12): 56 data bytes64 bytes from 192.168.32.12: icmp_seq=0 ttl=64 time=0.463 ms64 bytes from 192.168.32.12: icmp_seq=1 ttl=64 time=0.086 ms#ping 命令找不到$ apt-get update$ apt-get install inetutils-ping Redis 集群搭建12345#创建 redis master 容器$ docker run -d --name=redis_master -p 6380:6379 redis#两个 redis slave 容器$ docker run -d --name=redis_slave_1 -p 6380:6379 --link=redis_master:master redis redis-server --slaveof master 6379$ docker run -d --name=redis_slave_2 -p 6381:6379 --link=redis_master:master redis redis-server --slaveof master 6379 现在写入到Redis主节点的数据都会在从节点上备份一份数据。 为了防止 master 宕机，再由Sentinel集群根据投票选举出slave节点作为新的master。 下面为Sentinel编写Dockerfile，在redis镜像的基础上作改动： 12345FROM redis:latestCOPY run-sentinel.sh /run-sentinel.shCOPY sentinel.conf /etc/sentinel.confRUN chmod +x /run-sentinel.shENTRYPOINT [\"/run-sentinel.sh\"] Sentinel的配置文件： 123456port 26379dir /tmpsentinel monitor master redis-master 6379 2sentinel down-after-milliseconds master 30000sentinel parallel-syncs master 1sentinel failover-timeout master 180000 run-sentinel.sh： 12#!/bin/bashexec redis-server /etc/sentinel.conf --sentinel 构建出Sentinel的镜像文件，容器运行的方式类似于redis： 123$ docker run -d --name=sentinel_1 --link=redis_master:redis-master [build_sentinel_image]$ docker run -d --name=sentinel_2 --link=redis_master:redis-master [build_sentinel_image]$ docker run -d --name=sentinel_3 --link=redis_master:redis-master [build_sentinel_image] 这下Sentinel的容器也搭建起来了，应用的结构图如下：","categories":[],"tags":[]},{"title":"","slug":"【02】Docker 使用","date":"2018-05-25T14:26:13.069Z","updated":"2018-05-25T14:28:18.719Z","comments":true,"path":"2018/05/25/【02】Docker 使用/","link":"","permalink":"https://blog.milk4j.com/2018/05/25/【02】Docker 使用/","excerpt":"","text":"Docker使用一. docker使用 1. docker ps 查看运行中的容器 2. docker images 查看docker镜像 3. docker rm id(容器id) 删除容器（容器id可以通过docker ps查看，容器必须停止后才能删除） 3.1 删除全部的容器 docker rm docker ps -a -q 4. docker stop id(容器id) 停止容器运行 5. docker rmi id(镜像id) 删除镜像 6. docker pull ubuntu:16.04(镜像名称:版本号) 下载镜像 7. docker run -it ubuntu:16.04 创建并运行容器容器 -t 表示在新容器内指定一个伪终端或终端 -i 表示允许我们对容器内的 (STDIN) 进行交互 -p 指定映射端口 -d 在后台运行容器并打印容器ID 7.1 docker run -dit ubuntu:16.04 创建并后台运行容器 7.2 docker run -ditp 8080:8080（主机端口:容器端口） ubuntu:16.04 创建并后台运行容器且映射容器的端口 8. docker attach id(容器id) 进入正在运行中的容器环境 9. 退出容器 9.1 exit 直接退出容器并终止容器运行 9.2 [ctrl+p]+[ctrl+q]（快捷键） 退出容器，但是不会终止容器运行 10. docker commit -m’版本标识’ id(容器id) ubuntu:16.04(镜像与版本号) 提交镜像且生成镜像（可以通过该命令把搭建好的容器打包成一个新的镜像或者覆盖原镜像（即是修改原镜像内容，生成的镜像名与版本号相同就可以直接覆盖））","categories":[],"tags":[]},{"title":"","slug":"Docker 安装 nginx","date":"2018-05-25T14:23:37.506Z","updated":"2018-06-08T18:00:03.879Z","comments":true,"path":"2018/05/25/Docker 安装 nginx/","link":"","permalink":"https://blog.milk4j.com/2018/05/25/Docker 安装 nginx/","excerpt":"","text":"Docker 安装 nginx方式一：通过 pull 仓库镜像一、下载镜像1docker pull nginx 二、使用镜像创建容器1234567891011121314151617181920212223242526cd ~mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf#www目录将映射为nginx容器配置的虚拟目录#logs目录将映射为nginx容器的日志目录#conf目录里的配置文件将映射为nginx容器的配置文件#找一份默认的 nginx.conf 配置文件放在 conf 目录下,否则下面启动会报错docker run -p 80:80 --name web -v $PWD/www:/www -v $PWD/logs:/wwwlogs -d nginxdocker cp web:/etc/nginx/nginx.conf #删除容器后再运行下面的命令docker run -p 80:80 --name web --link=app1:app1 --link=app2:app2 --link=app3:app3 -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/conf/servers:/etc/nginx/conf.d -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~#docker inspect [容器名|id]docker inspect mynginx 命令说明： -p 80:80：将容器的80端口映射到主机的80端口 –name web：将容器命名为web -v $PWD/www:/www：将主机中当前目录下的www挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf：将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs：将主机中当前目录下的logs挂载到容器的/wwwlogs 方式二：通过 Dockerfile构建构建准备工作123mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/confcd ~/nginxvi Dockerfile 在 Dockerfile 中输入如下内容：123456789101112131415161718#指定使用那个基础镜像FROM centosMAINTAINER ginkgoLABEL Discription=\"基于centos的nginx镜像\" version=\"1.0\"WORKDIR /usr/local/srcRUN yum install -y wgetRUN wget http://nginx.org/download/nginx-1.8.0.tar.gzRUN tar -zxvf nginx-1.8.0.tar.gzWORKDIR nginx-1.8.0#安装nginx所依赖的包RUN yum -y install gcc-c++RUN yum -y install pcre pcre-develRUN yum -y install zlib zlib-develRUN yum -y install openssl openssl-devel libssl-devRUN ./configureRUN makeRUN make installEXPOSE 80 通过Dockerfile 构建一个镜像1234# -t 镜像名 , \".\" 是Dockerfile 所在的目录，可以使用绝对路径docker build -t ginkgo/nginx .#查看镜像docker images 构建|运行容器1234567891011121314151617#找一份默认的 nginx.conf 配置文件放在 ~/nginx/conf 目录下,否则下面启动会报错docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx#此时打开浏览器访问宿主机的 IP 就可看到 nginx 的界面了，安装启动成功#-d:让容器在后台运行。#-P:将容器内部使用的网络端口映射到我们使用的主机上。#使用命令进入交互式终端docker exec -it mynginx /bin/bash#查看 IPifconfig#发现找不到指令，需要安装 net-tools 工具依次执行，再执行 ifconfigapt-get updateapt-get install net-tools#在宿主机中查询容器的 IP，返回 json 串，里面包含了详细的容器信息，包括 IP ~docker inspect [容器名|id]","categories":[],"tags":[]},{"title":"Mac后端开发环境搭建","slug":"Mac后端开发环境搭建","date":"2018-04-14T02:01:56.000Z","updated":"2018-10-24T09:53:47.494Z","comments":true,"path":"2018/04/14/Mac后端开发环境搭建/","link":"","permalink":"https://blog.milk4j.com/2018/04/14/Mac后端开发环境搭建/","excerpt":"","text":"作为一个开发人员，选择 Mac 是一个非常好的选择，首先 Mac 是 Unix 的内核，支持 Unix 内核的命令，使用 Mac 能帮助我们熟悉 Unix 的操作命令 1、HomeBrew1.1 简介Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。 简单点说，Homebrew 是以最简单、最灵活的方式来安装苹果公司在 MacOS 中不包含的 UNIX 工具。 1.2 安装与卸载安装打开终端，复制粘贴，大约1分钟左右，下载完成，过程中需要输入密码，其他无需任何操作： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 卸载有安装就要有卸载，打开终端，复制粘贴： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot; 其实只用把上面安装的install换成uninstall就行了。 使用Homebrew 常用命令，下面以安装 git 为例（使用 brew 安装默认安装软件包的最新版本） 123456789101112131415161718安装任意软件包：brew install git卸载已安装软件包：brew uninstall git搜索可用软件包：brew search git查看任意软件包信息：brew info git更新已安装的软件包：brew upgrade git查看所有已安装的软件包：brew list更新 Homebrew：brew update查看 HomeBrew 版本：brew -vHomeBrew 帮助信息：brew -h 使用 brew -h 看下官方帮助： 123456789101112131415161718192021222324$ brew -hExample usage: brew search [TEXT|/REGEX/] brew info [FORMULA...] brew install FORMULA... brew update brew upgrade [FORMULA...] brew uninstall FORMULA... brew list [FORMULA...]Troubleshooting: brew config brew doctor brew install --verbose --debug FORMULAContributing: brew create [URL [--no-fetch]] brew edit [FORMULA...]Further help: brew commands brew help [COMMAND] man brew https://docs.brew.sh 友情提示在Mac OS X 10.11系统以后，/usr/local/等系统目录下的文件读写是需要系统root权限的，以往的Homebrew安装如果没有指定安装路径，会默认安装在这些需要系统root用户读写权限的目录下，导致有些指令需要添加sudo前缀来执行，比如升级Homebrew需要：sudo brew update 推荐: 安装Homebrew时对安装路径进行指定，直接安装在不需要系统root用户授权就可以自由读写的目录下 1/usr/bin/ruby &lt;install path&gt; -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 下面是我的 HomeBrew 的版本： 123$ brew -vHomebrew 1.6.0Homebrew/homebrew-core (no git repository) 默认安装的所有的命令都在/usr/local/bin目录下，安装文件都在/usr/local/Cellar下，对应的配置文件都在/usr/local/etc下 1.3 CakebrewCakebrew 是 HomeBrew 的 GUI 版本，提供图形化的方式安装和管理软件包，安装方式： 1brew cask install cakebrew 1.4 homebrew-caskhomebrew-cask安装常用软件，比在网上下载安装文件安装的优势在于：（1）节省下载安装包的过程，一行命令即可安装（2）一些在网上搜不到安装文件的软件也可以通过这种方法安装 12brew tap phinze/homebrew-caskbrew install brew-cask 使用方法：将上面的brew换成brew cask即可，如 1brew cask install qq 使用 brew cask 安装常用的软件： brew cask 搜索地址 https://caskroom.github.io/search 12345678910111213141516171819202122232425262728brew cask install yybrew cask install qqbrew cask install dash # 帮助文档brew cask install atombrew cask install sequel-pro # mysql可视化工具brew cask install sourcetree # git可视化工具brew cask install neteasemusic # 网易云音乐brew cask install android-file-transfer # android 传输工具brew cask install android-studiobrew cask install intellij-ideabrew cask install visual-studio-codebrew cask install mockplus # 比较不错的画原型工具brew cask install alfred # 小红帽brew cask install the-unarchiver # 压缩工具brew cask install thunder # 迅雷brew cask install mplayerx # 播放器brew cask install iterm2 # mac上最好用的终端brew cask install cd-to # 当前目录在终端显示brew cask install duet # ipad做外接显示器brew cask install ckb # 海盗船机械键盘驱动brew cask install shadowsocksx # 翻墙工具brew cask install firefox # 火狐brew cask install foxmail # 邮箱客户端brew cask install rdm # redis 客户端brew cask install typora # markdown工具brew cask install macdownbrew cask install cyberduck # ftp工具brew cask install bearychat 2、iTerm22.1 简介ITERM2 是 MAC 下最好的终端工具。直接去官网下载安装包安装即可使用。 2.2 iTerm2 常用快捷键 切换 tab：⌘+← ，⌘+→ ，⌘+{ ， ⌘+} ，⌘+数字直接定位到该 tab 新建 tab：⌘+t 顺序切换 pane：⌘+[ ， ⌘+] 按方向切换 pane：⌘+Option+方向键 切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分 智能查找，支持正则查找：⌘+f 3、安装OH MY ZSH安装ZSH 是一种Shell指令集，Mac 自带 ZSH 的安装。但 Oh my zsh 可以让你能更简便的配置 ZSH。 安装方式如下: 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 等待安装完成即可 配置设置 zsh 为系统的默认的 shell 1chsh -s /bin/zsh 更改zsh主题编辑 ~/.zshrc ，将文本中的 ZSH_THEME 修改为如下（个人推荐主题：ys） 1ZSH_THEME=\"ys\" 注：主题文件在 ~/.oh-my-zsh/themes 目录 4、安装JDK安装通过 HomeBrew 安装 JDK 安装 jdk8 brew cask info java8 安装 jdk9 brew cask info java9 也可以通过官网下载安装包安装 上述两个文件安装完成后，执行下述命令 123echo \"alias setJdk9='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk9.0.4.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"alias setJdk8='export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home'\" &gt;&gt; ~/.zshrcecho \"export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home\" &gt;&gt; ~/.zshrc 这样在命令行中默认设置当前环境变量为 JAVA 8 , 当我们需要切换到 JAVA 9 时只需在命令行中执行命令 setJdk9 即可 。 5、安装 Maven安装Maven 是Java生态中用来构建项目的工具。通过brew安装 1brew install maven 等待安装完成后即可 验证在命令行中输入下述命令验证MAVEN是否正确安装 1234567$ mvn -vApache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)Maven home: /usr/local/Cellar/maven/3.5.3/libexecJava version: 1.8.0_161, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: \"mac os x\", version: \"10.13.4\", arch: \"x86_64\", family: \"mac\" 如果有以上输出内容即标识安装完成 配置在 ~/.m2 目录下创建 settings.xml 文件，使用阿里云的 maven 仓库，内容如下 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt;&lt;/pluginGroups&gt; &lt;proxies&gt;&lt;/proxies&gt; &lt;servers&gt;&lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;JDK-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;JDK-1.8&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 6、安装 RedisRedis 是一款基于数据结构的内存数据库。在我们的项目中被用作高速集中式缓存的解决方案。 安装1brew install redis 等待安装完成即可 验证在命令行中输入下述命令查看 reids 版本 12$ redis-server -v Redis server v=2.8.3 sha=00000000:0 malloc=libc bits=64 build=e836d8ad888e21a1 如果有以上输出内容即表示安装完成 7、安装MySQLMysql 是业界主流的开源关系型数据库。在我们项目中用以持久化用户及系统数据。 安装1brew install mysql 等待安装完成即可 验证12$ mysql -Vmysql Ver 14.14 Distrib 5.6.15, for osx10.9 (x86_64) using EditLine wrapper 如果有以上输出内容即表示安装完成 8、安装 ElasticSearch安装Elasticsearch(简称ES）是一款基于lucene的全文搜索中间件。用于处理在大量文本中通过关键字搜索的场景（例如搜索商品、店铺等）。先在下面的链接中下载安装包（已集成相关插件）后解压, 将解压后的文件夹放到你想安装的目录。通过 brew 安装5.6版的 ES： 1brew install elasticsearch@5.6 验证打开Iterm2，进入 elasticsearch的安装目录，执行以下命令 1$ ./elasticsearch 就可以看到启动日志了 9、安装Nginx安装Nginx 是一款轻量的高性能的Http与反向代理服务器。可被用作转发页面的请求至后台的Tomcat服务器 1brew install nginx 等待安装完成即可 验证在命令行中输入下述命令验证 Nginx 是否正确安装 (版本可能有所不同) 12345$ nginx -Vnginx version: nginx/1.6.3built by clang 6.1.0 (clang-602.0.49) (based on LLVM 3.6.0svn)TLS SNI support enabledconfigure arguments: --prefix=/usr/local/Cellar/nginx/1.6.3 --with-http_ssl_module --with-pcre --with-ipv6 --sbin-path=/usr/local/Cellar/nginx/1.6.3/bin/nginx --with-cc-opt=&apos;-I/usr/local/Cellar/pcre/8.36/include -I/usr/local/Cellar/openssl/1.0.2a-1/include&apos; --with-ld-opt=&apos;-L/usr/local/Cellar/pcre/8.36/lib -L/usr/local/Cellar/openssl/1.0.2a-1/lib&apos; --conf-path=/usr/local/etc/nginx/nginx.conf --pid-path=/usr/local/var/run/nginx.pid --lock-path=/usr/local/var/run/nginx.lock --http-client-body-temp-path=/usr/local/var/run/nginx/client_body_temp --http-proxy-temp-path=/usr/local/var/run/nginx/proxy_temp --http-fastcgi-temp-path=/usr/local/var/run/nginx/fastcgi_temp --http-uwsgi-temp-path=/usr/local/var/run/nginx/uwsgi_temp --http-scgi-temp-path=/usr/local/var/run/nginx/scgi_temp --http-log-path=/usr/local/var/log/nginx/access.log --error-log-path=/usr/local/var/log/nginx/error.log --with-http_gzip_static_module 修改配置文件12345678910111213141516171819202122#user nobody;worker_processes 2;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip on; include servers/*.conf;&#125; 10、安装 SEQUEL PROSequel Pro 是一款免费的 MySQL 的图形管理工具。 安装在官网可下载最新版本 11、安装 IntelliJ IDEAIntelliJ IDEA 业界公认为最好的 Java 开发工具之一 安装【官网】，网上有很多破解方法，如果资金允许请支持正版 12、安装 Zookeeper安装通过 brew 安装 1brew install zookeeper 13、LaunchRocket简介是一个帮助管理Homebrew安装的服务的软件，比如你使用brew安装的Mysql、Redis、MongoDB，LaunchRocket 可以管理这些服务的生命周期和启动方式（自启动、手动启动），传统方式需要使用命令行的命令，而使用LaunchRocket则可以在图形界面中进行管理。 安装brew 安装 1brew cask install launchrocket 14、一些其他实用软件办公：1234567891011121314markdown 编辑器：BoostNote、Typora、YuWriter、Mou文本编辑工具：Atom、Visual Studio Code、Sublime时间/项目管理工具：2Do、OmniPlan、OmniForce流程图绘制：OmniGraffle脑图绘制：Xmind、MindNode、iThoughtsX文稿编辑/演示： KeyNote、Pages、Scrivener、Quiver状态栏图标隐藏工具：Bartender3压缩工具：Dr.Unarchiver技术文档离线阅读：Dash效率搜索：Alfred3数据库管理工具：Sequel Pro、Navicat、TablePlusGit 的 GUI 工具：SourceTree、GitUpREST 客户端：Postman、PawHosts 切换管理工具：SwitchHosts 上班必备12社交软件：微信、QQ、钉钉上班听音乐：网易云音乐、酷我音乐、QQ音乐","categories":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/categories/mac/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://blog.milk4j.com/tags/mac/"}]},{"title":"Hexo基本使用","slug":"Hexo基本使用","date":"2015-04-21T15:20:36.000Z","updated":"2018-10-22T02:18:04.969Z","comments":true,"path":"2015/04/21/Hexo基本使用/","link":"","permalink":"https://blog.milk4j.com/2015/04/21/Hexo基本使用/","excerpt":"","text":"官网 Hexo| 文档 documentation | 社区 troubleshooting | Git地址 GitHub. 快速入门新建文章1$ hexo new \"My New Post\" 详细说明: Writing 运行1$ hexo server 详细说明: Server 生成静态文件1$ hexo generate 详细说明: Generating 发布到远程站点1$ hexo deploy 详细说明: Deployment","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.milk4j.com/tags/hexo/"}]}]}